{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zo4_NBVWMQvE"
   },
   "source": [
    "# **APRENDIZAGEM POR REFORÇO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxK5jFkXgZt3"
   },
   "source": [
    "https://gym.openai.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwJaIifT9YtC"
   },
   "source": [
    "https://gym.openai.com/envs/Taxi-v3/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNKu2HUe9fGW"
   },
   "source": [
    "**Links de referência**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJuapuEAMK2m"
   },
   "source": [
    "https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXmTMZJhML9T"
   },
   "source": [
    "https://medium.com/turing-talks/aprendizado-por-refor%C3%A7o-4-gym-d18ac1280628"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7swTjEjMHMMl"
   },
   "source": [
    "**Instalando a Biblioteca GYM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nuOSLFMCbKY",
    "outputId": "2b3fc123-535b-4b91-81fe-bfa043b0bbed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym[ale-py]\n",
      "  Using cached gym-0.26.2.tar.gz (721 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[33mWARNING: gym 0.26.2 does not provide the extra 'ale-py'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /home/lucas/anaconda3/lib/python3.12/site-packages (from gym[ale-py]) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/lucas/anaconda3/lib/python3.12/site-packages (from gym[ale-py]) (2.2.1)\n",
      "Collecting gym-notices>=0.0.4 (from gym[ale-py])\n",
      "  Using cached gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
      "Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827623 sha256=86e4e6624c52012d5a3d08202078c751adf6fb1548622a4ade4bf394431342a7\n",
      "  Stored in directory: /home/lucas/.cache/pip/wheels/95/51/6c/9bb05ebbe7c5cb8171dfaa3611f32622ca4658d53f31c79077\n",
      "Successfully built gym\n",
      "Installing collected packages: gym-notices, gym\n",
      "Successfully installed gym-0.26.2 gym-notices-0.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install 'gym[ale-py]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LRh70CdVChvL"
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4_DwI5tHbq1"
   },
   "source": [
    "**Carregando e renderizando o ambiente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MvgWNK_uCmCK",
    "outputId": "22fbee27-fb72-4138-9199-f648844c6511"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"Taxi-v3\").env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JKfP0RINDAfA"
   },
   "outputs": [],
   "source": [
    "## Função inoperante devido a inúmeros problemas na execução.\n",
    "## Ela não é essencial para a aprendizagem por reforço, é apenas uma demonstração.\n",
    "## Não retirei do vídeo porque a imagem ajuda no entendimento das ações.\n",
    "# env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rj2ZuAZDDCR4",
    "outputId": "acb57ba6-cf4b-4036-b38f-cf8bef3fbc8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, {'prob': 1.0, 'action_mask': array([0, 1, 0, 0, 0, 0], dtype=int8)})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redefinindo o ambiente e retornando um estado inicial aleatório.\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0oB2144rDkDe"
   },
   "outputs": [],
   "source": [
    "## função inoperante\n",
    "# env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXaShm9SIFDU"
   },
   "source": [
    "env.reset: redefine o ambiente e retorna um estado inicial aleatório.\n",
    "\n",
    "env.step(action): Apresenta os passos de ação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0g-pY7BoDwOu",
    "outputId": "2abe21b9-1bbd-40f6-e431-ec434ceff773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space Discrete(6)\n",
      "State Space Discrete(500)\n"
     ]
    }
   ],
   "source": [
    "# Print no espaço de ação discreto e no espaço de estado discreto\n",
    "print(\"Action Space {}\".format(env.action_space))\n",
    "print(\"State Space {}\".format(env.observation_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8ovsxyiC-sA"
   },
   "source": [
    "**ESPAÇO DE ESTADO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORr0nKOpA9CY"
   },
   "source": [
    "Espaço de estado da grade: 5x5 = 25\n",
    "\n",
    "Espaço posição do passageiro: 5 (quatro pontos externos e um dentro do taxi)\n",
    "\n",
    "Espaço de posição de embargue/desembarque (destino): 4\n",
    "\n",
    "Total: 5x5x5x4 = 500 espaços de estado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCjLZN58DCy-"
   },
   "source": [
    "**ESPAÇO DE AÇÃO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5C0tVoAJwPp"
   },
   "source": [
    "O algoritmo escolherá um número de ação de 0 a 5, onde:\n",
    "\n",
    "0 = sul\n",
    "\n",
    "1 = norte\n",
    "\n",
    "2 = leste\n",
    "\n",
    "3 = oeste\n",
    "\n",
    "4 = embarque\n",
    "\n",
    "5 = desembarque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEn_Sq6RK68T"
   },
   "source": [
    "**Colocando o taxi na linha 3, coluna 1, nosso passageiro no local 2 e nosso destino é o local 0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wr_-TDSJEgFt",
    "outputId": "a1eea964-cfc4-45d1-ad3c-5d56e8a6ca5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: 328\n"
     ]
    }
   ],
   "source": [
    "state = env.encode(3, 1, 2,0) # (linha do taxi, coluna do taxi, índice do passageiro, índice do destino)\n",
    "print(\"State:\", state)\n",
    "\n",
    "env.s = state\n",
    "#env.render() # função temporariamente inoperante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywJ13rDjJMbf"
   },
   "source": [
    "Táxi amarelo é sem passageiro e verde é com passageiro.\n",
    "\n",
    "A barra (\"|\") representa uma parede que o táxi não pode atravessar.\n",
    "\n",
    "R, G, Y, B são os possíveis locais de coleta e destino. A **letra azul** representa o local de **embargue** do passageiro e a **letra roxa** é o **desembargue** do passageiro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-cTUWHZKW4U"
   },
   "source": [
    "Recompensas (Já definidas na biblioteca):\n",
    "\n",
    "+20 para um desembarque correto.\n",
    "\n",
    "-10 para um embarque ou desembarque incorreto.\n",
    "\n",
    "-1 para ações que não sejam as duas anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bmWgFuTKEoNj",
    "outputId": "bd13b218-f4c0-434e-95ec-4527f5f6918e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 428, -1, False)],\n",
       " 1: [(1.0, 228, -1, False)],\n",
       " 2: [(1.0, 348, -1, False)],\n",
       " 3: [(1.0, 328, -1, False)],\n",
       " 4: [(1.0, 328, -10, False)],\n",
       " 5: [(1.0, 328, -10, False)]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.P[328]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gSapNw99FFSq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SnRf1JhUFDeR"
   },
   "outputs": [],
   "source": [
    "tabela_q = np.zeros([env.observation_space.n, env.action_space.n]) #iniciando a tabela Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLUVMJzb6qXp",
    "outputId": "3188c841-9c29-42f2-d2f5-877b8682a088"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14WKyz3w61DI",
    "outputId": "529fecab-0d3b-4efc-9cab-b9e5a8ce5d9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeD6Mkl86VL1"
   },
   "source": [
    "**TREINAMENTO DO ALGORITMO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUwTuTxgFOU6",
    "outputId": "de962e76-ed64-4c23-8602-866cdbd7b9a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episódios: 200000\n",
      "Treinamento terminado.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    " \n",
    "# Verifique se o ambiente usa um estado discreto\n",
    "try:\n",
    "    estado_dim = env.observation_space.n  # Se o estado for discreto\n",
    "except AttributeError:\n",
    "    estado_dim = env.observation_space.shape[0]  # Se o estado for contínuo\n",
    "\n",
    "# Inicialize a tabela Q com zeros\n",
    "tabela_q = np.zeros([estado_dim, env.action_space.n])\n",
    "\n",
    "# Defina os hiperparâmetros\n",
    "alpha = 0.1  # Taxa de aprendizado\n",
    "gamma = 0.6  # Fator de desconto\n",
    "epsilon = 0.1  # Taxa de exploração (chance de ação aleatória)\n",
    "\n",
    "# Treinamento por 200.000 episódios\n",
    "for i in range(1, 200001):\n",
    "    estado = env.reset()\n",
    "\n",
    "    # Verificar se o estado é uma tupla ou array e converter para um índice\n",
    "    if isinstance(estado, np.ndarray) or isinstance(estado, tuple):\n",
    "        estado = estado[0]  # Ajuste dependendo da estrutura do estado\n",
    "\n",
    "    episodios, penalidades, recompensa = 0, 0, 0\n",
    "    terminado = False\n",
    "\n",
    "    while not terminado:\n",
    "        # Decida se será tomada uma ação aleatória ou se seguirá a política da tabela Q\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            acao = env.action_space.sample()  # Ação aleatória\n",
    "        else:\n",
    "            acao = np.argmax(tabela_q[estado])  # Melhor ação com base na tabela Q\n",
    "\n",
    "        # Tome a ação e observe o novo estado e a recompensa\n",
    "        resultado = env.step(acao)  # Captura múltiplos valores\n",
    "\n",
    "        # Verifique se a função `step` retorna 4 ou 5 valores\n",
    "        if len(resultado) == 5:\n",
    "            proximo_estado, recompensa, terminado, truncado, info = resultado\n",
    "            terminado = terminado or truncado  # Combine terminado e truncado\n",
    "        else:\n",
    "            proximo_estado, recompensa, terminado, info = resultado\n",
    "\n",
    "        # Se o próximo estado for array ou tupla, converta para índice\n",
    "        if isinstance(proximo_estado, np.ndarray) or isinstance(proximo_estado, tuple):\n",
    "            proximo_estado = proximo_estado[0]\n",
    "\n",
    "        # Atualize o valor da tabela Q utilizando a equação de Bellman\n",
    "        valor_antigo = tabela_q[estado, acao]\n",
    "        proximo_max = np.max(tabela_q[proximo_estado])\n",
    "\n",
    "        valor_novo = (1 - alpha) * valor_antigo + alpha * (recompensa + gamma * proximo_max)\n",
    "        tabela_q[estado, acao] = valor_novo\n",
    "\n",
    "        if recompensa == -10:\n",
    "            penalidades += 1\n",
    "\n",
    "        estado = proximo_estado\n",
    "        episodios += 1\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Episódios: {i}\")\n",
    "\n",
    "print(\"Treinamento terminado.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRvVzvzL6k8U"
   },
   "source": [
    "**AVALIAÇÃO DO ALGORITMO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygame==2.1.0\n",
      "  Using cached pygame-2.1.0.tar.gz (5.8 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[29 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m WARNING, No \"Setup\" File Exists, Running \"buildconfig/config.py\"\n",
      "  \u001b[31m   \u001b[0m Using UNIX configuration...\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m WARNING:root:Some pygame dependencies were not found. Pygame can still compile and install, but games that depend on those missing dependencies will not run. Use -auto to continue building without all dependencies.\n",
      "  \u001b[31m   \u001b[0m Missing dependencies\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Hunting dependencies...\n",
      "  \u001b[31m   \u001b[0m SDL     : found 2.0.20\n",
      "  \u001b[31m   \u001b[0m FONT    : found\n",
      "  \u001b[31m   \u001b[0m IMAGE   : found\n",
      "  \u001b[31m   \u001b[0m MIXER   : found\n",
      "  \u001b[31m   \u001b[0m PNG     : found\n",
      "  \u001b[31m   \u001b[0m JPEG    : found\n",
      "  \u001b[31m   \u001b[0m SCRAP   : found\n",
      "  \u001b[31m   \u001b[0m PORTMIDI: not found\n",
      "  \u001b[31m   \u001b[0m PORTMIDI portmidi.h libportmidi.so ['/usr/include', '/usr/include/SDL2', '/usr/local/include', '/usr/local/include/SDL2', '/usr/X11R6/include', '/usr/include/SDL2'] ['/usr/lib', '/usr/lib64', '/usr/X11R6/lib', '/usr/lib/i386-linux-gnu', '/usr/lib/x86_64-linux-gnu', '/usr/lib/arm-linux-gnueabihf/', '/usr/lib/aarch64-linux-gnu/', '/usr/local/lib', '/usr/local/lib64', '/usr/local/X11R6/lib', '/usr/local/lib/i386-linux-gnu', '/usr/local/lib/x86_64-linux-gnu', '/usr/local/lib/arm-linux-gnueabihf/', '/usr/local/lib/aarch64-linux-gnu/']\n",
      "  \u001b[31m   \u001b[0m PORTTIME: not found\n",
      "  \u001b[31m   \u001b[0m PORTTIME porttime.h libporttime.so ['/usr/include', '/usr/include/SDL2', '/usr/local/include', '/usr/local/include/SDL2', '/usr/X11R6/include', '/usr/include/SDL2'] ['/usr/lib', '/usr/lib64', '/usr/X11R6/lib', '/usr/lib/i386-linux-gnu', '/usr/lib/x86_64-linux-gnu', '/usr/lib/arm-linux-gnueabihf/', '/usr/lib/aarch64-linux-gnu/', '/usr/local/lib', '/usr/local/lib64', '/usr/local/X11R6/lib', '/usr/local/lib/i386-linux-gnu', '/usr/local/lib/x86_64-linux-gnu', '/usr/local/lib/arm-linux-gnueabihf/', '/usr/local/lib/aarch64-linux-gnu/']\n",
      "  \u001b[31m   \u001b[0m FREETYPE: found 24.1.18\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ---\n",
      "  \u001b[31m   \u001b[0m For help with compilation see:\n",
      "  \u001b[31m   \u001b[0m     https://www.pygame.org/wiki/Compilation\n",
      "  \u001b[31m   \u001b[0m To contribute to pygame development see:\n",
      "  \u001b[31m   \u001b[0m     https://www.pygame.org/contribute.html\n",
      "  \u001b[31m   \u001b[0m ---\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pygame==2.1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hl4PZe4Q1M0i",
    "outputId": "3674634d-308f-43e4-df59-29b61ee59562"
   },
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "pygame is not installed, run `pip install gym[toy_text]`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/gym/envs/toy_text/taxi.py:294\u001b[0m, in \u001b[0;36mTaxiEnv._render_gui\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m  \u001b[38;5;66;03m# dependency to pygame only if rendering with human\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygame'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m         penalidades \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Armazenar o frame para visualização (removendo o argumento `mode='ansi'`)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m---> 37\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m: env\u001b[38;5;241m.\u001b[39mrender(),  \u001b[38;5;66;03m# Removido o argumento 'mode'\u001b[39;00m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m: proximo_estado,\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m'\u001b[39m: acao,\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m: recompensa\n\u001b[1;32m     41\u001b[0m     })\n\u001b[1;32m     43\u001b[0m     estado \u001b[38;5;241m=\u001b[39m proximo_estado\n\u001b[1;32m     45\u001b[0m total_penalidades \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m penalidades\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/gym/wrappers/order_enforcing.py:51\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_render_order_enforcing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m     )\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/gym/wrappers/env_checker.py:55\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_render_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/gym/envs/toy_text/taxi.py:290\u001b[0m, in \u001b[0;36mTaxiEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_text()\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# self.render_mode in {\"human\", \"rgb_array\"}:\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_gui(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/gym/envs/toy_text/taxi.py:296\u001b[0m, in \u001b[0;36mTaxiEnv._render_gui\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m  \u001b[38;5;66;03m# dependency to pygame only if rendering with human\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DependencyNotInstalled(\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpygame is not installed, run `pip install gym[toy_text]`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     )\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     pygame\u001b[38;5;241m.\u001b[39minit()\n",
      "\u001b[0;31mDependencyNotInstalled\u001b[0m: pygame is not installed, run `pip install gym[toy_text]`"
     ]
    }
   ],
   "source": [
    "total_penalidades = 0\n",
    "episodios = 100\n",
    "frames = []\n",
    "\n",
    "for i in range(episodios):\n",
    "    estado = env.reset()\n",
    "\n",
    "    # Verificar se o estado é uma tupla ou array e converter para um índice\n",
    "    if isinstance(estado, np.ndarray) or isinstance(estado, tuple):\n",
    "        estado = estado[0]  # Ajuste dependendo da estrutura do estado\n",
    "\n",
    "    penalidades, recompensa = 0, 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        acao = np.argmax(tabela_q[estado])\n",
    "        \n",
    "        # Tome a ação e receba o novo estado\n",
    "        resultado = env.step(acao)\n",
    "        \n",
    "        # Verifique se env.step() retorna 4 ou 5 valores\n",
    "        if len(resultado) == 5:\n",
    "            proximo_estado, recompensa, done, truncado, info = resultado\n",
    "            done = done or truncado\n",
    "        else:\n",
    "            proximo_estado, recompensa, done, info = resultado\n",
    "\n",
    "        # Converter o estado para um índice válido, se necessário\n",
    "        if isinstance(proximo_estado, np.ndarray) or isinstance(proximo_estado, tuple):\n",
    "            proximo_estado = proximo_estado[0]\n",
    "\n",
    "        if recompensa == -10:\n",
    "            penalidades += 1\n",
    "\n",
    "        # Armazenar o frame para visualização (removendo o argumento `mode='ansi'`)\n",
    "        frames.append({\n",
    "            'frame': env.render(),  # Removido o argumento 'mode'\n",
    "            'state': proximo_estado,\n",
    "            'action': acao,\n",
    "            'reward': recompensa\n",
    "        })\n",
    "\n",
    "        estado = proximo_estado\n",
    "\n",
    "    total_penalidades += penalidades\n",
    "\n",
    "# Exibir os resultados\n",
    "print('Episódios:', episodios)\n",
    "print('Penalidades:', total_penalidades)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZU5Kh861xvp",
    "outputId": "f752cbd5-70ee-4303-f8e8-79675e92e979"
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "for frame in frames:\n",
    "  clear_output(wait=True)\n",
    "  print(frame['frame'])\n",
    "  print('Estado', frame['state'])\n",
    "  print('Ação', frame['action'])\n",
    "  print('Recompensa', frame['reward'])\n",
    "  sleep(.2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
