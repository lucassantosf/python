{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "client = Groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8b33d2da-7bc9-4d82-929f-f597faf4b37c', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='LLaMA e LangChain são dois modelos de linguagem baseados em AI que são frequentemente mencionados juntos, mas eles têm algumas diferenças importantes.\\n\\nLLaMA (Large Language Model Application) é um modelo de linguagem desenvolvido pela Meta AI que é projetado para ser um modelo mais amplo e mais detalhado em relação aos modelos anteriores. Ele tem mais de 25 bilhões de parâmetros e é treinado para aprender conceitos e conhecimentos de larga escala. Isso permite que LLaMA seja mais sensato e mais preciso na sua compreensão e resposta a perguntas e tarefas.\\n\\nLangChain, por outro lado, é um modelo de linguagem desenvolvido pela Meta AI e pela Shanghai Fintech & AI, o qual é projetado para ser mais focado em tarefas de linguagem específicas, como conversas, resumo de texto e tradução. Ele tem mais de 10 bilhões de parâmetros e é treinado para melhorar a precisão e a fluência na geração de texto.\\n\\nUma das principais diferenças entre LLaMA e LangChain é a sua aplicação. LLaMA é projetado para ser um modelo geral, capaz de lidar com uma ampla variedade de tarefas e problemas, enquanto LangChain é mais especializado em tarefas específicas de linguagem.\\n\\nEm resumo, LLaMA é um modelo mais amplo e mais detalhado, projetado para ser um modelo geral, enquanto LangChain é um modelo mais especializado, projetado para lidar com tarefas específicas de linguagem.\\n\\nAqui estão alguns outros pontos a considerar:\\n\\n* LLaMA é mais recente e tem mais parâmetros que LangChain.\\n* LLaMA é mais preciso e mais sensato que LangChain, devido à sua formação mais ampla.\\n* LangChain é mais rápido e mais eficiente que LLaMA, devido à sua arquitetura mais especializada.\\n\\nEm resumo, LLaMA é uma ferramenta mais completa e mais versátil, enquanto LangChain é mais especializado e mais rápido. Ambos os modelos têm suas próprias características e vantagens, e dependendo das necessidades específicas, um ou outro pode ser mais adequado.', role='assistant', function_call=None, reasoning=None, tool_calls=None))], created=1738791604, model='llama3-8b-8192', object='chat.completion', system_fingerprint='fp_a97cfe35ae', usage=CompletionUsage(completion_tokens=498, prompt_tokens=30, total_tokens=528, completion_time=0.415, prompt_time=0.011400711, queue_time=0.064646618, total_time=0.426400711), x_groq={'id': 'req_01jkc0wm67f9nb3y90kxhhn0xp'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensagens = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Explique a diferença entre llm e langchain. Responda em português\" \n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=mensagens,\n",
    "    model=\"llama3-8b-8192\"\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLaMA e LangChain são dois modelos de linguagem baseados em AI que são frequentemente mencionados juntos, mas eles têm algumas diferenças importantes.\n",
      "\n",
      "LLaMA (Large Language Model Application) é um modelo de linguagem desenvolvido pela Meta AI que é projetado para ser um modelo mais amplo e mais detalhado em relação aos modelos anteriores. Ele tem mais de 25 bilhões de parâmetros e é treinado para aprender conceitos e conhecimentos de larga escala. Isso permite que LLaMA seja mais sensato e mais preciso na sua compreensão e resposta a perguntas e tarefas.\n",
      "\n",
      "LangChain, por outro lado, é um modelo de linguagem desenvolvido pela Meta AI e pela Shanghai Fintech & AI, o qual é projetado para ser mais focado em tarefas de linguagem específicas, como conversas, resumo de texto e tradução. Ele tem mais de 10 bilhões de parâmetros e é treinado para melhorar a precisão e a fluência na geração de texto.\n",
      "\n",
      "Uma das principais diferenças entre LLaMA e LangChain é a sua aplicação. LLaMA é projetado para ser um modelo geral, capaz de lidar com uma ampla variedade de tarefas e problemas, enquanto LangChain é mais especializado em tarefas específicas de linguagem.\n",
      "\n",
      "Em resumo, LLaMA é um modelo mais amplo e mais detalhado, projetado para ser um modelo geral, enquanto LangChain é um modelo mais especializado, projetado para lidar com tarefas específicas de linguagem.\n",
      "\n",
      "Aqui estão alguns outros pontos a considerar:\n",
      "\n",
      "* LLaMA é mais recente e tem mais parâmetros que LangChain.\n",
      "* LLaMA é mais preciso e mais sensato que LangChain, devido à sua formação mais ampla.\n",
      "* LangChain é mais rápido e mais eficiente que LLaMA, devido à sua arquitetura mais especializada.\n",
      "\n",
      "Em resumo, LLaMA é uma ferramenta mais completa e mais versátil, enquanto LangChain é mais especializado e mais rápido. Ambos os modelos têm suas próprias características e vantagens, e dependendo das necessidades específicas, um ou outro pode ser mais adequado.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLaMA (Large Language Model Application) e LangChain são ambas plataformas de linguagem artificial que oferecem ferramentas para a geração de texto, classificação de texto e outras tarefas de processamento de linguagem natural. No entanto, há algumas diferenças importantes entre elas:\n",
      "\n",
      "1. **Arquitetura**: LLaMA é uma plataforma baseada em transformers, desenvolvida pela baGAN, uma equipe de pesquisadores da partir de Meta AI. Já LangChain é uma plataforma baseada em seqüências de linguagem, desenvolvida pela equipe de pesquisa do instituto de tecnologia de língua (ITL).\n",
      "2. **Tamanho e capacidade**: LLaMA é uma das maiores redes neurais treinadas para processamento de linguagem natural, com mais de 7 bilhões de parâmetros. Isso a torna mais flexível e capaz de gerar texto mais complexo e detalhado. LangChain, embora seja um modelo de linguagem avançado, tem um tamanho relativamente menor, com cerca de 1,5 bilhão de parâmetros.\n",
      "3. **Serviços e recursos**: LLaMA oferece um conjunto de ferramentas e recursos mais amplo, como geração de texto, tradução, resumo, classificação e análise de sentimentos. LangChain, por outro lado, se concentra mais em tarefas de geração de texto e classificação, com foco em aplicativos móveis e Web.\n",
      "4. **Plataformas**: LLaMA é uma plataforma mais ampla, disponível em máquinas virtuais e no Google Colab, o que permite sua integração em projetos mais complexos. LangChain é disponível em um ambiente de desenvolvimento integrado (IDE) mais simplificado, mas que é fácil de usar e configurar.\n",
      "5. **Compatibilidade**: LLaMA é composta por uma série de modelos treinados de forma independente, enquanto LangChain é um modelo único treinado para uma variedade de tarefas. Isso pode fazer com que LangChain seja mais fácil de implementar e treinar, mas LLaMA seja mais versátil e capaz de abranger uma ampla gama de tarefas.\n",
      "6. **Licensing**: LLaMA é uma plataforma proprietária, o que significa que os usuários precisam ter uma licença para utilizá-la. LangChain, por outro lado, é uma plataforma de código aberto, o que significa que os usuários podem usar e customizar o modelo de forma gratuita.\n",
      "\n",
      "Em resumo, LLaMA é mais ampla e mais capaz, mas mais difícil de implementar e treinar, enquanto LangChain é mais fácil de usar e configurar, mas mais limitada em termos de recursos e capacidade.None"
     ]
    }
   ],
   "source": [
    "mensagens = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Explique a diferença entre llm e langchain. Responda em português\" \n",
    "    }\n",
    "]\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    messages=mensagens,\n",
    "    model=\"llama3-8b-8192\",\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunck in stream:\n",
    "    print(chunck.choices[0].delta.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcrição de Áudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def format_text(response):\n",
    "    text = response.text\n",
    "    text_formatted = textwrap.fill(text, width=100)\n",
    "    print(text_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Seja muito bem-vindo e bem-vinda ao curso Desbravando a IA com Python Explorando modelos de Hugging\n",
      "Face Neste curso eu quero te mostrar uma das maiores plataformas de inteligência artificial que\n",
      "possui diversos modelos prontos que é a plataforma do Hugging Face E o meu objetivo neste curso é\n",
      "explorar dois tipos de modelos Modelos relacionados a processamento de linguagem natural onde\n",
      "estaremos trabalhando com análise de sentimentos, vamos trabalhar também com informações de\n",
      "perguntas e respostas, vamos trabalhar também com modelos que nos ajudem a resumir textos e assim\n",
      "por diante. Por outro lado, nós teremos também modelos relacionados à visão computacional. Estaremos\n",
      "trabalhando com aplicações para segmentar imagens, classificar imagens, detectar objetos e muito\n",
      "mais. Space além disso em algumas sessões você vai ter a oportunidade de construir o teu modelo é\n",
      "uma interface web para o teu modelo utilizando a biblioteca Gradio e também vamos aprender a colocar\n",
      "a aplicação que construirmos em produção utilizando o Hugging Face no Space espero que você possa\n",
      "estar empolgado para esse curso pois estou muito empolgado para disseminar esse conhecimento\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "\n",
    "arquivo = \"files/curso.mp3\"\n",
    "\n",
    "with open(arquivo, \"rb\") as audio:\n",
    "    transcricao = client.audio.transcriptions.create(\n",
    "        file=(arquivo, audio.read()),\n",
    "        model=\"whisper-large-v3\",\n",
    "        response_format=\"json\",\n",
    "        language=\"pt\",\n",
    "        prompt=\"Este é um curso de Hugging Face que usa aplicação com Gradio\"\n",
    "    )\n",
    "    \n",
    "    format_text(transcricao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def format_text(response):\n",
    "    text = response.content\n",
    "    text_formatted = textwrap.fill(text, width=100)\n",
    "    print(text_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.2-11b-vision-preview\",\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\":[\n",
    "            {\"type\": \"text\", \"text\":\"O que há nessa imagem?\"},\n",
    "            {\"type\":\"image_url\", \"image_url\": {\n",
    "                \"url\": \"https://www.civitatis.com/blog/wp-content/uploads/2023/12/shutterstock_318248558-scaled.jpg\"\n",
    "            }}\n",
    "        ]\n",
    "    }],\n",
    "    temperature=1,\n",
    "    max_completion_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=False,\n",
    "    stop=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A essa imagem que se identifica uma praia. No fundo do relevo (em destaque branco) pode ser\n",
      "identificado um monte, além de algumas torres. Essas torres tem uma verticalidade caracteristica à\n",
      "construções de metropoles. Além disso, a imagem também tem casinhas junto à praia, bem próximas o\n",
      "bastante de não fazer com que a praia fique assoalhada. Essas casinhas devem servir como\n",
      "acomodações. Sempre, a imagem indica ao espectador que a praia está próxima de um local habitado.\n",
      "Essas acomodações nas proximidades da praia, com características de turísticas, indicam que essa\n",
      "praia possui uma atractividade a estas pessoas.  Essas acomodações possuirem uma verticalidade\n",
      "semelhante à ocupação humana (ponto de partida deste argumento e sendo as únicas estruturas\n",
      "similares às habitações) dada pelo monte destaque em baixo, junto à praia da imagem, devem servir de\n",
      "hospedagem nas distancias desde o monte e o mar. Então, a praia da imagem deve ser uma praia que um\n",
      "turista ou morador de alguma outras localidades se acomoda para um dia de lazer, o quais incluem\n",
      "este tipo de acomodações próximas à praia em um local próximo.  Outra característica observada é a\n",
      "enorme quantidade de pessoas não deslocadas da acomodação (sua ausência é evidênte) fazendo\n",
      "atividade no mar ou em locais ao redor.   Finalmente, tendo em consideração o relevo, localização,\n",
      "ocupação e relação (inserção) do local em relação à foto fotografia que o reproduz, indica-se que\n",
      "identifica-se prudentialmente, a praia Ilha de Paquetá, no estado do Rio de Janeiro.\n"
     ]
    }
   ],
   "source": [
    "format_text(completion.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
