{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "\n",
    "tool_repl = PythonREPLTool()\n",
    "tool_repl.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The Zen of Python, by Tim Peters\\n\\nBeautiful is better than ugly.\\nExplicit is better than implicit.\\nSimple is better than complex.\\nComplex is better than complicated.\\nFlat is better than nested.\\nSparse is better than dense.\\nReadability counts.\\nSpecial cases aren't special enough to break the rules.\\nAlthough practicality beats purity.\\nErrors should never pass silently.\\nUnless explicitly silenced.\\nIn the face of ambiguity, refuse the temptation to guess.\\nThere should be one-- and preferably only one --obvious way to do it.\\nAlthough that way may not be obvious at first unless you're Dutch.\\nNow is better than never.\\nAlthough never is often better than *right* now.\\nIf the implementation is hard to explain, it's a bad idea.\\nIf the implementation is easy to explain, it may be a good idea.\\nNamespaces are one honking great idea -- let's do more of those!\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_repl.run({\"query\": \"import this\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools([\"stackexchange\"])\n",
    "\n",
    "tool_stack = tools[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: Fixing ‘ascii’ codec can’t encode ‘\\\\u2014’ error in OpenAI API during vector store embedding\\nreturn value.encode(encoding or &quot;ascii&quot;)\\n\\nUnicodeEncodeError: &#39;ascii&#39; codec can&#39;t encode character &#39;\\\\u2014&#39; in position 160: ordinal not in range(128)\\n\\n\\nThis is Dependencise that I installed:\\npip install <span class=\"highlight\">langchain</span> &hellip; <span class=\"highlight\">langchain</span>-openai langgraph tiktoken langchainhub chromadb <span class=\"highlight\">langchain</span>-community beautifulsoup4 langchain_cohere\\n\\nComplete Code is looks like this :\\nimport os\\nimport sys\\nimport io\\nfrom urllib.parse import &hellip; \\n\\nQuestion: Is this approach completely wrong? Should I try using another framework other than ray.io?\\nIt seems that ray.io cannot be used with other frameworks like <span class=\"highlight\">langchain</span> and vector databases like faiss. I am having serialization issues when trying to use ray.io with <span class=\"highlight\">langchain</span> and faiss. &hellip; Yesterday I was trying to mix ray.io framework technology with other frameworks, like <span class=\"highlight\">langchain</span> and FAISS, with no success.\\nThis is the code I have been working on. It is on gist.github. &hellip; \\n\\nQuestion: LLM Model Lacking Confidence and Changing Answers Based on User Input\\nI&#39;ve trained a Large Language Model (LLM) using the RAG method to answer user queries. However, I&#39;m facing an issue where the model lacks confidence in its answers and changes them based on user input &hellip; \\nAnswer: You can add a prompt that enforces the model to prioritize earlier answers to ensure consistency. For example, you may ask the model to validate if its new answer conflicts with its prior knowledge, a … '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_stack.run({\"query\": \"LangChain\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
