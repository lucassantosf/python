{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "487145f8-7c5d-48cc-a700-7be1aac45604",
   "metadata": {},
   "source": [
    "## Redução de dimensionalidade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3097d9f-f8e5-4372-b83c-99b5b438a373",
   "metadata": {},
   "source": [
    "## Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f53ace4-e66a-497a-916f-03dd47c522dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importação da classe para rede neural utilizando o scikit-learn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e3ebd5-79ea-4b19-be06-48e60a371f6a",
   "metadata": {},
   "source": [
    "## Criação da Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbf961f-5eca-4e27-a0bf-62113ef91630",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "previsores = np.asarray(digits.data, 'float32')\n",
    "classe = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970291b2-f13c-477e-903f-9ed4063a2242",
   "metadata": {},
   "source": [
    "## Criação do normalizador - Escalonamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bae5308c-d5d7-4bfe-94fd-748e8362ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = MinMaxScaler(feature_range = (0,1))\n",
    "previsores = normalizador.fit_transform(previsores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b38f3e-ffb8-4853-86b7-50156b381e7d",
   "metadata": {},
   "source": [
    "## Divisão da base de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e593088-0295-4c64-9a64-3ca8c1e09374",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc1ff78-5b9e-412e-9b40-507fee96d3c3",
   "metadata": {},
   "source": [
    "## Criar estrutura do RBM - Restricted Boltzmann Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed1e7b7-ecd5-43ea-825d-b9578826a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação e configuração da \n",
    "rbm = BernoulliRBM(random_state=0)\n",
    "rbm.n_iter = 25\n",
    "rbm.n_components = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c5b4d-3887-4306-9641-bc1275ecb746",
   "metadata": {},
   "source": [
    "## Criação da rede neural usando scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43c8c71e-dcfc-4981-bbc1-6925b1a29544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O parâmetro hidden_layer_sizes cria as camadas escondidas, sendo que cada número\n",
    "# 37 representa uma camada. Neste exemplo temos duas camadas escondidas com 37 \n",
    "# neurônios cada uma - usada a fórmula (entradas + saídas) / 2 = (64 + 10) / 2 = 37\n",
    "# No scikit-learn não é necessário configurar a camada de saída, pois ele \n",
    "# faz automaticamente. Definimos o max_iter com no máximo 1000 épocas, porém,\n",
    "# quando a loos function não melhora depois de um certo número de rodadas ele\n",
    "# pára a execução. O parâmetro verbosa mostra as mensagens na tela\n",
    "mlp_rbm = MLPClassifier(hidden_layer_sizes = (37, 37),\n",
    "                        activation = 'relu', \n",
    "                        solver = 'adam',\n",
    "                        batch_size = 50,\n",
    "                        max_iter = 1000,\n",
    "                        verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaccd8ec-9c8e-42d0-a8a3-b012d68c5edb",
   "metadata": {},
   "source": [
    "## Criação do pipeline para executarmos o rbm e logo após o mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ebc0bd0-665b-46fc-8fe3-33d124183fe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.23863865\n",
      "Iteration 2, loss = 2.01292421\n",
      "Iteration 3, loss = 1.69923007\n",
      "Iteration 4, loss = 1.31352058\n",
      "Iteration 5, loss = 0.95474917\n",
      "Iteration 6, loss = 0.72331949\n",
      "Iteration 7, loss = 0.58516827\n",
      "Iteration 8, loss = 0.50221604\n",
      "Iteration 9, loss = 0.44309032\n",
      "Iteration 10, loss = 0.40339132\n",
      "Iteration 11, loss = 0.37434827\n",
      "Iteration 12, loss = 0.34796821\n",
      "Iteration 13, loss = 0.33193947\n",
      "Iteration 14, loss = 0.31526825\n",
      "Iteration 15, loss = 0.29967217\n",
      "Iteration 16, loss = 0.29112591\n",
      "Iteration 17, loss = 0.28305146\n",
      "Iteration 18, loss = 0.26986669\n",
      "Iteration 19, loss = 0.26312496\n",
      "Iteration 20, loss = 0.25597223\n",
      "Iteration 21, loss = 0.25233099\n",
      "Iteration 22, loss = 0.24381311\n",
      "Iteration 23, loss = 0.24004308\n",
      "Iteration 24, loss = 0.23468972\n",
      "Iteration 25, loss = 0.23061009\n",
      "Iteration 26, loss = 0.22707451\n",
      "Iteration 27, loss = 0.21964472\n",
      "Iteration 28, loss = 0.21926045\n",
      "Iteration 29, loss = 0.21392808\n",
      "Iteration 30, loss = 0.20940013\n",
      "Iteration 31, loss = 0.20990261\n",
      "Iteration 32, loss = 0.20812587\n",
      "Iteration 33, loss = 0.20047498\n",
      "Iteration 34, loss = 0.19795674\n",
      "Iteration 35, loss = 0.19616432\n",
      "Iteration 36, loss = 0.19247641\n",
      "Iteration 37, loss = 0.19302107\n",
      "Iteration 38, loss = 0.19086964\n",
      "Iteration 39, loss = 0.18511410\n",
      "Iteration 40, loss = 0.18806155\n",
      "Iteration 41, loss = 0.18238970\n",
      "Iteration 42, loss = 0.18327120\n",
      "Iteration 43, loss = 0.18125400\n",
      "Iteration 44, loss = 0.17558737\n",
      "Iteration 45, loss = 0.17724265\n",
      "Iteration 46, loss = 0.17724326\n",
      "Iteration 47, loss = 0.16943230\n",
      "Iteration 48, loss = 0.16880047\n",
      "Iteration 49, loss = 0.17053363\n",
      "Iteration 50, loss = 0.16539877\n",
      "Iteration 51, loss = 0.16439982\n",
      "Iteration 52, loss = 0.16391410\n",
      "Iteration 53, loss = 0.16420530\n",
      "Iteration 54, loss = 0.16289821\n",
      "Iteration 55, loss = 0.16200469\n",
      "Iteration 56, loss = 0.15903198\n",
      "Iteration 57, loss = 0.15754377\n",
      "Iteration 58, loss = 0.15756750\n",
      "Iteration 59, loss = 0.15594105\n",
      "Iteration 60, loss = 0.15238571\n",
      "Iteration 61, loss = 0.15525249\n",
      "Iteration 62, loss = 0.15019655\n",
      "Iteration 63, loss = 0.14979726\n",
      "Iteration 64, loss = 0.14708430\n",
      "Iteration 65, loss = 0.14916954\n",
      "Iteration 66, loss = 0.14372984\n",
      "Iteration 67, loss = 0.14685341\n",
      "Iteration 68, loss = 0.14488404\n",
      "Iteration 69, loss = 0.14348471\n",
      "Iteration 70, loss = 0.14227982\n",
      "Iteration 71, loss = 0.14324007\n",
      "Iteration 72, loss = 0.13862811\n",
      "Iteration 73, loss = 0.14105129\n",
      "Iteration 74, loss = 0.13738387\n",
      "Iteration 75, loss = 0.13670999\n",
      "Iteration 76, loss = 0.14001677\n",
      "Iteration 77, loss = 0.13703207\n",
      "Iteration 78, loss = 0.13279405\n",
      "Iteration 79, loss = 0.13397731\n",
      "Iteration 80, loss = 0.13078650\n",
      "Iteration 81, loss = 0.13095855\n",
      "Iteration 82, loss = 0.13204604\n",
      "Iteration 83, loss = 0.12733764\n",
      "Iteration 84, loss = 0.12926235\n",
      "Iteration 85, loss = 0.12642785\n",
      "Iteration 86, loss = 0.12606230\n",
      "Iteration 87, loss = 0.12788471\n",
      "Iteration 88, loss = 0.12321575\n",
      "Iteration 89, loss = 0.12601838\n",
      "Iteration 90, loss = 0.12355135\n",
      "Iteration 91, loss = 0.12030491\n",
      "Iteration 92, loss = 0.12325691\n",
      "Iteration 93, loss = 0.12000442\n",
      "Iteration 94, loss = 0.12073623\n",
      "Iteration 95, loss = 0.11977869\n",
      "Iteration 96, loss = 0.11921205\n",
      "Iteration 97, loss = 0.11807486\n",
      "Iteration 98, loss = 0.11671477\n",
      "Iteration 99, loss = 0.11635038\n",
      "Iteration 100, loss = 0.11621602\n",
      "Iteration 101, loss = 0.11296547\n",
      "Iteration 102, loss = 0.11737952\n",
      "Iteration 103, loss = 0.11275828\n",
      "Iteration 104, loss = 0.11315623\n",
      "Iteration 105, loss = 0.11126823\n",
      "Iteration 106, loss = 0.11192228\n",
      "Iteration 107, loss = 0.11201946\n",
      "Iteration 108, loss = 0.11034637\n",
      "Iteration 109, loss = 0.10891834\n",
      "Iteration 110, loss = 0.10733754\n",
      "Iteration 111, loss = 0.10853210\n",
      "Iteration 112, loss = 0.10617260\n",
      "Iteration 113, loss = 0.10662801\n",
      "Iteration 114, loss = 0.10516091\n",
      "Iteration 115, loss = 0.10566909\n",
      "Iteration 116, loss = 0.10295072\n",
      "Iteration 117, loss = 0.10345450\n",
      "Iteration 118, loss = 0.10744731\n",
      "Iteration 119, loss = 0.10435238\n",
      "Iteration 120, loss = 0.10641684\n",
      "Iteration 121, loss = 0.10094960\n",
      "Iteration 122, loss = 0.09829794\n",
      "Iteration 123, loss = 0.10385238\n",
      "Iteration 124, loss = 0.10114186\n",
      "Iteration 125, loss = 0.09749867\n",
      "Iteration 126, loss = 0.09961709\n",
      "Iteration 127, loss = 0.09924417\n",
      "Iteration 128, loss = 0.09893254\n",
      "Iteration 129, loss = 0.09775244\n",
      "Iteration 130, loss = 0.09469949\n",
      "Iteration 131, loss = 0.09572696\n",
      "Iteration 132, loss = 0.09360573\n",
      "Iteration 133, loss = 0.09475253\n",
      "Iteration 134, loss = 0.09329672\n",
      "Iteration 135, loss = 0.09533936\n",
      "Iteration 136, loss = 0.09369374\n",
      "Iteration 137, loss = 0.09483579\n",
      "Iteration 138, loss = 0.09112771\n",
      "Iteration 139, loss = 0.09194168\n",
      "Iteration 140, loss = 0.08973264\n",
      "Iteration 141, loss = 0.09017752\n",
      "Iteration 142, loss = 0.09001175\n",
      "Iteration 143, loss = 0.08909557\n",
      "Iteration 144, loss = 0.08950358\n",
      "Iteration 145, loss = 0.08866919\n",
      "Iteration 146, loss = 0.08651041\n",
      "Iteration 147, loss = 0.08810266\n",
      "Iteration 148, loss = 0.08627333\n",
      "Iteration 149, loss = 0.08724148\n",
      "Iteration 150, loss = 0.08760360\n",
      "Iteration 151, loss = 0.09121205\n",
      "Iteration 152, loss = 0.08404251\n",
      "Iteration 153, loss = 0.08683551\n",
      "Iteration 154, loss = 0.08428993\n",
      "Iteration 155, loss = 0.08258780\n",
      "Iteration 156, loss = 0.08360473\n",
      "Iteration 157, loss = 0.08387970\n",
      "Iteration 158, loss = 0.08570220\n",
      "Iteration 159, loss = 0.08400546\n",
      "Iteration 160, loss = 0.08051809\n",
      "Iteration 161, loss = 0.08379462\n",
      "Iteration 162, loss = 0.07976189\n",
      "Iteration 163, loss = 0.08057135\n",
      "Iteration 164, loss = 0.08122556\n",
      "Iteration 165, loss = 0.07911834\n",
      "Iteration 166, loss = 0.07874488\n",
      "Iteration 167, loss = 0.07638390\n",
      "Iteration 168, loss = 0.07596382\n",
      "Iteration 169, loss = 0.07636480\n",
      "Iteration 170, loss = 0.07612448\n",
      "Iteration 171, loss = 0.07666643\n",
      "Iteration 172, loss = 0.07713311\n",
      "Iteration 173, loss = 0.07695333\n",
      "Iteration 174, loss = 0.07526798\n",
      "Iteration 175, loss = 0.07442009\n",
      "Iteration 176, loss = 0.07200846\n",
      "Iteration 177, loss = 0.07379781\n",
      "Iteration 178, loss = 0.07361412\n",
      "Iteration 179, loss = 0.07056891\n",
      "Iteration 180, loss = 0.07304742\n",
      "Iteration 181, loss = 0.07180502\n",
      "Iteration 182, loss = 0.07071415\n",
      "Iteration 183, loss = 0.06849109\n",
      "Iteration 184, loss = 0.07207706\n",
      "Iteration 185, loss = 0.07177339\n",
      "Iteration 186, loss = 0.06919848\n",
      "Iteration 187, loss = 0.07003180\n",
      "Iteration 188, loss = 0.07057301\n",
      "Iteration 189, loss = 0.06860289\n",
      "Iteration 190, loss = 0.06812424\n",
      "Iteration 191, loss = 0.06721481\n",
      "Iteration 192, loss = 0.06678223\n",
      "Iteration 193, loss = 0.06822800\n",
      "Iteration 194, loss = 0.06713174\n",
      "Iteration 195, loss = 0.06539467\n",
      "Iteration 196, loss = 0.06598375\n",
      "Iteration 197, loss = 0.06511758\n",
      "Iteration 198, loss = 0.06806199\n",
      "Iteration 199, loss = 0.06501645\n",
      "Iteration 200, loss = 0.06481437\n",
      "Iteration 201, loss = 0.06380241\n",
      "Iteration 202, loss = 0.06599802\n",
      "Iteration 203, loss = 0.06522920\n",
      "Iteration 204, loss = 0.06046801\n",
      "Iteration 205, loss = 0.06225772\n",
      "Iteration 206, loss = 0.05991286\n",
      "Iteration 207, loss = 0.06273336\n",
      "Iteration 208, loss = 0.06161285\n",
      "Iteration 209, loss = 0.06174538\n",
      "Iteration 210, loss = 0.06140632\n",
      "Iteration 211, loss = 0.05741716\n",
      "Iteration 212, loss = 0.06042845\n",
      "Iteration 213, loss = 0.05880427\n",
      "Iteration 214, loss = 0.05782968\n",
      "Iteration 215, loss = 0.05830224\n",
      "Iteration 216, loss = 0.05884732\n",
      "Iteration 217, loss = 0.05731416\n",
      "Iteration 218, loss = 0.05986864\n",
      "Iteration 219, loss = 0.05870031\n",
      "Iteration 220, loss = 0.05793050\n",
      "Iteration 221, loss = 0.05448574\n",
      "Iteration 222, loss = 0.05685023\n",
      "Iteration 223, loss = 0.05711914\n",
      "Iteration 224, loss = 0.05794922\n",
      "Iteration 225, loss = 0.05351725\n",
      "Iteration 226, loss = 0.05369460\n",
      "Iteration 227, loss = 0.05219969\n",
      "Iteration 228, loss = 0.05241580\n",
      "Iteration 229, loss = 0.05199383\n",
      "Iteration 230, loss = 0.05374483\n",
      "Iteration 231, loss = 0.05296897\n",
      "Iteration 232, loss = 0.05088150\n",
      "Iteration 233, loss = 0.05250524\n",
      "Iteration 234, loss = 0.05402472\n",
      "Iteration 235, loss = 0.05118921\n",
      "Iteration 236, loss = 0.05337679\n",
      "Iteration 237, loss = 0.05066092\n",
      "Iteration 238, loss = 0.05017940\n",
      "Iteration 239, loss = 0.04891958\n",
      "Iteration 240, loss = 0.04979505\n",
      "Iteration 241, loss = 0.04990859\n",
      "Iteration 242, loss = 0.05053383\n",
      "Iteration 243, loss = 0.05238638\n",
      "Iteration 244, loss = 0.04987086\n",
      "Iteration 245, loss = 0.05004042\n",
      "Iteration 246, loss = 0.05044375\n",
      "Iteration 247, loss = 0.04598634\n",
      "Iteration 248, loss = 0.04783151\n",
      "Iteration 249, loss = 0.04753946\n",
      "Iteration 250, loss = 0.04599415\n",
      "Iteration 251, loss = 0.04710908\n",
      "Iteration 252, loss = 0.04636679\n",
      "Iteration 253, loss = 0.04796614\n",
      "Iteration 254, loss = 0.04483122\n",
      "Iteration 255, loss = 0.04592873\n",
      "Iteration 256, loss = 0.04526102\n",
      "Iteration 257, loss = 0.04326777\n",
      "Iteration 258, loss = 0.04543542\n",
      "Iteration 259, loss = 0.04499892\n",
      "Iteration 260, loss = 0.04321677\n",
      "Iteration 261, loss = 0.04483767\n",
      "Iteration 262, loss = 0.04304892\n",
      "Iteration 263, loss = 0.04246728\n",
      "Iteration 264, loss = 0.04180791\n",
      "Iteration 265, loss = 0.04346780\n",
      "Iteration 266, loss = 0.04102052\n",
      "Iteration 267, loss = 0.04220830\n",
      "Iteration 268, loss = 0.04079214\n",
      "Iteration 269, loss = 0.04110650\n",
      "Iteration 270, loss = 0.04314913\n",
      "Iteration 271, loss = 0.04316430\n",
      "Iteration 272, loss = 0.04226394\n",
      "Iteration 273, loss = 0.04152229\n",
      "Iteration 274, loss = 0.03995029\n",
      "Iteration 275, loss = 0.04040193\n",
      "Iteration 276, loss = 0.04272628\n",
      "Iteration 277, loss = 0.04023217\n",
      "Iteration 278, loss = 0.03888418\n",
      "Iteration 279, loss = 0.04065538\n",
      "Iteration 280, loss = 0.03989071\n",
      "Iteration 281, loss = 0.03862662\n",
      "Iteration 282, loss = 0.03811857\n",
      "Iteration 283, loss = 0.03832081\n",
      "Iteration 284, loss = 0.03742047\n",
      "Iteration 285, loss = 0.03807476\n",
      "Iteration 286, loss = 0.04028310\n",
      "Iteration 287, loss = 0.03648930\n",
      "Iteration 288, loss = 0.03692532\n",
      "Iteration 289, loss = 0.03490495\n",
      "Iteration 290, loss = 0.03422256\n",
      "Iteration 291, loss = 0.03605137\n",
      "Iteration 292, loss = 0.03735114\n",
      "Iteration 293, loss = 0.03582692\n",
      "Iteration 294, loss = 0.03498566\n",
      "Iteration 295, loss = 0.03472271\n",
      "Iteration 296, loss = 0.03647811\n",
      "Iteration 297, loss = 0.03498203\n",
      "Iteration 298, loss = 0.03372020\n",
      "Iteration 299, loss = 0.03347819\n",
      "Iteration 300, loss = 0.03548023\n",
      "Iteration 301, loss = 0.03176715\n",
      "Iteration 302, loss = 0.03409902\n",
      "Iteration 303, loss = 0.03476796\n",
      "Iteration 304, loss = 0.03563144\n",
      "Iteration 305, loss = 0.03620637\n",
      "Iteration 306, loss = 0.03820380\n",
      "Iteration 307, loss = 0.03186598\n",
      "Iteration 308, loss = 0.03202116\n",
      "Iteration 309, loss = 0.03228572\n",
      "Iteration 310, loss = 0.03284417\n",
      "Iteration 311, loss = 0.03065516\n",
      "Iteration 312, loss = 0.03228805\n",
      "Iteration 313, loss = 0.03246546\n",
      "Iteration 314, loss = 0.03237063\n",
      "Iteration 315, loss = 0.03134610\n",
      "Iteration 316, loss = 0.03080105\n",
      "Iteration 317, loss = 0.03412100\n",
      "Iteration 318, loss = 0.03356077\n",
      "Iteration 319, loss = 0.02933362\n",
      "Iteration 320, loss = 0.03080132\n",
      "Iteration 321, loss = 0.02968897\n",
      "Iteration 322, loss = 0.02976107\n",
      "Iteration 323, loss = 0.02888543\n",
      "Iteration 324, loss = 0.02912733\n",
      "Iteration 325, loss = 0.02946556\n",
      "Iteration 326, loss = 0.03339300\n",
      "Iteration 327, loss = 0.03222096\n",
      "Iteration 328, loss = 0.03123547\n",
      "Iteration 329, loss = 0.03558775\n",
      "Iteration 330, loss = 0.03065632\n",
      "Iteration 331, loss = 0.03016099\n",
      "Iteration 332, loss = 0.03151268\n",
      "Iteration 333, loss = 0.02995062\n",
      "Iteration 334, loss = 0.03268093\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;rbm&#x27;,\n",
       "                 BernoulliRBM(n_components=50, n_iter=25, random_state=0)),\n",
       "                (&#x27;mlp&#x27;,\n",
       "                 MLPClassifier(batch_size=50, hidden_layer_sizes=(37, 37),\n",
       "                               max_iter=1000, verbose=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;rbm&#x27;,\n",
       "                 BernoulliRBM(n_components=50, n_iter=25, random_state=0)),\n",
       "                (&#x27;mlp&#x27;,\n",
       "                 MLPClassifier(batch_size=50, hidden_layer_sizes=(37, 37),\n",
       "                               max_iter=1000, verbose=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BernoulliRBM<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.BernoulliRBM.html\">?<span>Documentation for BernoulliRBM</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>BernoulliRBM(n_components=50, n_iter=25, random_state=0)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(batch_size=50, hidden_layer_sizes=(37, 37), max_iter=1000,\n",
       "              verbose=1)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('rbm',\n",
       "                 BernoulliRBM(n_components=50, n_iter=25, random_state=0)),\n",
       "                ('mlp',\n",
       "                 MLPClassifier(batch_size=50, hidden_layer_sizes=(37, 37),\n",
       "                               max_iter=1000, verbose=1))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador_rbm = Pipeline(steps=[('rbm', rbm), ('mlp', mlp_rbm)])\n",
    "classificador_rbm.fit(previsores_treinamento, classe_treinamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332ecb04-a556-4f97-b547-d2d69f9a55b6",
   "metadata": {},
   "source": [
    "### Previsões usando rbm + mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "424fd76d-f8a9-494f-a7ab-17bf2c957d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes_rbm = classificador_rbm.predict(previsores_teste)\n",
    "precisao_rbm = metrics.accuracy_score(previsoes_rbm, classe_teste)\n",
    "precisao_rbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ab50ab-9e3b-4420-bb75-516e6d480c84",
   "metadata": {},
   "source": [
    "## Criação da rede neural simples sem aplicação de rbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e974f21b-c27e-484d-b9c1-629f904b87f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.29709207\n",
      "Iteration 2, loss = 1.98955132\n",
      "Iteration 3, loss = 1.60978386\n",
      "Iteration 4, loss = 1.15693512\n",
      "Iteration 5, loss = 0.79751130\n",
      "Iteration 6, loss = 0.57133705\n",
      "Iteration 7, loss = 0.43896326\n",
      "Iteration 8, loss = 0.35832610\n",
      "Iteration 9, loss = 0.29956323\n",
      "Iteration 10, loss = 0.26162296\n",
      "Iteration 11, loss = 0.23273030\n",
      "Iteration 12, loss = 0.20645656\n",
      "Iteration 13, loss = 0.19299108\n",
      "Iteration 14, loss = 0.17561953\n",
      "Iteration 15, loss = 0.16187304\n",
      "Iteration 16, loss = 0.15268833\n",
      "Iteration 17, loss = 0.14271888\n",
      "Iteration 18, loss = 0.13595041\n",
      "Iteration 19, loss = 0.12716892\n",
      "Iteration 20, loss = 0.11682642\n",
      "Iteration 21, loss = 0.11276603\n",
      "Iteration 22, loss = 0.10745614\n",
      "Iteration 23, loss = 0.10056440\n",
      "Iteration 24, loss = 0.09665030\n",
      "Iteration 25, loss = 0.09210748\n",
      "Iteration 26, loss = 0.09147813\n",
      "Iteration 27, loss = 0.08462994\n",
      "Iteration 28, loss = 0.08060215\n",
      "Iteration 29, loss = 0.08008596\n",
      "Iteration 30, loss = 0.07469682\n",
      "Iteration 31, loss = 0.07231216\n",
      "Iteration 32, loss = 0.06760716\n",
      "Iteration 33, loss = 0.06558619\n",
      "Iteration 34, loss = 0.06511631\n",
      "Iteration 35, loss = 0.06000372\n",
      "Iteration 36, loss = 0.05963083\n",
      "Iteration 37, loss = 0.05811399\n",
      "Iteration 38, loss = 0.05432999\n",
      "Iteration 39, loss = 0.05150493\n",
      "Iteration 40, loss = 0.05035031\n",
      "Iteration 41, loss = 0.05029199\n",
      "Iteration 42, loss = 0.04699066\n",
      "Iteration 43, loss = 0.04421410\n",
      "Iteration 44, loss = 0.04356599\n",
      "Iteration 45, loss = 0.04144984\n",
      "Iteration 46, loss = 0.03891472\n",
      "Iteration 47, loss = 0.03832277\n",
      "Iteration 48, loss = 0.04142315\n",
      "Iteration 49, loss = 0.03659243\n",
      "Iteration 50, loss = 0.03712436\n",
      "Iteration 51, loss = 0.03714649\n",
      "Iteration 52, loss = 0.03315940\n",
      "Iteration 53, loss = 0.03105791\n",
      "Iteration 54, loss = 0.03008900\n",
      "Iteration 55, loss = 0.02925373\n",
      "Iteration 56, loss = 0.02809824\n",
      "Iteration 57, loss = 0.02714816\n",
      "Iteration 58, loss = 0.02806273\n",
      "Iteration 59, loss = 0.02485165\n",
      "Iteration 60, loss = 0.02382232\n",
      "Iteration 61, loss = 0.02352792\n",
      "Iteration 62, loss = 0.02329508\n",
      "Iteration 63, loss = 0.02310046\n",
      "Iteration 64, loss = 0.02217278\n",
      "Iteration 65, loss = 0.02187948\n",
      "Iteration 66, loss = 0.02009005\n",
      "Iteration 67, loss = 0.02011824\n",
      "Iteration 68, loss = 0.01878520\n",
      "Iteration 69, loss = 0.01784985\n",
      "Iteration 70, loss = 0.01843067\n",
      "Iteration 71, loss = 0.01775191\n",
      "Iteration 72, loss = 0.01607603\n",
      "Iteration 73, loss = 0.01549940\n",
      "Iteration 74, loss = 0.01581911\n",
      "Iteration 75, loss = 0.01576026\n",
      "Iteration 76, loss = 0.01513210\n",
      "Iteration 77, loss = 0.01443171\n",
      "Iteration 78, loss = 0.01372675\n",
      "Iteration 79, loss = 0.01299696\n",
      "Iteration 80, loss = 0.01294137\n",
      "Iteration 81, loss = 0.01291794\n",
      "Iteration 82, loss = 0.01308695\n",
      "Iteration 83, loss = 0.01219449\n",
      "Iteration 84, loss = 0.01105747\n",
      "Iteration 85, loss = 0.01137500\n",
      "Iteration 86, loss = 0.01088575\n",
      "Iteration 87, loss = 0.01077318\n",
      "Iteration 88, loss = 0.00988464\n",
      "Iteration 89, loss = 0.00978536\n",
      "Iteration 90, loss = 0.00979176\n",
      "Iteration 91, loss = 0.00911414\n",
      "Iteration 92, loss = 0.00868060\n",
      "Iteration 93, loss = 0.00883514\n",
      "Iteration 94, loss = 0.00862836\n",
      "Iteration 95, loss = 0.00787461\n",
      "Iteration 96, loss = 0.00789132\n",
      "Iteration 97, loss = 0.00823294\n",
      "Iteration 98, loss = 0.00736147\n",
      "Iteration 99, loss = 0.00713548\n",
      "Iteration 100, loss = 0.00702590\n",
      "Iteration 101, loss = 0.00672053\n",
      "Iteration 102, loss = 0.00658461\n",
      "Iteration 103, loss = 0.00673351\n",
      "Iteration 104, loss = 0.00625089\n",
      "Iteration 105, loss = 0.00635579\n",
      "Iteration 106, loss = 0.00596933\n",
      "Iteration 107, loss = 0.00596033\n",
      "Iteration 108, loss = 0.00606597\n",
      "Iteration 109, loss = 0.00556919\n",
      "Iteration 110, loss = 0.00524073\n",
      "Iteration 111, loss = 0.00527552\n",
      "Iteration 112, loss = 0.00496663\n",
      "Iteration 113, loss = 0.00504717\n",
      "Iteration 114, loss = 0.00472563\n",
      "Iteration 115, loss = 0.00471606\n",
      "Iteration 116, loss = 0.00457951\n",
      "Iteration 117, loss = 0.00430984\n",
      "Iteration 118, loss = 0.00446828\n",
      "Iteration 119, loss = 0.00414822\n",
      "Iteration 120, loss = 0.00408729\n",
      "Iteration 121, loss = 0.00396577\n",
      "Iteration 122, loss = 0.00386387\n",
      "Iteration 123, loss = 0.00390337\n",
      "Iteration 124, loss = 0.00370681\n",
      "Iteration 125, loss = 0.00384011\n",
      "Iteration 126, loss = 0.00338914\n",
      "Iteration 127, loss = 0.00362926\n",
      "Iteration 128, loss = 0.00334907\n",
      "Iteration 129, loss = 0.00316437\n",
      "Iteration 130, loss = 0.00303589\n",
      "Iteration 131, loss = 0.00300512\n",
      "Iteration 132, loss = 0.00299529\n",
      "Iteration 133, loss = 0.00286434\n",
      "Iteration 134, loss = 0.00281323\n",
      "Iteration 135, loss = 0.00267155\n",
      "Iteration 136, loss = 0.00258996\n",
      "Iteration 137, loss = 0.00253754\n",
      "Iteration 138, loss = 0.00253778\n",
      "Iteration 139, loss = 0.00248131\n",
      "Iteration 140, loss = 0.00238025\n",
      "Iteration 141, loss = 0.00233821\n",
      "Iteration 142, loss = 0.00228047\n",
      "Iteration 143, loss = 0.00220375\n",
      "Iteration 144, loss = 0.00212018\n",
      "Iteration 145, loss = 0.00223241\n",
      "Iteration 146, loss = 0.00203151\n",
      "Iteration 147, loss = 0.00199871\n",
      "Iteration 148, loss = 0.00198035\n",
      "Iteration 149, loss = 0.00189453\n",
      "Iteration 150, loss = 0.00186536\n",
      "Iteration 151, loss = 0.00179004\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9805555555555555"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_simples = MLPClassifier(hidden_layer_sizes = (37, 37),\n",
    "                        activation = 'relu', \n",
    "                        solver = 'adam',\n",
    "                        batch_size = 50,\n",
    "                        max_iter = 1000,\n",
    "                        verbose = 1)\n",
    "mlp_simples.fit(previsores_treinamento, classe_treinamento)\n",
    "previsoes_mlp = mlp_simples.predict(previsores_teste)\n",
    "precisao_mlp = metrics.accuracy_score(previsoes_mlp, classe_teste)\n",
    "precisao_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15b8a678-798b-41d9-8a6c-98b4bc2fb5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparando os resultados, com RBM chegamos em 0.93 e sem RBM o percentual é de 0.98\n",
    "# Com isso chegamos a conclusão que usar RBM com essa base de dados e com redes\n",
    "# neurais piora os resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
