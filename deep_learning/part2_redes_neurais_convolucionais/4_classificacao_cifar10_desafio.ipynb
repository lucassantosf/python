{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d85a14fd-5031-447e-a739-19a5f9ed18e4",
   "metadata": {},
   "source": [
    "# MNIST Simples\n",
    "\n",
    "Não tem base de dados externa, é importado a base de dados internamento do tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5aee0f-a2da-4ae8-bd6f-94fdd1064281",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a0ff0d-c9ce-4ad2-bad4-589b6c0901af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "220a5ecf-2816-4c6c-af16-5653eff133f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacao desta lib para desativar erro no TensorFlow\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adbd4a8b-e734-486e-af62-a902da952e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 16:01:06.480770: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-13 16:01:06.483965: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-13 16:01:06.530197: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-13 16:01:07.449718: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d021dc6f-a9c2-4dad-b201-ba060a576239",
   "metadata": {},
   "source": [
    "## Importando base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be641d4a-14f0-49ce-9541-72a0d4076d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34bf13a4-fef7-4cdb-8a29-2e9239849314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59,  62,  63],\n",
       "         [ 43,  46,  45],\n",
       "         [ 50,  48,  43],\n",
       "         ...,\n",
       "         [158, 132, 108],\n",
       "         [152, 125, 102],\n",
       "         [148, 124, 103]],\n",
       "\n",
       "        [[ 16,  20,  20],\n",
       "         [  0,   0,   0],\n",
       "         [ 18,   8,   0],\n",
       "         ...,\n",
       "         [123,  88,  55],\n",
       "         [119,  83,  50],\n",
       "         [122,  87,  57]],\n",
       "\n",
       "        [[ 25,  24,  21],\n",
       "         [ 16,   7,   0],\n",
       "         [ 49,  27,   8],\n",
       "         ...,\n",
       "         [118,  84,  50],\n",
       "         [120,  84,  50],\n",
       "         [109,  73,  42]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208, 170,  96],\n",
       "         [201, 153,  34],\n",
       "         [198, 161,  26],\n",
       "         ...,\n",
       "         [160, 133,  70],\n",
       "         [ 56,  31,   7],\n",
       "         [ 53,  34,  20]],\n",
       "\n",
       "        [[180, 139,  96],\n",
       "         [173, 123,  42],\n",
       "         [186, 144,  30],\n",
       "         ...,\n",
       "         [184, 148,  94],\n",
       "         [ 97,  62,  34],\n",
       "         [ 83,  53,  34]],\n",
       "\n",
       "        [[177, 144, 116],\n",
       "         [168, 129,  94],\n",
       "         [179, 142,  87],\n",
       "         ...,\n",
       "         [216, 184, 140],\n",
       "         [151, 118,  84],\n",
       "         [123,  92,  72]]],\n",
       "\n",
       "\n",
       "       [[[154, 177, 187],\n",
       "         [126, 137, 136],\n",
       "         [105, 104,  95],\n",
       "         ...,\n",
       "         [ 91,  95,  71],\n",
       "         [ 87,  90,  71],\n",
       "         [ 79,  81,  70]],\n",
       "\n",
       "        [[140, 160, 169],\n",
       "         [145, 153, 154],\n",
       "         [125, 125, 118],\n",
       "         ...,\n",
       "         [ 96,  99,  78],\n",
       "         [ 77,  80,  62],\n",
       "         [ 71,  73,  61]],\n",
       "\n",
       "        [[140, 155, 164],\n",
       "         [139, 146, 149],\n",
       "         [115, 115, 112],\n",
       "         ...,\n",
       "         [ 79,  82,  64],\n",
       "         [ 68,  70,  55],\n",
       "         [ 67,  69,  55]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175, 167, 166],\n",
       "         [156, 154, 160],\n",
       "         [154, 160, 170],\n",
       "         ...,\n",
       "         [ 42,  34,  36],\n",
       "         [ 61,  53,  57],\n",
       "         [ 93,  83,  91]],\n",
       "\n",
       "        [[165, 154, 128],\n",
       "         [156, 152, 130],\n",
       "         [159, 161, 142],\n",
       "         ...,\n",
       "         [103,  93,  96],\n",
       "         [123, 114, 120],\n",
       "         [131, 121, 131]],\n",
       "\n",
       "        [[163, 148, 120],\n",
       "         [158, 148, 122],\n",
       "         [163, 156, 133],\n",
       "         ...,\n",
       "         [143, 133, 139],\n",
       "         [143, 134, 142],\n",
       "         [143, 133, 144]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[113, 120, 112],\n",
       "         [111, 118, 111],\n",
       "         [105, 112, 106],\n",
       "         ...,\n",
       "         [ 72,  81,  80],\n",
       "         [ 72,  80,  79],\n",
       "         [ 72,  80,  79]],\n",
       "\n",
       "        [[111, 118, 110],\n",
       "         [104, 111, 104],\n",
       "         [ 99, 106,  98],\n",
       "         ...,\n",
       "         [ 68,  75,  73],\n",
       "         [ 70,  76,  75],\n",
       "         [ 78,  84,  82]],\n",
       "\n",
       "        [[106, 113, 105],\n",
       "         [ 99, 106,  98],\n",
       "         [ 95, 102,  94],\n",
       "         ...,\n",
       "         [ 78,  85,  83],\n",
       "         [ 79,  85,  83],\n",
       "         [ 80,  86,  84]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 35, 178, 235],\n",
       "         [ 40, 176, 239],\n",
       "         [ 42, 176, 241],\n",
       "         ...,\n",
       "         [ 99, 177, 219],\n",
       "         [ 79, 147, 197],\n",
       "         [ 89, 148, 189]],\n",
       "\n",
       "        [[ 57, 182, 234],\n",
       "         [ 44, 184, 250],\n",
       "         [ 50, 183, 240],\n",
       "         ...,\n",
       "         [156, 182, 200],\n",
       "         [141, 177, 206],\n",
       "         [116, 149, 175]],\n",
       "\n",
       "        [[ 98, 197, 237],\n",
       "         [ 64, 189, 252],\n",
       "         [ 69, 192, 245],\n",
       "         ...,\n",
       "         [188, 195, 206],\n",
       "         [119, 135, 147],\n",
       "         [ 61,  79,  90]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 73,  79,  77],\n",
       "         [ 53,  63,  68],\n",
       "         [ 54,  68,  80],\n",
       "         ...,\n",
       "         [ 17,  40,  64],\n",
       "         [ 21,  36,  51],\n",
       "         [ 33,  48,  49]],\n",
       "\n",
       "        [[ 61,  68,  75],\n",
       "         [ 55,  70,  86],\n",
       "         [ 57,  79, 103],\n",
       "         ...,\n",
       "         [ 24,  48,  72],\n",
       "         [ 17,  35,  53],\n",
       "         [  7,  23,  32]],\n",
       "\n",
       "        [[ 44,  56,  73],\n",
       "         [ 46,  66,  88],\n",
       "         [ 49,  77, 105],\n",
       "         ...,\n",
       "         [ 27,  52,  77],\n",
       "         [ 21,  43,  66],\n",
       "         [ 12,  31,  50]]],\n",
       "\n",
       "\n",
       "       [[[189, 211, 240],\n",
       "         [186, 208, 236],\n",
       "         [185, 207, 235],\n",
       "         ...,\n",
       "         [175, 195, 224],\n",
       "         [172, 194, 222],\n",
       "         [169, 194, 220]],\n",
       "\n",
       "        [[194, 210, 239],\n",
       "         [191, 207, 236],\n",
       "         [190, 206, 235],\n",
       "         ...,\n",
       "         [173, 192, 220],\n",
       "         [171, 191, 218],\n",
       "         [167, 190, 216]],\n",
       "\n",
       "        [[208, 219, 244],\n",
       "         [205, 216, 240],\n",
       "         [204, 215, 239],\n",
       "         ...,\n",
       "         [175, 191, 217],\n",
       "         [172, 190, 216],\n",
       "         [169, 191, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[207, 199, 181],\n",
       "         [203, 195, 175],\n",
       "         [203, 196, 173],\n",
       "         ...,\n",
       "         [135, 132, 127],\n",
       "         [162, 158, 150],\n",
       "         [168, 163, 151]],\n",
       "\n",
       "        [[198, 190, 170],\n",
       "         [189, 181, 159],\n",
       "         [180, 172, 147],\n",
       "         ...,\n",
       "         [178, 171, 160],\n",
       "         [175, 169, 156],\n",
       "         [175, 169, 154]],\n",
       "\n",
       "        [[198, 189, 173],\n",
       "         [189, 181, 162],\n",
       "         [178, 170, 149],\n",
       "         ...,\n",
       "         [195, 184, 169],\n",
       "         [196, 189, 171],\n",
       "         [195, 190, 171]]],\n",
       "\n",
       "\n",
       "       [[[229, 229, 239],\n",
       "         [236, 237, 247],\n",
       "         [234, 236, 247],\n",
       "         ...,\n",
       "         [217, 219, 233],\n",
       "         [221, 223, 234],\n",
       "         [222, 223, 233]],\n",
       "\n",
       "        [[222, 221, 229],\n",
       "         [239, 239, 249],\n",
       "         [233, 234, 246],\n",
       "         ...,\n",
       "         [223, 223, 236],\n",
       "         [227, 228, 238],\n",
       "         [210, 211, 220]],\n",
       "\n",
       "        [[213, 206, 211],\n",
       "         [234, 232, 239],\n",
       "         [231, 233, 244],\n",
       "         ...,\n",
       "         [220, 220, 232],\n",
       "         [220, 219, 232],\n",
       "         [202, 203, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[150, 143, 135],\n",
       "         [140, 135, 127],\n",
       "         [132, 127, 120],\n",
       "         ...,\n",
       "         [224, 222, 218],\n",
       "         [230, 228, 225],\n",
       "         [241, 241, 238]],\n",
       "\n",
       "        [[137, 132, 126],\n",
       "         [130, 127, 120],\n",
       "         [125, 121, 115],\n",
       "         ...,\n",
       "         [181, 180, 178],\n",
       "         [202, 201, 198],\n",
       "         [212, 211, 207]],\n",
       "\n",
       "        [[122, 119, 114],\n",
       "         [118, 116, 110],\n",
       "         [120, 116, 111],\n",
       "         ...,\n",
       "         [179, 177, 173],\n",
       "         [164, 164, 162],\n",
       "         [163, 163, 161]]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20feaa36-6704-4538-a11f-32f4afa5dac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 1), (10000, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d30795a-83c2-4b06-9502-3a3216ef7f68",
   "metadata": {},
   "source": [
    "## Pré-preparamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "204b233b-061f-4e68-ab4e-655e95b441ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255.0  # Normalizando os valores para o intervalo [0, 1]\n",
    "X_test = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c28efc5e-4e09-469d-a15c-642c267e4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)  # One-hot encoding para as labels\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72cc8107-e4be-4606-9231-9bf562c76b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e792568-7f21-46e7-b0e2-645f7f828eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 10), (10000, 10))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e93fa782-1547-4dbb-9386-3c702477db80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.23137255, 0.24313726, 0.24705882],\n",
       "         [0.16862746, 0.18039216, 0.1764706 ],\n",
       "         [0.19607843, 0.1882353 , 0.16862746],\n",
       "         ...,\n",
       "         [0.61960787, 0.5176471 , 0.42352942],\n",
       "         [0.59607846, 0.49019608, 0.4       ],\n",
       "         [0.5803922 , 0.4862745 , 0.40392157]],\n",
       "\n",
       "        [[0.0627451 , 0.07843138, 0.07843138],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.07058824, 0.03137255, 0.        ],\n",
       "         ...,\n",
       "         [0.48235294, 0.34509805, 0.21568628],\n",
       "         [0.46666667, 0.3254902 , 0.19607843],\n",
       "         [0.47843137, 0.34117648, 0.22352941]],\n",
       "\n",
       "        [[0.09803922, 0.09411765, 0.08235294],\n",
       "         [0.0627451 , 0.02745098, 0.        ],\n",
       "         [0.19215687, 0.10588235, 0.03137255],\n",
       "         ...,\n",
       "         [0.4627451 , 0.32941177, 0.19607843],\n",
       "         [0.47058824, 0.32941177, 0.19607843],\n",
       "         [0.42745098, 0.28627452, 0.16470589]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8156863 , 0.6666667 , 0.3764706 ],\n",
       "         [0.7882353 , 0.6       , 0.13333334],\n",
       "         [0.7764706 , 0.6313726 , 0.10196079],\n",
       "         ...,\n",
       "         [0.627451  , 0.52156866, 0.27450982],\n",
       "         [0.21960784, 0.12156863, 0.02745098],\n",
       "         [0.20784314, 0.13333334, 0.07843138]],\n",
       "\n",
       "        [[0.7058824 , 0.54509807, 0.3764706 ],\n",
       "         [0.6784314 , 0.48235294, 0.16470589],\n",
       "         [0.7294118 , 0.5647059 , 0.11764706],\n",
       "         ...,\n",
       "         [0.72156864, 0.5803922 , 0.36862746],\n",
       "         [0.38039216, 0.24313726, 0.13333334],\n",
       "         [0.3254902 , 0.20784314, 0.13333334]],\n",
       "\n",
       "        [[0.69411767, 0.5647059 , 0.45490196],\n",
       "         [0.65882355, 0.5058824 , 0.36862746],\n",
       "         [0.7019608 , 0.5568628 , 0.34117648],\n",
       "         ...,\n",
       "         [0.84705883, 0.72156864, 0.54901963],\n",
       "         [0.5921569 , 0.4627451 , 0.32941177],\n",
       "         [0.48235294, 0.36078432, 0.28235295]]],\n",
       "\n",
       "\n",
       "       [[[0.6039216 , 0.69411767, 0.73333335],\n",
       "         [0.49411765, 0.5372549 , 0.53333336],\n",
       "         [0.4117647 , 0.40784314, 0.37254903],\n",
       "         ...,\n",
       "         [0.35686275, 0.37254903, 0.2784314 ],\n",
       "         [0.34117648, 0.3529412 , 0.2784314 ],\n",
       "         [0.30980393, 0.31764707, 0.27450982]],\n",
       "\n",
       "        [[0.54901963, 0.627451  , 0.6627451 ],\n",
       "         [0.5686275 , 0.6       , 0.6039216 ],\n",
       "         [0.49019608, 0.49019608, 0.4627451 ],\n",
       "         ...,\n",
       "         [0.3764706 , 0.3882353 , 0.30588236],\n",
       "         [0.3019608 , 0.3137255 , 0.24313726],\n",
       "         [0.2784314 , 0.28627452, 0.23921569]],\n",
       "\n",
       "        [[0.54901963, 0.60784316, 0.6431373 ],\n",
       "         [0.54509807, 0.57254905, 0.58431375],\n",
       "         [0.4509804 , 0.4509804 , 0.4392157 ],\n",
       "         ...,\n",
       "         [0.30980393, 0.32156864, 0.2509804 ],\n",
       "         [0.26666668, 0.27450982, 0.21568628],\n",
       "         [0.2627451 , 0.27058825, 0.21568628]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6862745 , 0.654902  , 0.6509804 ],\n",
       "         [0.6117647 , 0.6039216 , 0.627451  ],\n",
       "         [0.6039216 , 0.627451  , 0.6666667 ],\n",
       "         ...,\n",
       "         [0.16470589, 0.13333334, 0.14117648],\n",
       "         [0.23921569, 0.20784314, 0.22352941],\n",
       "         [0.3647059 , 0.3254902 , 0.35686275]],\n",
       "\n",
       "        [[0.64705884, 0.6039216 , 0.5019608 ],\n",
       "         [0.6117647 , 0.59607846, 0.50980395],\n",
       "         [0.62352943, 0.6313726 , 0.5568628 ],\n",
       "         ...,\n",
       "         [0.40392157, 0.3647059 , 0.3764706 ],\n",
       "         [0.48235294, 0.44705883, 0.47058824],\n",
       "         [0.5137255 , 0.4745098 , 0.5137255 ]],\n",
       "\n",
       "        [[0.6392157 , 0.5803922 , 0.47058824],\n",
       "         [0.61960787, 0.5803922 , 0.47843137],\n",
       "         [0.6392157 , 0.6117647 , 0.52156866],\n",
       "         ...,\n",
       "         [0.56078434, 0.52156866, 0.54509807],\n",
       "         [0.56078434, 0.5254902 , 0.5568628 ],\n",
       "         [0.56078434, 0.52156866, 0.5647059 ]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.44313726, 0.47058824, 0.4392157 ],\n",
       "         [0.43529412, 0.4627451 , 0.43529412],\n",
       "         [0.4117647 , 0.4392157 , 0.41568628],\n",
       "         ...,\n",
       "         [0.28235295, 0.31764707, 0.3137255 ],\n",
       "         [0.28235295, 0.3137255 , 0.30980393],\n",
       "         [0.28235295, 0.3137255 , 0.30980393]],\n",
       "\n",
       "        [[0.43529412, 0.4627451 , 0.43137255],\n",
       "         [0.40784314, 0.43529412, 0.40784314],\n",
       "         [0.3882353 , 0.41568628, 0.38431373],\n",
       "         ...,\n",
       "         [0.26666668, 0.29411766, 0.28627452],\n",
       "         [0.27450982, 0.29803923, 0.29411766],\n",
       "         [0.30588236, 0.32941177, 0.32156864]],\n",
       "\n",
       "        [[0.41568628, 0.44313726, 0.4117647 ],\n",
       "         [0.3882353 , 0.41568628, 0.38431373],\n",
       "         [0.37254903, 0.4       , 0.36862746],\n",
       "         ...,\n",
       "         [0.30588236, 0.33333334, 0.3254902 ],\n",
       "         [0.30980393, 0.33333334, 0.3254902 ],\n",
       "         [0.3137255 , 0.3372549 , 0.32941177]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.13725491, 0.69803923, 0.92156863],\n",
       "         [0.15686275, 0.6901961 , 0.9372549 ],\n",
       "         [0.16470589, 0.6901961 , 0.94509804],\n",
       "         ...,\n",
       "         [0.3882353 , 0.69411767, 0.85882354],\n",
       "         [0.30980393, 0.5764706 , 0.77254903],\n",
       "         [0.34901962, 0.5803922 , 0.7411765 ]],\n",
       "\n",
       "        [[0.22352941, 0.7137255 , 0.91764706],\n",
       "         [0.17254902, 0.72156864, 0.98039216],\n",
       "         [0.19607843, 0.7176471 , 0.9411765 ],\n",
       "         ...,\n",
       "         [0.6117647 , 0.7137255 , 0.78431374],\n",
       "         [0.5529412 , 0.69411767, 0.80784315],\n",
       "         [0.45490196, 0.58431375, 0.6862745 ]],\n",
       "\n",
       "        [[0.38431373, 0.77254903, 0.92941177],\n",
       "         [0.2509804 , 0.7411765 , 0.9882353 ],\n",
       "         [0.27058825, 0.7529412 , 0.9607843 ],\n",
       "         ...,\n",
       "         [0.7372549 , 0.7647059 , 0.80784315],\n",
       "         [0.46666667, 0.5294118 , 0.5764706 ],\n",
       "         [0.23921569, 0.30980393, 0.3529412 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.28627452, 0.30980393, 0.3019608 ],\n",
       "         [0.20784314, 0.24705882, 0.26666668],\n",
       "         [0.21176471, 0.26666668, 0.3137255 ],\n",
       "         ...,\n",
       "         [0.06666667, 0.15686275, 0.2509804 ],\n",
       "         [0.08235294, 0.14117648, 0.2       ],\n",
       "         [0.12941177, 0.1882353 , 0.19215687]],\n",
       "\n",
       "        [[0.23921569, 0.26666668, 0.29411766],\n",
       "         [0.21568628, 0.27450982, 0.3372549 ],\n",
       "         [0.22352941, 0.30980393, 0.40392157],\n",
       "         ...,\n",
       "         [0.09411765, 0.1882353 , 0.28235295],\n",
       "         [0.06666667, 0.13725491, 0.20784314],\n",
       "         [0.02745098, 0.09019608, 0.1254902 ]],\n",
       "\n",
       "        [[0.17254902, 0.21960784, 0.28627452],\n",
       "         [0.18039216, 0.25882354, 0.34509805],\n",
       "         [0.19215687, 0.3019608 , 0.4117647 ],\n",
       "         ...,\n",
       "         [0.10588235, 0.20392157, 0.3019608 ],\n",
       "         [0.08235294, 0.16862746, 0.25882354],\n",
       "         [0.04705882, 0.12156863, 0.19607843]]],\n",
       "\n",
       "\n",
       "       [[[0.7411765 , 0.827451  , 0.9411765 ],\n",
       "         [0.7294118 , 0.8156863 , 0.9254902 ],\n",
       "         [0.7254902 , 0.8117647 , 0.92156863],\n",
       "         ...,\n",
       "         [0.6862745 , 0.7647059 , 0.8784314 ],\n",
       "         [0.6745098 , 0.7607843 , 0.87058824],\n",
       "         [0.6627451 , 0.7607843 , 0.8627451 ]],\n",
       "\n",
       "        [[0.7607843 , 0.8235294 , 0.9372549 ],\n",
       "         [0.7490196 , 0.8117647 , 0.9254902 ],\n",
       "         [0.74509805, 0.80784315, 0.92156863],\n",
       "         ...,\n",
       "         [0.6784314 , 0.7529412 , 0.8627451 ],\n",
       "         [0.67058825, 0.7490196 , 0.85490197],\n",
       "         [0.654902  , 0.74509805, 0.84705883]],\n",
       "\n",
       "        [[0.8156863 , 0.85882354, 0.95686275],\n",
       "         [0.8039216 , 0.84705883, 0.9411765 ],\n",
       "         [0.8       , 0.84313726, 0.9372549 ],\n",
       "         ...,\n",
       "         [0.6862745 , 0.7490196 , 0.8509804 ],\n",
       "         [0.6745098 , 0.74509805, 0.84705883],\n",
       "         [0.6627451 , 0.7490196 , 0.84313726]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8117647 , 0.78039217, 0.70980394],\n",
       "         [0.79607844, 0.7647059 , 0.6862745 ],\n",
       "         [0.79607844, 0.76862746, 0.6784314 ],\n",
       "         ...,\n",
       "         [0.5294118 , 0.5176471 , 0.49803922],\n",
       "         [0.63529414, 0.61960787, 0.5882353 ],\n",
       "         [0.65882355, 0.6392157 , 0.5921569 ]],\n",
       "\n",
       "        [[0.7764706 , 0.74509805, 0.6666667 ],\n",
       "         [0.7411765 , 0.70980394, 0.62352943],\n",
       "         [0.7058824 , 0.6745098 , 0.5764706 ],\n",
       "         ...,\n",
       "         [0.69803923, 0.67058825, 0.627451  ],\n",
       "         [0.6862745 , 0.6627451 , 0.6117647 ],\n",
       "         [0.6862745 , 0.6627451 , 0.6039216 ]],\n",
       "\n",
       "        [[0.7764706 , 0.7411765 , 0.6784314 ],\n",
       "         [0.7411765 , 0.70980394, 0.63529414],\n",
       "         [0.69803923, 0.6666667 , 0.58431375],\n",
       "         ...,\n",
       "         [0.7647059 , 0.72156864, 0.6627451 ],\n",
       "         [0.76862746, 0.7411765 , 0.67058825],\n",
       "         [0.7647059 , 0.74509805, 0.67058825]]],\n",
       "\n",
       "\n",
       "       [[[0.8980392 , 0.8980392 , 0.9372549 ],\n",
       "         [0.9254902 , 0.92941177, 0.96862745],\n",
       "         [0.91764706, 0.9254902 , 0.96862745],\n",
       "         ...,\n",
       "         [0.8509804 , 0.85882354, 0.9137255 ],\n",
       "         [0.8666667 , 0.8745098 , 0.91764706],\n",
       "         [0.87058824, 0.8745098 , 0.9137255 ]],\n",
       "\n",
       "        [[0.87058824, 0.8666667 , 0.8980392 ],\n",
       "         [0.9372549 , 0.9372549 , 0.9764706 ],\n",
       "         [0.9137255 , 0.91764706, 0.9647059 ],\n",
       "         ...,\n",
       "         [0.8745098 , 0.8745098 , 0.9254902 ],\n",
       "         [0.8901961 , 0.89411765, 0.93333334],\n",
       "         [0.8235294 , 0.827451  , 0.8627451 ]],\n",
       "\n",
       "        [[0.8352941 , 0.80784315, 0.827451  ],\n",
       "         [0.91764706, 0.9098039 , 0.9372549 ],\n",
       "         [0.90588236, 0.9137255 , 0.95686275],\n",
       "         ...,\n",
       "         [0.8627451 , 0.8627451 , 0.9098039 ],\n",
       "         [0.8627451 , 0.85882354, 0.9098039 ],\n",
       "         [0.7921569 , 0.79607844, 0.84313726]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5882353 , 0.56078434, 0.5294118 ],\n",
       "         [0.54901963, 0.5294118 , 0.49803922],\n",
       "         [0.5176471 , 0.49803922, 0.47058824],\n",
       "         ...,\n",
       "         [0.8784314 , 0.87058824, 0.85490197],\n",
       "         [0.9019608 , 0.89411765, 0.88235295],\n",
       "         [0.94509804, 0.94509804, 0.93333334]],\n",
       "\n",
       "        [[0.5372549 , 0.5176471 , 0.49411765],\n",
       "         [0.50980395, 0.49803922, 0.47058824],\n",
       "         [0.49019608, 0.4745098 , 0.4509804 ],\n",
       "         ...,\n",
       "         [0.70980394, 0.7058824 , 0.69803923],\n",
       "         [0.7921569 , 0.7882353 , 0.7764706 ],\n",
       "         [0.83137256, 0.827451  , 0.8117647 ]],\n",
       "\n",
       "        [[0.47843137, 0.46666667, 0.44705883],\n",
       "         [0.4627451 , 0.45490196, 0.43137255],\n",
       "         [0.47058824, 0.45490196, 0.43529412],\n",
       "         ...,\n",
       "         [0.7019608 , 0.69411767, 0.6784314 ],\n",
       "         [0.6431373 , 0.6431373 , 0.63529414],\n",
       "         [0.6392157 , 0.6392157 , 0.6313726 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2836d29-e322-4565-bc7d-af7c5965a93c",
   "metadata": {},
   "source": [
    "## Estrutura da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f6264f6-f8fa-4ee3-80ef-1fc729d6622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8360e47-267b-4613-94bf-cac96e7f6017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m295,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">315,722</span> (1.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m315,722\u001b[0m (1.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">315,722</span> (1.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m315,722\u001b[0m (1.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5f6d4ac-a0af-4cc7-815c-010c8c432f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03ec64af-d909-462b-b12f-5642782c0e3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 16:01:37.271226: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 31ms/step - accuracy: 0.2848 - loss: 1.9254 - val_accuracy: 0.5172 - val_loss: 1.3614\n",
      "Epoch 2/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 56ms/step - accuracy: 0.4779 - loss: 1.4492 - val_accuracy: 0.5913 - val_loss: 1.1935\n",
      "Epoch 3/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 48ms/step - accuracy: 0.5378 - loss: 1.2987 - val_accuracy: 0.6134 - val_loss: 1.1290\n",
      "Epoch 4/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 57ms/step - accuracy: 0.5694 - loss: 1.2128 - val_accuracy: 0.6436 - val_loss: 1.0403\n",
      "Epoch 5/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 67ms/step - accuracy: 0.5938 - loss: 1.1513 - val_accuracy: 0.6489 - val_loss: 1.0172\n",
      "Epoch 6/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 29ms/step - accuracy: 0.6126 - loss: 1.1059 - val_accuracy: 0.6624 - val_loss: 0.9732\n",
      "Epoch 7/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 69ms/step - accuracy: 0.6272 - loss: 1.0744 - val_accuracy: 0.6575 - val_loss: 0.9698\n",
      "Epoch 8/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 50ms/step - accuracy: 0.6337 - loss: 1.0471 - val_accuracy: 0.6751 - val_loss: 0.9331\n",
      "Epoch 9/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.6424 - loss: 1.0232 - val_accuracy: 0.6878 - val_loss: 0.9022\n",
      "Epoch 10/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.6516 - loss: 0.9974 - val_accuracy: 0.6948 - val_loss: 0.8903\n",
      "Epoch 11/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - accuracy: 0.6508 - loss: 0.9879 - val_accuracy: 0.6988 - val_loss: 0.8653\n",
      "Epoch 12/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 29ms/step - accuracy: 0.6626 - loss: 0.9741 - val_accuracy: 0.6935 - val_loss: 0.8659\n",
      "Epoch 13/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.6662 - loss: 0.9494 - val_accuracy: 0.6913 - val_loss: 0.8850\n",
      "Epoch 14/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 28ms/step - accuracy: 0.6721 - loss: 0.9379 - val_accuracy: 0.7089 - val_loss: 0.8400\n",
      "Epoch 15/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.6736 - loss: 0.9318 - val_accuracy: 0.7115 - val_loss: 0.8317\n",
      "Epoch 16/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.6806 - loss: 0.9034 - val_accuracy: 0.7110 - val_loss: 0.8304\n",
      "Epoch 17/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 33ms/step - accuracy: 0.6840 - loss: 0.8857 - val_accuracy: 0.7170 - val_loss: 0.8152\n",
      "Epoch 18/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.6914 - loss: 0.8823 - val_accuracy: 0.7089 - val_loss: 0.8378\n",
      "Epoch 19/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.6920 - loss: 0.8663 - val_accuracy: 0.7144 - val_loss: 0.8261\n",
      "Epoch 20/20\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.6920 - loss: 0.8710 - val_accuracy: 0.7219 - val_loss: 0.8078\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=20,  # Você pode ajustar o número de épocas\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55e91ba1-e7a0-4244-ad07-e8045a3b8735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 4ms/step - accuracy: 0.7219 - loss: 0.8078\n",
      "Acurácia no conjunto de teste: 0.72\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Acurácia no conjunto de teste: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae5406-d793-42a9-8b11-182d32701816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
