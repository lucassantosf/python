{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb6e90a-ae5d-4b14-99d0-3c668cd779da",
   "metadata": {},
   "source": [
    "# Previsão temporal - preços da bolsa de valores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad8eeeb-bbbb-4fb2-8d17-95cdb23165bd",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e184b0e-32a4-4805-a47f-4e7e499ca278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacao desta lib para desativar erro no TensorFlow\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5674851-e883-4e2b-8a46-191012c19f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 18:44:13.804543: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-10 18:44:13.808080: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-10 18:44:13.856197: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-10 18:44:14.754649: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f5ef04c-bb08-4940-abf8-180a2b76d996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.26.4', '2.2.2', '2.16.1', '3.8.4', '1.4.2')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__, pd.__version__, tf.__version__, matplotlib.__version__, sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8814e86d-2c49-444a-ad93-ed0144a2f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5613a-a694-4474-a8b8-53dae35bfe6d",
   "metadata": {},
   "source": [
    "## Carregamento base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aae312f5-ada8-4af3-80ac-2b4c83586e27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>20.209999</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>18.086271</td>\n",
       "      <td>30182600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>19.809999</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>18.738441</td>\n",
       "      <td>30552600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>20.330000</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>20.170000</td>\n",
       "      <td>20.430000</td>\n",
       "      <td>18.766001</td>\n",
       "      <td>36141000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>20.480000</td>\n",
       "      <td>20.670000</td>\n",
       "      <td>19.950001</td>\n",
       "      <td>20.080000</td>\n",
       "      <td>18.444506</td>\n",
       "      <td>28069600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.230000</td>\n",
       "      <td>19.459999</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>17.911745</td>\n",
       "      <td>29091300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>2017-12-25</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.718563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.990000</td>\n",
       "      <td>15.690000</td>\n",
       "      <td>15.970000</td>\n",
       "      <td>15.938125</td>\n",
       "      <td>22173100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>15.990000</td>\n",
       "      <td>16.139999</td>\n",
       "      <td>15.980000</td>\n",
       "      <td>16.049999</td>\n",
       "      <td>16.017963</td>\n",
       "      <td>23552200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.129999</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.067865</td>\n",
       "      <td>19011500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.067865</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1245 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Open       High        Low      Close  Adj Close  \\\n",
       "0     2013-01-02  19.990000  20.209999  19.690001  19.690001  18.086271   \n",
       "1     2013-01-03  19.809999  20.400000  19.700001  20.400000  18.738441   \n",
       "2     2013-01-04  20.330000  20.620001  20.170000  20.430000  18.766001   \n",
       "3     2013-01-07  20.480000  20.670000  19.950001  20.080000  18.444506   \n",
       "4     2013-01-08  20.110001  20.230000  19.459999  19.500000  17.911745   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "1240  2017-12-25  15.750000  15.750000  15.750000  15.750000  15.718563   \n",
       "1241  2017-12-26  15.750000  15.990000  15.690000  15.970000  15.938125   \n",
       "1242  2017-12-27  15.990000  16.139999  15.980000  16.049999  16.017963   \n",
       "1243  2017-12-28  16.100000  16.129999  16.000000  16.100000  16.067865   \n",
       "1244  2017-12-29  16.100000  16.100000  16.100000  16.100000  16.067865   \n",
       "\n",
       "          Volume  \n",
       "0     30182600.0  \n",
       "1     30552600.0  \n",
       "2     36141000.0  \n",
       "3     28069600.0  \n",
       "4     29091300.0  \n",
       "...          ...  \n",
       "1240         0.0  \n",
       "1241  22173100.0  \n",
       "1242  23552200.0  \n",
       "1243  19011500.0  \n",
       "1244         0.0  \n",
       "\n",
       "[1245 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = pd.read_csv('petr4-treinamento.csv')\n",
    "base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15301b20-af73-404b-8707-c857c46b2495",
   "metadata": {},
   "source": [
    "## Verificar se há dados faltantes na base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e97a554e-a1e9-45c4-b279-f86753f9237b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         3\n",
       "High         3\n",
       "Low          3\n",
       "Close        3\n",
       "Adj Close    3\n",
       "Volume       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b27fcaaa-881b-4ced-a111-66d50b7055cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = base.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b0dbf1-6b31-4f97-8263-a01560afc82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21367f52-0024-4a89-89e8-89bcbb8889ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7cb5730-f533-482c-9d61-f71849ee81f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_treinamento = base.iloc[:,1:7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3728f64-fabd-4a2b-a179-ab9680c98282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9990000e+01, 2.0209999e+01, 1.9690001e+01, 1.9690001e+01,\n",
       "        1.8086271e+01, 3.0182600e+07],\n",
       "       [1.9809999e+01, 2.0400000e+01, 1.9700001e+01, 2.0400000e+01,\n",
       "        1.8738441e+01, 3.0552600e+07],\n",
       "       [2.0330000e+01, 2.0620001e+01, 2.0170000e+01, 2.0430000e+01,\n",
       "        1.8766001e+01, 3.6141000e+07],\n",
       "       ...,\n",
       "       [1.5990000e+01, 1.6139999e+01, 1.5980000e+01, 1.6049999e+01,\n",
       "        1.6017963e+01, 2.3552200e+07],\n",
       "       [1.6100000e+01, 1.6129999e+01, 1.6000000e+01, 1.6100000e+01,\n",
       "        1.6067865e+01, 1.9011500e+07],\n",
       "       [1.6100000e+01, 1.6100000e+01, 1.6100000e+01, 1.6100000e+01,\n",
       "        1.6067865e+01, 0.0000000e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d10896a-fdf6-47a6-86e3-d690ea29614b",
   "metadata": {},
   "source": [
    "## Normalização dos dados - escalonamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98e237a4-5905-4d6f-bec6-4ed4c2a13e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76501938, 0.77266112, 0.79682707, 0.76080559, 0.6838135 ,\n",
       "        0.04318274],\n",
       "       [0.7562984 , 0.78187106, 0.79733884, 0.79567784, 0.71590949,\n",
       "        0.0437121 ],\n",
       "       [0.78149225, 0.79253519, 0.82139202, 0.79715132, 0.71726583,\n",
       "        0.05170752],\n",
       "       ...,\n",
       "       [0.57122093, 0.57537562, 0.60696008, 0.58202356, 0.58202349,\n",
       "        0.03369652],\n",
       "       [0.57655039, 0.57489089, 0.60798362, 0.5844794 , 0.58447937,\n",
       "        0.02720006],\n",
       "       [0.57655039, 0.57343674, 0.61310133, 0.5844794 , 0.58447937,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizador = MinMaxScaler(feature_range=(0,1))\n",
    "base_treinamento_normalizada = normalizador.fit_transform(base_treinamento)\n",
    "base_treinamento_normalizada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cee5a9-740a-413c-974d-11c6b39fcf9d",
   "metadata": {},
   "source": [
    "## Separacao base de previsores e alvo com base nos ultimos 90 registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d64bbcb0-4259-453e-834c-227e474663cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_treinamento_normalizada.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b505e6cf-4e37-4410-8c78-5dbde3a612c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # previsores\n",
    "y = [] # alvo - preco real\n",
    "\n",
    "for i in range(90,1242): # 90 precos anteriores\n",
    "    X.append(base_treinamento_normalizada[i-90:i,0:6])\n",
    "    y.append(base_treinamento_normalizada[i,0])\n",
    "    #print(i,i-90)\n",
    "\n",
    "X,y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "544c59d4-f5b1-4969-ad9a-4a03f3eb38ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.76501938, 0.77266112, 0.79682707, 0.76080559, 0.6838135 ,\n",
       "         0.04318274],\n",
       "        [0.7562984 , 0.78187106, 0.79733884, 0.79567784, 0.71590949,\n",
       "         0.0437121 ],\n",
       "        [0.78149225, 0.79253519, 0.82139202, 0.79715132, 0.71726583,\n",
       "         0.05170752],\n",
       "        [0.78875969, 0.7949588 , 0.81013311, 0.77996075, 0.70144373,\n",
       "         0.04015963],\n",
       "        [0.77083338, 0.77363063, 0.78505624, 0.75147351, 0.67522435,\n",
       "         0.0416214 ],\n",
       "        [0.74806197, 0.75618037, 0.78505624, 0.76031438, 0.68336137,\n",
       "         0.03485382],\n",
       "        [0.75436047, 0.76490543, 0.78915051, 0.76768177, 0.69014234,\n",
       "         0.02507502],\n",
       "        [0.75823643, 0.76442079, 0.79733884, 0.77013751, 0.6924025 ,\n",
       "         0.0260728 ],\n",
       "        [0.76598837, 0.77411537, 0.79682707, 0.76227897, 0.68516964,\n",
       "         0.0404927 ],\n",
       "        [0.76598837, 0.77411537, 0.79682707, 0.76719061, 0.68969016,\n",
       "         0.0423977 ],\n",
       "        [0.76017437, 0.75714973, 0.79222108, 0.76817293, 0.69059437,\n",
       "         0.02401858],\n",
       "        [0.75872098, 0.75908871, 0.79222108, 0.76178781, 0.68471746,\n",
       "         0.02821315],\n",
       "        [0.75581391, 0.75714973, 0.78915051, 0.75540279, 0.6788408 ,\n",
       "         0.02706042],\n",
       "        [0.74467054, 0.74309258, 0.77533265, 0.74607071, 0.67025175,\n",
       "         0.02587622],\n",
       "        [0.7374031 , 0.74357736, 0.77328557, 0.75540279, 0.6788408 ,\n",
       "         0.03367205],\n",
       "        [0.7374031 , 0.74454673, 0.77328557, 0.75392926, 0.67748471,\n",
       "         0.02460946],\n",
       "        [0.73498067, 0.75036355, 0.78045041, 0.75687631, 0.68019705,\n",
       "         0.02806007],\n",
       "        [0.75242248, 0.75327189, 0.77533265, 0.74508849, 0.66934774,\n",
       "         0.02878973],\n",
       "        [0.73401163, 0.73194382, 0.75332651, 0.73231836, 0.65759427,\n",
       "         0.03876941],\n",
       "        [0.71656977, 0.71352399, 0.71903787, 0.68762287, 0.6164569 ,\n",
       "         0.09583767],\n",
       "        [0.68120155, 0.68153175, 0.70522006, 0.68172891, 0.61103237,\n",
       "         0.04756616],\n",
       "        [0.67538755, 0.69704314, 0.71647907, 0.70039291, 0.62821037,\n",
       "         0.04129104],\n",
       "        [0.67635659, 0.68250121, 0.70470824, 0.67779964, 0.60741587,\n",
       "         0.04620398],\n",
       "        [0.63372098, 0.67959287, 0.67246673, 0.68172891, 0.61103237,\n",
       "         0.11064144],\n",
       "        [0.66521318, 0.66553563, 0.6862846 , 0.65815327, 0.58933361,\n",
       "         0.04418925],\n",
       "        [0.65649225, 0.66456617, 0.67553736, 0.65324168, 0.584813  ,\n",
       "         0.0530315 ],\n",
       "        [0.64680228, 0.65487159, 0.67860793, 0.6650295 , 0.5956623 ,\n",
       "         0.04444964],\n",
       "        [0.66618222, 0.66553563, 0.69651996, 0.66797641, 0.59837464,\n",
       "         0.03194532],\n",
       "        [0.65843028, 0.66068832, 0.6888434 , 0.66159139, 0.59249793,\n",
       "         0.0370597 ],\n",
       "        [0.64970935, 0.65535633, 0.6862846 , 0.6596267 , 0.59068976,\n",
       "         0.0357702 ],\n",
       "        [0.65116274, 0.66311202, 0.68577277, 0.67288805, 0.60289526,\n",
       "         0.02903152],\n",
       "        [0.66424419, 0.67426079, 0.70470824, 0.68271123, 0.61193639,\n",
       "         0.0412361 ],\n",
       "        [0.67344961, 0.67038294, 0.68730803, 0.65913564, 0.59023768,\n",
       "         0.03711206],\n",
       "        [0.64292631, 0.6446922 , 0.66939616, 0.64440082, 0.57667593,\n",
       "         0.04346845],\n",
       "        [0.64486434, 0.64178381, 0.65967247, 0.63605111, 0.56899095,\n",
       "         0.04421171],\n",
       "        [0.62257747, 0.62190984, 0.65148414, 0.62622798, 0.55994986,\n",
       "         0.04364257],\n",
       "        [0.60949617, 0.61027635, 0.63510752, 0.61591359, 0.55045665,\n",
       "         0.04779322],\n",
       "        [0.60998067, 0.61609307, 0.6407369 , 0.61935165, 0.55362107,\n",
       "         0.04092922],\n",
       "        [0.60852713, 0.60979157, 0.63613096, 0.60952857, 0.54457989,\n",
       "         0.03981569],\n",
       "        [0.59593023, 0.61803199, 0.62845445, 0.62377213, 0.55768961,\n",
       "         0.04509603],\n",
       "        [0.61143411, 0.62190984, 0.63254862, 0.60412577, 0.5396073 ,\n",
       "         0.05085238],\n",
       "        [0.60222863, 0.60542899, 0.6320368 , 0.60707267, 0.54231954,\n",
       "         0.04531064],\n",
       "        [0.64922481, 0.67862336, 0.6704196 , 0.68025539, 0.60967603,\n",
       "         0.10572707],\n",
       "        [0.68362398, 0.74212312, 0.72620261, 0.72445981, 0.65036132,\n",
       "         0.08930445],\n",
       "        [0.70687989, 0.72952012, 0.7185261 , 0.69597258, 0.62414194,\n",
       "         0.04376518],\n",
       "        [0.68265509, 0.71255448, 0.7062436 , 0.72347744, 0.64945705,\n",
       "         0.03589495],\n",
       "        [0.70978682, 0.72079491, 0.74257927, 0.71414542, 0.64086801,\n",
       "         0.03739277],\n",
       "        [0.70784879, 0.72370339, 0.74769703, 0.71463658, 0.64132019,\n",
       "         0.04530406],\n",
       "        [0.71608527, 0.73242845, 0.74104401, 0.74115922, 0.66573124,\n",
       "         0.03887614],\n",
       "        [0.73643411, 0.74066888, 0.76202661, 0.73133599, 0.65669001,\n",
       "         0.06269313],\n",
       "        [0.7122093 , 0.73097431, 0.75332651, 0.73673879, 0.6616627 ,\n",
       "         0.05787405],\n",
       "        [0.7122093 , 0.73097431, 0.75281474, 0.73182715, 0.65714209,\n",
       "         0.04839097],\n",
       "        [0.7194767 , 0.72176442, 0.74513818, 0.71954817, 0.6458407 ,\n",
       "         0.03954013],\n",
       "        [0.70348832, 0.70722254, 0.73541453, 0.70383112, 0.63137489,\n",
       "         0.03144514],\n",
       "        [0.69525189, 0.69995148, 0.73387917, 0.70874262, 0.63589531,\n",
       "         0.02308847],\n",
       "        [0.70397287, 0.70528357, 0.73183214, 0.70677803, 0.63408723,\n",
       "         0.03482392],\n",
       "        [0.70397287, 0.7081919 , 0.73490276, 0.70677803, 0.63408723,\n",
       "         0.02257928],\n",
       "        [0.69767442, 0.69510427, 0.72824974, 0.69842833, 0.6264022 ,\n",
       "         0.01903582],\n",
       "        [0.68168605, 0.68395536, 0.71136131, 0.67927317, 0.60877212,\n",
       "         0.02224034],\n",
       "        [0.68168605, 0.68395536, 0.69344933, 0.66306491, 0.59385423,\n",
       "         0.02942397],\n",
       "        [0.65310078, 0.66650509, 0.69396111, 0.67779964, 0.60741587,\n",
       "         0.02244093],\n",
       "        [0.66618222, 0.67571493, 0.6949847 , 0.66355598, 0.59430621,\n",
       "         0.02782257],\n",
       "        [0.64825581, 0.66117305, 0.68730803, 0.66797641, 0.59837464,\n",
       "         0.02440802],\n",
       "        [0.66182175, 0.66117305, 0.6765609 , 0.64685666, 0.57893629,\n",
       "         0.03144357],\n",
       "        [0.64341085, 0.6776539 , 0.68372569, 0.68516703, 0.61419665,\n",
       "         0.04400526],\n",
       "        [0.67877902, 0.69704314, 0.71903787, 0.69842833, 0.6264022 ,\n",
       "         0.04546845],\n",
       "        [0.69137592, 0.69122642, 0.7036848 , 0.67730848, 0.60696374,\n",
       "         0.03177292],\n",
       "        [0.66569772, 0.66941348, 0.6862846 , 0.67583495, 0.6056075 ,\n",
       "         0.03919891],\n",
       "        [0.65406982, 0.6572952 , 0.665302  , 0.63998039, 0.57260735,\n",
       "         0.05120333],\n",
       "        [0.64292631, 0.65341735, 0.68116684, 0.66306491, 0.59385423,\n",
       "         0.03397579],\n",
       "        [0.64147292, 0.64614639, 0.65813715, 0.63703343, 0.56989516,\n",
       "         0.05635362],\n",
       "        [0.63565891, 0.66262729, 0.665302  , 0.66895878, 0.5992789 ,\n",
       "         0.04077971],\n",
       "        [0.67587209, 0.68880271, 0.70777897, 0.6969548 , 0.625046  ,\n",
       "         0.0548714 ],\n",
       "        [0.68653106, 0.70382942, 0.71903787, 0.71660126, 0.64312846,\n",
       "         0.03461346],\n",
       "        [0.70300383, 0.73921474, 0.74411464, 0.73280952, 0.6580463 ,\n",
       "         0.04969664],\n",
       "        [0.71996119, 0.74600097, 0.76202661, 0.74852661, 0.67251211,\n",
       "         0.04766145],\n",
       "        [0.73982553, 0.74745521, 0.76867958, 0.73526526, 0.66030651,\n",
       "         0.05031056],\n",
       "        [0.76550388, 0.79059622, 0.80962134, 0.79666016, 0.71681365,\n",
       "         0.10120858],\n",
       "        [0.74854651, 0.76732913, 0.7840328 , 0.7804519 , 0.71911682,\n",
       "         0.06567045],\n",
       "        [0.75823643, 0.79301983, 0.80501535, 0.78831045, 0.72648688,\n",
       "         0.04828195],\n",
       "        [0.78924419, 0.79447407, 0.80706238, 0.77455795, 0.71358928,\n",
       "         0.06152981],\n",
       "        [0.76598837, 0.78041692, 0.80348004, 0.79223972, 0.73017189,\n",
       "         0.04455508],\n",
       "        [0.78488372, 0.79835191, 0.82702155, 0.80648339, 0.74353023,\n",
       "         0.03775975],\n",
       "        [0.80184109, 0.80222976, 0.82395082, 0.79027514, 0.72832946,\n",
       "         0.03492235],\n",
       "        [0.77761628, 0.78768783, 0.81729785, 0.7907662 , 0.72879006,\n",
       "         0.03271233],\n",
       "        [0.77325581, 0.78138628, 0.79785051, 0.77406679, 0.71312854,\n",
       "         0.0315204 ],\n",
       "        [0.7562984 , 0.75521086, 0.78096208, 0.75098236, 0.69147899,\n",
       "         0.03087142],\n",
       "        [0.74273261, 0.74697043, 0.77430911, 0.75392926, 0.69424286,\n",
       "         0.04384244],\n",
       "        [0.74127907, 0.74503146, 0.77840328, 0.75491163, 0.6951641 ,\n",
       "         0.03128876],\n",
       "        [0.74224806, 0.76635967, 0.78505624, 0.76375249, 0.7034554 ,\n",
       "         0.03586405]]),\n",
       " (1152, 90, 6))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938b32d0-584b-4fb9-a765-e2e0ab0b95c2",
   "metadata": {},
   "source": [
    "## Estrutura da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "009c8b00-17f3-4723-9f24-19af598d5b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m42,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m30,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">113,451</span> (443.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m113,451\u001b[0m (443.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">113,451</span> (443.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m113,451\u001b[0m (443.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 100, return_sequences=True, input_shape=(X.shape[1],6)))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences=True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences=True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "951a8935-bfce-4b61-8259-b66c45964319",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer='adam',loss='mean_squared_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a2e216-44dc-4c8d-8d0d-10d5c3029aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss',min_delta=1e-10,patience=10,verbose=True)\n",
    "rlr = ReduceLROnPlateau(monitor='loss',factor=0.2,patience=5,verbose=1)\n",
    "mcp = ModelCheckpoint(filepath='pesos.keras',monitor='loss',save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bcf9f73-650b-4c7f-a444-e2e340503f56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0623 - mean_absolute_error: 0.1891\n",
      "Epoch 1: loss improved from inf to 0.03203, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - loss: 0.0615 - mean_absolute_error: 0.1876 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0111 - mean_absolute_error: 0.0820\n",
      "Epoch 2: loss improved from 0.03203 to 0.01084, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.0111 - mean_absolute_error: 0.0820 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0086 - mean_absolute_error: 0.0698\n",
      "Epoch 3: loss improved from 0.01084 to 0.00880, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - loss: 0.0086 - mean_absolute_error: 0.0698 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0078 - mean_absolute_error: 0.0658\n",
      "Epoch 4: loss improved from 0.00880 to 0.00728, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - loss: 0.0078 - mean_absolute_error: 0.0657 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0073 - mean_absolute_error: 0.0659\n",
      "Epoch 5: loss did not improve from 0.00728\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - loss: 0.0073 - mean_absolute_error: 0.0659 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0068 - mean_absolute_error: 0.0627\n",
      "Epoch 6: loss improved from 0.00728 to 0.00657, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - loss: 0.0067 - mean_absolute_error: 0.0626 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0059 - mean_absolute_error: 0.0588\n",
      "Epoch 7: loss improved from 0.00657 to 0.00587, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - loss: 0.0059 - mean_absolute_error: 0.0588 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0061 - mean_absolute_error: 0.0599\n",
      "Epoch 8: loss improved from 0.00587 to 0.00579, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - loss: 0.0061 - mean_absolute_error: 0.0598 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0054 - mean_absolute_error: 0.0561\n",
      "Epoch 9: loss did not improve from 0.00579\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - loss: 0.0054 - mean_absolute_error: 0.0561 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0062 - mean_absolute_error: 0.0584\n",
      "Epoch 10: loss improved from 0.00579 to 0.00551, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - loss: 0.0062 - mean_absolute_error: 0.0584 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0053 - mean_absolute_error: 0.0558\n",
      "Epoch 11: loss improved from 0.00551 to 0.00496, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - loss: 0.0053 - mean_absolute_error: 0.0558 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0050 - mean_absolute_error: 0.0550\n",
      "Epoch 12: loss improved from 0.00496 to 0.00495, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.0050 - mean_absolute_error: 0.0550 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0050 - mean_absolute_error: 0.0546\n",
      "Epoch 13: loss improved from 0.00495 to 0.00492, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.0050 - mean_absolute_error: 0.0546 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0050 - mean_absolute_error: 0.0538\n",
      "Epoch 14: loss improved from 0.00492 to 0.00464, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - loss: 0.0050 - mean_absolute_error: 0.0538 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0051 - mean_absolute_error: 0.0547\n",
      "Epoch 15: loss did not improve from 0.00464\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - loss: 0.0051 - mean_absolute_error: 0.0548 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0052 - mean_absolute_error: 0.0556\n",
      "Epoch 16: loss did not improve from 0.00464\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0052 - mean_absolute_error: 0.0556 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0044 - mean_absolute_error: 0.0508\n",
      "Epoch 17: loss improved from 0.00464 to 0.00443, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - loss: 0.0044 - mean_absolute_error: 0.0508 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0041 - mean_absolute_error: 0.0489\n",
      "Epoch 18: loss improved from 0.00443 to 0.00394, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 140ms/step - loss: 0.0041 - mean_absolute_error: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0044 - mean_absolute_error: 0.0506\n",
      "Epoch 19: loss did not improve from 0.00394\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 0.0044 - mean_absolute_error: 0.0505 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0034 - mean_absolute_error: 0.0446\n",
      "Epoch 20: loss improved from 0.00394 to 0.00375, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - loss: 0.0035 - mean_absolute_error: 0.0446 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0042 - mean_absolute_error: 0.0492\n",
      "Epoch 21: loss did not improve from 0.00375\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 0.0042 - mean_absolute_error: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0044 - mean_absolute_error: 0.0502\n",
      "Epoch 22: loss did not improve from 0.00375\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0044 - mean_absolute_error: 0.0502 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0042 - mean_absolute_error: 0.0501\n",
      "Epoch 23: loss did not improve from 0.00375\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0042 - mean_absolute_error: 0.0500 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0038 - mean_absolute_error: 0.0453\n",
      "Epoch 24: loss did not improve from 0.00375\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0038 - mean_absolute_error: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0036 - mean_absolute_error: 0.0458\n",
      "Epoch 25: loss improved from 0.00375 to 0.00360, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0036 - mean_absolute_error: 0.0457 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0036 - mean_absolute_error: 0.0446\n",
      "Epoch 26: loss improved from 0.00360 to 0.00328, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0035 - mean_absolute_error: 0.0446 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0030 - mean_absolute_error: 0.0416\n",
      "Epoch 27: loss improved from 0.00328 to 0.00318, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0030 - mean_absolute_error: 0.0416 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0031 - mean_absolute_error: 0.0420\n",
      "Epoch 28: loss improved from 0.00318 to 0.00312, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0031 - mean_absolute_error: 0.0420 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0029 - mean_absolute_error: 0.0411\n",
      "Epoch 29: loss improved from 0.00312 to 0.00297, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0029 - mean_absolute_error: 0.0411 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0035 - mean_absolute_error: 0.0453\n",
      "Epoch 30: loss did not improve from 0.00297\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0035 - mean_absolute_error: 0.0453 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0029 - mean_absolute_error: 0.0411\n",
      "Epoch 31: loss did not improve from 0.00297\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0029 - mean_absolute_error: 0.0411 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0032 - mean_absolute_error: 0.0427\n",
      "Epoch 32: loss did not improve from 0.00297\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0032 - mean_absolute_error: 0.0427 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0029 - mean_absolute_error: 0.0417\n",
      "Epoch 33: loss improved from 0.00297 to 0.00277, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0029 - mean_absolute_error: 0.0417 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0028 - mean_absolute_error: 0.0408\n",
      "Epoch 34: loss improved from 0.00277 to 0.00265, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0028 - mean_absolute_error: 0.0407 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0028 - mean_absolute_error: 0.0393\n",
      "Epoch 35: loss did not improve from 0.00265\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0028 - mean_absolute_error: 0.0394 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0025 - mean_absolute_error: 0.0386\n",
      "Epoch 36: loss improved from 0.00265 to 0.00261, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0025 - mean_absolute_error: 0.0386 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0027 - mean_absolute_error: 0.0398\n",
      "Epoch 37: loss did not improve from 0.00261\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0027 - mean_absolute_error: 0.0398 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0024 - mean_absolute_error: 0.0372\n",
      "Epoch 38: loss improved from 0.00261 to 0.00251, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0024 - mean_absolute_error: 0.0372 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0026 - mean_absolute_error: 0.0393\n",
      "Epoch 39: loss improved from 0.00251 to 0.00250, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0026 - mean_absolute_error: 0.0392 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0024 - mean_absolute_error: 0.0366\n",
      "Epoch 40: loss did not improve from 0.00250\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0024 - mean_absolute_error: 0.0366 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0024 - mean_absolute_error: 0.0372\n",
      "Epoch 41: loss improved from 0.00250 to 0.00240, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - loss: 0.0024 - mean_absolute_error: 0.0373 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0023 - mean_absolute_error: 0.0362\n",
      "Epoch 42: loss did not improve from 0.00240\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0023 - mean_absolute_error: 0.0362 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0028 - mean_absolute_error: 0.0409\n",
      "Epoch 43: loss did not improve from 0.00240\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0028 - mean_absolute_error: 0.0409 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.0024 - mean_absolute_error: 0.0371\n",
      "Epoch 44: loss improved from 0.00240 to 0.00223, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 167ms/step - loss: 0.0024 - mean_absolute_error: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0023 - mean_absolute_error: 0.0353\n",
      "Epoch 45: loss did not improve from 0.00223\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 133ms/step - loss: 0.0023 - mean_absolute_error: 0.0353 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0026 - mean_absolute_error: 0.0388\n",
      "Epoch 46: loss did not improve from 0.00223\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.0026 - mean_absolute_error: 0.0388 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0026 - mean_absolute_error: 0.0386\n",
      "Epoch 47: loss did not improve from 0.00223\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0026 - mean_absolute_error: 0.0385 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0020 - mean_absolute_error: 0.0341\n",
      "Epoch 48: loss improved from 0.00223 to 0.00213, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0020 - mean_absolute_error: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0021 - mean_absolute_error: 0.0352\n",
      "Epoch 49: loss improved from 0.00213 to 0.00202, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - loss: 0.0021 - mean_absolute_error: 0.0352 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0023 - mean_absolute_error: 0.0354\n",
      "Epoch 50: loss did not improve from 0.00202\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 0.0023 - mean_absolute_error: 0.0354 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0021 - mean_absolute_error: 0.0335\n",
      "Epoch 51: loss did not improve from 0.00202\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 0.0021 - mean_absolute_error: 0.0336 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0020 - mean_absolute_error: 0.0330\n",
      "Epoch 52: loss did not improve from 0.00202\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0020 - mean_absolute_error: 0.0330 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0024 - mean_absolute_error: 0.0367\n",
      "Epoch 53: loss did not improve from 0.00202\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 0.0024 - mean_absolute_error: 0.0366 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0020 - mean_absolute_error: 0.0332\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 54: loss improved from 0.00202 to 0.00196, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0020 - mean_absolute_error: 0.0332 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0019 - mean_absolute_error: 0.0329\n",
      "Epoch 55: loss improved from 0.00196 to 0.00188, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0019 - mean_absolute_error: 0.0329 - learning_rate: 2.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0016 - mean_absolute_error: 0.0306\n",
      "Epoch 56: loss improved from 0.00188 to 0.00164, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0016 - mean_absolute_error: 0.0306 - learning_rate: 2.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0019 - mean_absolute_error: 0.0323\n",
      "Epoch 57: loss did not improve from 0.00164\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0019 - mean_absolute_error: 0.0323 - learning_rate: 2.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0017 - mean_absolute_error: 0.0308\n",
      "Epoch 58: loss did not improve from 0.00164\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - loss: 0.0017 - mean_absolute_error: 0.0309 - learning_rate: 2.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0018 - mean_absolute_error: 0.0320\n",
      "Epoch 59: loss did not improve from 0.00164\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0018 - mean_absolute_error: 0.0320 - learning_rate: 2.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0018 - mean_absolute_error: 0.0310\n",
      "Epoch 60: loss did not improve from 0.00164\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0018 - mean_absolute_error: 0.0310 - learning_rate: 2.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0016 - mean_absolute_error: 0.0299\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00164\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0016 - mean_absolute_error: 0.0300 - learning_rate: 2.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0016 - mean_absolute_error: 0.0303\n",
      "Epoch 62: loss did not improve from 0.00164\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0016 - mean_absolute_error: 0.0303 - learning_rate: 4.0000e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0017 - mean_absolute_error: 0.0314\n",
      "Epoch 63: loss did not improve from 0.00164\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0017 - mean_absolute_error: 0.0314 - learning_rate: 4.0000e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0017 - mean_absolute_error: 0.0308\n",
      "Epoch 64: loss did not improve from 0.00164\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0017 - mean_absolute_error: 0.0308 - learning_rate: 4.0000e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0016 - mean_absolute_error: 0.0301\n",
      "Epoch 65: loss did not improve from 0.00164\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0016 - mean_absolute_error: 0.0301 - learning_rate: 4.0000e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0018 - mean_absolute_error: 0.0312\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 66: loss did not improve from 0.00164\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0018 - mean_absolute_error: 0.0312 - learning_rate: 4.0000e-05\n",
      "Epoch 66: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x729700d0ac90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X,y,epochs=100,batch_size=32,callbacks=[es,rlr,mcp])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49612d6f-5dfd-48a5-b4a3-17e1b4ac2354",
   "metadata": {},
   "source": [
    "## Previsoes com Base de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac280fde-b4ec-43fd-a270-0de812ef76b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.516966</td>\n",
       "      <td>33461800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>16.490000</td>\n",
       "      <td>16.719999</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.666668</td>\n",
       "      <td>55940900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>16.780001</td>\n",
       "      <td>16.959999</td>\n",
       "      <td>16.620001</td>\n",
       "      <td>16.730000</td>\n",
       "      <td>16.696608</td>\n",
       "      <td>37064900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>16.570000</td>\n",
       "      <td>16.830000</td>\n",
       "      <td>16.796408</td>\n",
       "      <td>26958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>16.740000</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.709999</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.996010</td>\n",
       "      <td>28400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>17.160000</td>\n",
       "      <td>16.959999</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.996010</td>\n",
       "      <td>35070900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>16.920000</td>\n",
       "      <td>17.049999</td>\n",
       "      <td>16.770000</td>\n",
       "      <td>16.799999</td>\n",
       "      <td>16.766466</td>\n",
       "      <td>28547700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>16.879999</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>16.840000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>17.215569</td>\n",
       "      <td>37921500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>17.040001</td>\n",
       "      <td>17.410000</td>\n",
       "      <td>17.020000</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>17.265469</td>\n",
       "      <td>45912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>17.320000</td>\n",
       "      <td>17.440001</td>\n",
       "      <td>17.150000</td>\n",
       "      <td>17.350000</td>\n",
       "      <td>17.315371</td>\n",
       "      <td>28945400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>17.350000</td>\n",
       "      <td>17.840000</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>17.650000</td>\n",
       "      <td>17.614771</td>\n",
       "      <td>58618300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-17</td>\n",
       "      <td>17.920000</td>\n",
       "      <td>18.360001</td>\n",
       "      <td>17.809999</td>\n",
       "      <td>18.360001</td>\n",
       "      <td>18.323355</td>\n",
       "      <td>58488900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>18.530001</td>\n",
       "      <td>17.930000</td>\n",
       "      <td>18.219999</td>\n",
       "      <td>18.183632</td>\n",
       "      <td>48575800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>18.309999</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>18.030001</td>\n",
       "      <td>18.260000</td>\n",
       "      <td>18.223553</td>\n",
       "      <td>33470200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>18.260000</td>\n",
       "      <td>18.469999</td>\n",
       "      <td>18.090000</td>\n",
       "      <td>18.469999</td>\n",
       "      <td>18.433134</td>\n",
       "      <td>33920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>18.459999</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.240000</td>\n",
       "      <td>18.203592</td>\n",
       "      <td>35567700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>19.629999</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.301397</td>\n",
       "      <td>89768200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.301397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>19.620001</td>\n",
       "      <td>19.980000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>19.890221</td>\n",
       "      <td>81989500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>19.670000</td>\n",
       "      <td>20.049999</td>\n",
       "      <td>19.570000</td>\n",
       "      <td>19.850000</td>\n",
       "      <td>19.810381</td>\n",
       "      <td>55726200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>19.360001</td>\n",
       "      <td>19.490000</td>\n",
       "      <td>19.451097</td>\n",
       "      <td>46203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>19.740000</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>19.680000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>19.660681</td>\n",
       "      <td>41576600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date       Open       High        Low      Close  Adj Close  \\\n",
       "0   2018-01-02  16.190001  16.549999  16.190001  16.549999  16.516966   \n",
       "1   2018-01-03  16.490000  16.719999  16.370001  16.700001  16.666668   \n",
       "2   2018-01-04  16.780001  16.959999  16.620001  16.730000  16.696608   \n",
       "3   2018-01-05  16.700001  16.860001  16.570000  16.830000  16.796408   \n",
       "4   2018-01-08  16.740000  17.030001  16.709999  17.030001  16.996010   \n",
       "5   2018-01-09  17.030001  17.160000  16.959999  17.030001  16.996010   \n",
       "6   2018-01-10  16.920000  17.049999  16.770000  16.799999  16.766466   \n",
       "7   2018-01-11  16.879999  17.299999  16.840000  17.250000  17.215569   \n",
       "8   2018-01-12  17.040001  17.410000  17.020000  17.299999  17.265469   \n",
       "9   2018-01-15  17.320000  17.440001  17.150000  17.350000  17.315371   \n",
       "10  2018-01-16  17.350000  17.840000  17.299999  17.650000  17.614771   \n",
       "11  2018-01-17  17.920000  18.360001  17.809999  18.360001  18.323355   \n",
       "12  2018-01-18  18.350000  18.530001  17.930000  18.219999  18.183632   \n",
       "13  2018-01-19  18.309999  18.420000  18.030001  18.260000  18.223553   \n",
       "14  2018-01-22  18.260000  18.469999  18.090000  18.469999  18.433134   \n",
       "15  2018-01-23  18.400000  18.459999  18.000000  18.240000  18.203592   \n",
       "16  2018-01-24  18.420000  19.629999  18.420000  19.340000  19.301397   \n",
       "17  2018-01-25  19.340000  19.340000  19.340000  19.340000  19.301397   \n",
       "18  2018-01-26  19.620001  19.980000  19.100000  19.930000  19.890221   \n",
       "19  2018-01-29  19.670000  20.049999  19.570000  19.850000  19.810381   \n",
       "20  2018-01-30  19.770000  19.770000  19.360001  19.490000  19.451097   \n",
       "21  2018-01-31  19.740000  19.930000  19.680000  19.700001  19.660681   \n",
       "\n",
       "      Volume  \n",
       "0   33461800  \n",
       "1   55940900  \n",
       "2   37064900  \n",
       "3   26958200  \n",
       "4   28400000  \n",
       "5   35070900  \n",
       "6   28547700  \n",
       "7   37921500  \n",
       "8   45912100  \n",
       "9   28945400  \n",
       "10  58618300  \n",
       "11  58488900  \n",
       "12  48575800  \n",
       "13  33470200  \n",
       "14  33920000  \n",
       "15  35567700  \n",
       "16  89768200  \n",
       "17         0  \n",
       "18  81989500  \n",
       "19  55726200  \n",
       "20  46203000  \n",
       "21  41576600  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_teste = pd.read_csv('petr4-teste.csv')\n",
    "base_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87f36855-a8f0-4ed0-88c5-af9bcaaaf644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eda77bd3-e810-4103-83c5-5a0bbd9df998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.190001],\n",
       "       [16.49    ],\n",
       "       [16.780001],\n",
       "       [16.700001],\n",
       "       [16.74    ],\n",
       "       [17.030001],\n",
       "       [16.92    ],\n",
       "       [16.879999],\n",
       "       [17.040001],\n",
       "       [17.32    ],\n",
       "       [17.35    ],\n",
       "       [17.92    ],\n",
       "       [18.35    ],\n",
       "       [18.309999],\n",
       "       [18.26    ],\n",
       "       [18.4     ],\n",
       "       [18.42    ],\n",
       "       [19.34    ],\n",
       "       [19.620001],\n",
       "       [19.67    ],\n",
       "       [19.77    ],\n",
       "       [19.74    ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste = base_teste.iloc[:,1:2].values\n",
    "y_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f332133-34b0-4773-a414-5a0f1290012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_completa = pd.concat((base['Open'],base_teste['Open']),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc4ca502-79e7-4279-9d2b-f8d36078c456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1264,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_completa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f429bdf-609f-492e-9007-0fd75afabe0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.93    , 13.76    , 13.79    , 13.53    , 13.85    , 13.96    ,\n",
       "       14.57    , 14.65    , 15.02    , 15.1     , 14.88    , 14.98    ,\n",
       "       14.94    , 15.03    , 15.07    , 15.02    , 15.1     , 15.25    ,\n",
       "       15.85    , 15.6     , 15.79    , 15.86    , 15.7     , 15.37    ,\n",
       "       15.5     , 15.19    , 15.6     , 15.9     , 15.88    , 15.66    ,\n",
       "       15.61    , 16.129999, 16.17    , 16.08    , 16.23    , 16.16    ,\n",
       "       16.139999, 16.219999, 16.      , 16.190001, 16.290001, 16.290001,\n",
       "       16.530001, 16.780001, 16.77    , 16.969999, 16.9     , 16.99    ,\n",
       "       16.9     , 16.959999, 17.049999, 17.309999, 16.690001, 16.889999,\n",
       "       16.709999, 16.690001, 16.639999, 15.35    , 15.62    , 15.92    ,\n",
       "       16.02    , 16.15    , 16.09    , 15.98    , 16.25    , 16.01    ,\n",
       "       15.93    , 15.87    , 15.3     , 15.34    , 15.65    , 15.5     ,\n",
       "       15.22    , 15.3     , 15.51    , 15.48    , 15.36    , 15.65    ,\n",
       "       15.1     , 15.05    , 15.16    , 15.18    , 15.21    , 15.31    ,\n",
       "       15.75    , 15.75    , 15.75    , 15.99    , 16.1     , 16.1     ,\n",
       "       16.190001, 16.49    , 16.780001, 16.700001, 16.74    , 17.030001,\n",
       "       16.92    , 16.879999, 17.040001, 17.32    , 17.35    , 17.92    ,\n",
       "       18.35    , 18.309999, 18.26    , 18.4     , 18.42    , 19.34    ,\n",
       "       19.620001, 19.67    , 19.77    , 19.74    ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas = base_completa[len(base_completa) - len(base_teste) - 90:].values\n",
    "entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19511e9a-f3ba-4c04-a1c3-ccfd7642c98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a645fa1b-ede3-4edc-9d48-18bdd136924b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas = entradas.reshape(-1,1)\n",
    "entradas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a56eec26-bfe2-4ba6-930d-fe981ae68a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.93    ],\n",
       "       [13.76    ],\n",
       "       [13.79    ],\n",
       "       [13.53    ],\n",
       "       [13.85    ],\n",
       "       [13.96    ],\n",
       "       [14.57    ],\n",
       "       [14.65    ],\n",
       "       [15.02    ],\n",
       "       [15.1     ],\n",
       "       [14.88    ],\n",
       "       [14.98    ],\n",
       "       [14.94    ],\n",
       "       [15.03    ],\n",
       "       [15.07    ],\n",
       "       [15.02    ],\n",
       "       [15.1     ],\n",
       "       [15.25    ],\n",
       "       [15.85    ],\n",
       "       [15.6     ],\n",
       "       [15.79    ],\n",
       "       [15.86    ],\n",
       "       [15.7     ],\n",
       "       [15.37    ],\n",
       "       [15.5     ],\n",
       "       [15.19    ],\n",
       "       [15.6     ],\n",
       "       [15.9     ],\n",
       "       [15.88    ],\n",
       "       [15.66    ],\n",
       "       [15.61    ],\n",
       "       [16.129999],\n",
       "       [16.17    ],\n",
       "       [16.08    ],\n",
       "       [16.23    ],\n",
       "       [16.16    ],\n",
       "       [16.139999],\n",
       "       [16.219999],\n",
       "       [16.      ],\n",
       "       [16.190001],\n",
       "       [16.290001],\n",
       "       [16.290001],\n",
       "       [16.530001],\n",
       "       [16.780001],\n",
       "       [16.77    ],\n",
       "       [16.969999],\n",
       "       [16.9     ],\n",
       "       [16.99    ],\n",
       "       [16.9     ],\n",
       "       [16.959999],\n",
       "       [17.049999],\n",
       "       [17.309999],\n",
       "       [16.690001],\n",
       "       [16.889999],\n",
       "       [16.709999],\n",
       "       [16.690001],\n",
       "       [16.639999],\n",
       "       [15.35    ],\n",
       "       [15.62    ],\n",
       "       [15.92    ],\n",
       "       [16.02    ],\n",
       "       [16.15    ],\n",
       "       [16.09    ],\n",
       "       [15.98    ],\n",
       "       [16.25    ],\n",
       "       [16.01    ],\n",
       "       [15.93    ],\n",
       "       [15.87    ],\n",
       "       [15.3     ],\n",
       "       [15.34    ],\n",
       "       [15.65    ],\n",
       "       [15.5     ],\n",
       "       [15.22    ],\n",
       "       [15.3     ],\n",
       "       [15.51    ],\n",
       "       [15.48    ],\n",
       "       [15.36    ],\n",
       "       [15.65    ],\n",
       "       [15.1     ],\n",
       "       [15.05    ],\n",
       "       [15.16    ],\n",
       "       [15.18    ],\n",
       "       [15.21    ],\n",
       "       [15.31    ],\n",
       "       [15.75    ],\n",
       "       [15.75    ],\n",
       "       [15.75    ],\n",
       "       [15.99    ],\n",
       "       [16.1     ],\n",
       "       [16.1     ],\n",
       "       [16.190001],\n",
       "       [16.49    ],\n",
       "       [16.780001],\n",
       "       [16.700001],\n",
       "       [16.74    ],\n",
       "       [17.030001],\n",
       "       [16.92    ],\n",
       "       [16.879999],\n",
       "       [17.040001],\n",
       "       [17.32    ],\n",
       "       [17.35    ],\n",
       "       [17.92    ],\n",
       "       [18.35    ],\n",
       "       [18.309999],\n",
       "       [18.26    ],\n",
       "       [18.4     ],\n",
       "       [18.42    ],\n",
       "       [19.34    ],\n",
       "       [19.620001],\n",
       "       [19.67    ],\n",
       "       [19.77    ],\n",
       "       [19.74    ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9202499-328a-4604-926c-575464eaebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = normalizador.transform(entradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5690904-5b0a-4f29-bfd5-72115381adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste = []\n",
    "for i in range(90,112):\n",
    "    X_teste.append(entradas[i-90:i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d91cdad1-6f6d-4f75-a018-c4e14076d418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.47141473, 0.46317829, 0.46463178, 0.45203488, 0.46753876,\n",
       "        0.47286822, 0.50242248, 0.50629845, 0.52422481, 0.52810078,\n",
       "        0.51744186, 0.52228682, 0.52034884, 0.5247093 , 0.52664729,\n",
       "        0.52422481, 0.52810078, 0.53536822, 0.56443798, 0.55232558,\n",
       "        0.56153101, 0.56492248, 0.55717054, 0.54118217, 0.54748062,\n",
       "        0.53246124, 0.55232558, 0.56686047, 0.56589147, 0.55523256,\n",
       "        0.55281008, 0.57800383, 0.57994186, 0.5755814 , 0.58284884,\n",
       "        0.57945736, 0.57848832, 0.58236429, 0.57170543, 0.5809109 ,\n",
       "        0.58575586, 0.58575586, 0.59738377, 0.60949617, 0.60901163,\n",
       "        0.6187015 , 0.61531008, 0.61967054, 0.61531008, 0.61821701,\n",
       "        0.62257747, 0.63517437, 0.60513571, 0.61482553, 0.6061046 ,\n",
       "        0.60513571, 0.60271313, 0.54021318, 0.55329457, 0.56782946,\n",
       "        0.57267442, 0.57897287, 0.57606589, 0.57073643, 0.58381783,\n",
       "        0.57218992, 0.56831395, 0.56540698, 0.5377907 , 0.53972868,\n",
       "        0.55474806, 0.54748062, 0.53391473, 0.5377907 , 0.54796512,\n",
       "        0.54651163, 0.54069767, 0.55474806, 0.52810078, 0.52567829,\n",
       "        0.53100775, 0.53197674, 0.53343023, 0.53827519, 0.55959302,\n",
       "        0.55959302, 0.55959302, 0.57122093, 0.57655039, 0.57655039]),\n",
       " array([0.46317829, 0.46463178, 0.45203488, 0.46753876, 0.47286822,\n",
       "        0.50242248, 0.50629845, 0.52422481, 0.52810078, 0.51744186,\n",
       "        0.52228682, 0.52034884, 0.5247093 , 0.52664729, 0.52422481,\n",
       "        0.52810078, 0.53536822, 0.56443798, 0.55232558, 0.56153101,\n",
       "        0.56492248, 0.55717054, 0.54118217, 0.54748062, 0.53246124,\n",
       "        0.55232558, 0.56686047, 0.56589147, 0.55523256, 0.55281008,\n",
       "        0.57800383, 0.57994186, 0.5755814 , 0.58284884, 0.57945736,\n",
       "        0.57848832, 0.58236429, 0.57170543, 0.5809109 , 0.58575586,\n",
       "        0.58575586, 0.59738377, 0.60949617, 0.60901163, 0.6187015 ,\n",
       "        0.61531008, 0.61967054, 0.61531008, 0.61821701, 0.62257747,\n",
       "        0.63517437, 0.60513571, 0.61482553, 0.6061046 , 0.60513571,\n",
       "        0.60271313, 0.54021318, 0.55329457, 0.56782946, 0.57267442,\n",
       "        0.57897287, 0.57606589, 0.57073643, 0.58381783, 0.57218992,\n",
       "        0.56831395, 0.56540698, 0.5377907 , 0.53972868, 0.55474806,\n",
       "        0.54748062, 0.53391473, 0.5377907 , 0.54796512, 0.54651163,\n",
       "        0.54069767, 0.55474806, 0.52810078, 0.52567829, 0.53100775,\n",
       "        0.53197674, 0.53343023, 0.53827519, 0.55959302, 0.55959302,\n",
       "        0.55959302, 0.57122093, 0.57655039, 0.57655039, 0.5809109 ]),\n",
       " array([0.46463178, 0.45203488, 0.46753876, 0.47286822, 0.50242248,\n",
       "        0.50629845, 0.52422481, 0.52810078, 0.51744186, 0.52228682,\n",
       "        0.52034884, 0.5247093 , 0.52664729, 0.52422481, 0.52810078,\n",
       "        0.53536822, 0.56443798, 0.55232558, 0.56153101, 0.56492248,\n",
       "        0.55717054, 0.54118217, 0.54748062, 0.53246124, 0.55232558,\n",
       "        0.56686047, 0.56589147, 0.55523256, 0.55281008, 0.57800383,\n",
       "        0.57994186, 0.5755814 , 0.58284884, 0.57945736, 0.57848832,\n",
       "        0.58236429, 0.57170543, 0.5809109 , 0.58575586, 0.58575586,\n",
       "        0.59738377, 0.60949617, 0.60901163, 0.6187015 , 0.61531008,\n",
       "        0.61967054, 0.61531008, 0.61821701, 0.62257747, 0.63517437,\n",
       "        0.60513571, 0.61482553, 0.6061046 , 0.60513571, 0.60271313,\n",
       "        0.54021318, 0.55329457, 0.56782946, 0.57267442, 0.57897287,\n",
       "        0.57606589, 0.57073643, 0.58381783, 0.57218992, 0.56831395,\n",
       "        0.56540698, 0.5377907 , 0.53972868, 0.55474806, 0.54748062,\n",
       "        0.53391473, 0.5377907 , 0.54796512, 0.54651163, 0.54069767,\n",
       "        0.55474806, 0.52810078, 0.52567829, 0.53100775, 0.53197674,\n",
       "        0.53343023, 0.53827519, 0.55959302, 0.55959302, 0.55959302,\n",
       "        0.57122093, 0.57655039, 0.57655039, 0.5809109 , 0.59544574]),\n",
       " array([0.45203488, 0.46753876, 0.47286822, 0.50242248, 0.50629845,\n",
       "        0.52422481, 0.52810078, 0.51744186, 0.52228682, 0.52034884,\n",
       "        0.5247093 , 0.52664729, 0.52422481, 0.52810078, 0.53536822,\n",
       "        0.56443798, 0.55232558, 0.56153101, 0.56492248, 0.55717054,\n",
       "        0.54118217, 0.54748062, 0.53246124, 0.55232558, 0.56686047,\n",
       "        0.56589147, 0.55523256, 0.55281008, 0.57800383, 0.57994186,\n",
       "        0.5755814 , 0.58284884, 0.57945736, 0.57848832, 0.58236429,\n",
       "        0.57170543, 0.5809109 , 0.58575586, 0.58575586, 0.59738377,\n",
       "        0.60949617, 0.60901163, 0.6187015 , 0.61531008, 0.61967054,\n",
       "        0.61531008, 0.61821701, 0.62257747, 0.63517437, 0.60513571,\n",
       "        0.61482553, 0.6061046 , 0.60513571, 0.60271313, 0.54021318,\n",
       "        0.55329457, 0.56782946, 0.57267442, 0.57897287, 0.57606589,\n",
       "        0.57073643, 0.58381783, 0.57218992, 0.56831395, 0.56540698,\n",
       "        0.5377907 , 0.53972868, 0.55474806, 0.54748062, 0.53391473,\n",
       "        0.5377907 , 0.54796512, 0.54651163, 0.54069767, 0.55474806,\n",
       "        0.52810078, 0.52567829, 0.53100775, 0.53197674, 0.53343023,\n",
       "        0.53827519, 0.55959302, 0.55959302, 0.55959302, 0.57122093,\n",
       "        0.57655039, 0.57655039, 0.5809109 , 0.59544574, 0.60949617]),\n",
       " array([0.46753876, 0.47286822, 0.50242248, 0.50629845, 0.52422481,\n",
       "        0.52810078, 0.51744186, 0.52228682, 0.52034884, 0.5247093 ,\n",
       "        0.52664729, 0.52422481, 0.52810078, 0.53536822, 0.56443798,\n",
       "        0.55232558, 0.56153101, 0.56492248, 0.55717054, 0.54118217,\n",
       "        0.54748062, 0.53246124, 0.55232558, 0.56686047, 0.56589147,\n",
       "        0.55523256, 0.55281008, 0.57800383, 0.57994186, 0.5755814 ,\n",
       "        0.58284884, 0.57945736, 0.57848832, 0.58236429, 0.57170543,\n",
       "        0.5809109 , 0.58575586, 0.58575586, 0.59738377, 0.60949617,\n",
       "        0.60901163, 0.6187015 , 0.61531008, 0.61967054, 0.61531008,\n",
       "        0.61821701, 0.62257747, 0.63517437, 0.60513571, 0.61482553,\n",
       "        0.6061046 , 0.60513571, 0.60271313, 0.54021318, 0.55329457,\n",
       "        0.56782946, 0.57267442, 0.57897287, 0.57606589, 0.57073643,\n",
       "        0.58381783, 0.57218992, 0.56831395, 0.56540698, 0.5377907 ,\n",
       "        0.53972868, 0.55474806, 0.54748062, 0.53391473, 0.5377907 ,\n",
       "        0.54796512, 0.54651163, 0.54069767, 0.55474806, 0.52810078,\n",
       "        0.52567829, 0.53100775, 0.53197674, 0.53343023, 0.53827519,\n",
       "        0.55959302, 0.55959302, 0.55959302, 0.57122093, 0.57655039,\n",
       "        0.57655039, 0.5809109 , 0.59544574, 0.60949617, 0.6056202 ]),\n",
       " array([0.47286822, 0.50242248, 0.50629845, 0.52422481, 0.52810078,\n",
       "        0.51744186, 0.52228682, 0.52034884, 0.5247093 , 0.52664729,\n",
       "        0.52422481, 0.52810078, 0.53536822, 0.56443798, 0.55232558,\n",
       "        0.56153101, 0.56492248, 0.55717054, 0.54118217, 0.54748062,\n",
       "        0.53246124, 0.55232558, 0.56686047, 0.56589147, 0.55523256,\n",
       "        0.55281008, 0.57800383, 0.57994186, 0.5755814 , 0.58284884,\n",
       "        0.57945736, 0.57848832, 0.58236429, 0.57170543, 0.5809109 ,\n",
       "        0.58575586, 0.58575586, 0.59738377, 0.60949617, 0.60901163,\n",
       "        0.6187015 , 0.61531008, 0.61967054, 0.61531008, 0.61821701,\n",
       "        0.62257747, 0.63517437, 0.60513571, 0.61482553, 0.6061046 ,\n",
       "        0.60513571, 0.60271313, 0.54021318, 0.55329457, 0.56782946,\n",
       "        0.57267442, 0.57897287, 0.57606589, 0.57073643, 0.58381783,\n",
       "        0.57218992, 0.56831395, 0.56540698, 0.5377907 , 0.53972868,\n",
       "        0.55474806, 0.54748062, 0.53391473, 0.5377907 , 0.54796512,\n",
       "        0.54651163, 0.54069767, 0.55474806, 0.52810078, 0.52567829,\n",
       "        0.53100775, 0.53197674, 0.53343023, 0.53827519, 0.55959302,\n",
       "        0.55959302, 0.55959302, 0.57122093, 0.57655039, 0.57655039,\n",
       "        0.5809109 , 0.59544574, 0.60949617, 0.6056202 , 0.60755814]),\n",
       " array([0.50242248, 0.50629845, 0.52422481, 0.52810078, 0.51744186,\n",
       "        0.52228682, 0.52034884, 0.5247093 , 0.52664729, 0.52422481,\n",
       "        0.52810078, 0.53536822, 0.56443798, 0.55232558, 0.56153101,\n",
       "        0.56492248, 0.55717054, 0.54118217, 0.54748062, 0.53246124,\n",
       "        0.55232558, 0.56686047, 0.56589147, 0.55523256, 0.55281008,\n",
       "        0.57800383, 0.57994186, 0.5755814 , 0.58284884, 0.57945736,\n",
       "        0.57848832, 0.58236429, 0.57170543, 0.5809109 , 0.58575586,\n",
       "        0.58575586, 0.59738377, 0.60949617, 0.60901163, 0.6187015 ,\n",
       "        0.61531008, 0.61967054, 0.61531008, 0.61821701, 0.62257747,\n",
       "        0.63517437, 0.60513571, 0.61482553, 0.6061046 , 0.60513571,\n",
       "        0.60271313, 0.54021318, 0.55329457, 0.56782946, 0.57267442,\n",
       "        0.57897287, 0.57606589, 0.57073643, 0.58381783, 0.57218992,\n",
       "        0.56831395, 0.56540698, 0.5377907 , 0.53972868, 0.55474806,\n",
       "        0.54748062, 0.53391473, 0.5377907 , 0.54796512, 0.54651163,\n",
       "        0.54069767, 0.55474806, 0.52810078, 0.52567829, 0.53100775,\n",
       "        0.53197674, 0.53343023, 0.53827519, 0.55959302, 0.55959302,\n",
       "        0.55959302, 0.57122093, 0.57655039, 0.57655039, 0.5809109 ,\n",
       "        0.59544574, 0.60949617, 0.6056202 , 0.60755814, 0.62160858]),\n",
       " array([0.50629845, 0.52422481, 0.52810078, 0.51744186, 0.52228682,\n",
       "        0.52034884, 0.5247093 , 0.52664729, 0.52422481, 0.52810078,\n",
       "        0.53536822, 0.56443798, 0.55232558, 0.56153101, 0.56492248,\n",
       "        0.55717054, 0.54118217, 0.54748062, 0.53246124, 0.55232558,\n",
       "        0.56686047, 0.56589147, 0.55523256, 0.55281008, 0.57800383,\n",
       "        0.57994186, 0.5755814 , 0.58284884, 0.57945736, 0.57848832,\n",
       "        0.58236429, 0.57170543, 0.5809109 , 0.58575586, 0.58575586,\n",
       "        0.59738377, 0.60949617, 0.60901163, 0.6187015 , 0.61531008,\n",
       "        0.61967054, 0.61531008, 0.61821701, 0.62257747, 0.63517437,\n",
       "        0.60513571, 0.61482553, 0.6061046 , 0.60513571, 0.60271313,\n",
       "        0.54021318, 0.55329457, 0.56782946, 0.57267442, 0.57897287,\n",
       "        0.57606589, 0.57073643, 0.58381783, 0.57218992, 0.56831395,\n",
       "        0.56540698, 0.5377907 , 0.53972868, 0.55474806, 0.54748062,\n",
       "        0.53391473, 0.5377907 , 0.54796512, 0.54651163, 0.54069767,\n",
       "        0.55474806, 0.52810078, 0.52567829, 0.53100775, 0.53197674,\n",
       "        0.53343023, 0.53827519, 0.55959302, 0.55959302, 0.55959302,\n",
       "        0.57122093, 0.57655039, 0.57655039, 0.5809109 , 0.59544574,\n",
       "        0.60949617, 0.6056202 , 0.60755814, 0.62160858, 0.61627907]),\n",
       " array([0.52422481, 0.52810078, 0.51744186, 0.52228682, 0.52034884,\n",
       "        0.5247093 , 0.52664729, 0.52422481, 0.52810078, 0.53536822,\n",
       "        0.56443798, 0.55232558, 0.56153101, 0.56492248, 0.55717054,\n",
       "        0.54118217, 0.54748062, 0.53246124, 0.55232558, 0.56686047,\n",
       "        0.56589147, 0.55523256, 0.55281008, 0.57800383, 0.57994186,\n",
       "        0.5755814 , 0.58284884, 0.57945736, 0.57848832, 0.58236429,\n",
       "        0.57170543, 0.5809109 , 0.58575586, 0.58575586, 0.59738377,\n",
       "        0.60949617, 0.60901163, 0.6187015 , 0.61531008, 0.61967054,\n",
       "        0.61531008, 0.61821701, 0.62257747, 0.63517437, 0.60513571,\n",
       "        0.61482553, 0.6061046 , 0.60513571, 0.60271313, 0.54021318,\n",
       "        0.55329457, 0.56782946, 0.57267442, 0.57897287, 0.57606589,\n",
       "        0.57073643, 0.58381783, 0.57218992, 0.56831395, 0.56540698,\n",
       "        0.5377907 , 0.53972868, 0.55474806, 0.54748062, 0.53391473,\n",
       "        0.5377907 , 0.54796512, 0.54651163, 0.54069767, 0.55474806,\n",
       "        0.52810078, 0.52567829, 0.53100775, 0.53197674, 0.53343023,\n",
       "        0.53827519, 0.55959302, 0.55959302, 0.55959302, 0.57122093,\n",
       "        0.57655039, 0.57655039, 0.5809109 , 0.59544574, 0.60949617,\n",
       "        0.6056202 , 0.60755814, 0.62160858, 0.61627907, 0.61434104]),\n",
       " array([0.52810078, 0.51744186, 0.52228682, 0.52034884, 0.5247093 ,\n",
       "        0.52664729, 0.52422481, 0.52810078, 0.53536822, 0.56443798,\n",
       "        0.55232558, 0.56153101, 0.56492248, 0.55717054, 0.54118217,\n",
       "        0.54748062, 0.53246124, 0.55232558, 0.56686047, 0.56589147,\n",
       "        0.55523256, 0.55281008, 0.57800383, 0.57994186, 0.5755814 ,\n",
       "        0.58284884, 0.57945736, 0.57848832, 0.58236429, 0.57170543,\n",
       "        0.5809109 , 0.58575586, 0.58575586, 0.59738377, 0.60949617,\n",
       "        0.60901163, 0.6187015 , 0.61531008, 0.61967054, 0.61531008,\n",
       "        0.61821701, 0.62257747, 0.63517437, 0.60513571, 0.61482553,\n",
       "        0.6061046 , 0.60513571, 0.60271313, 0.54021318, 0.55329457,\n",
       "        0.56782946, 0.57267442, 0.57897287, 0.57606589, 0.57073643,\n",
       "        0.58381783, 0.57218992, 0.56831395, 0.56540698, 0.5377907 ,\n",
       "        0.53972868, 0.55474806, 0.54748062, 0.53391473, 0.5377907 ,\n",
       "        0.54796512, 0.54651163, 0.54069767, 0.55474806, 0.52810078,\n",
       "        0.52567829, 0.53100775, 0.53197674, 0.53343023, 0.53827519,\n",
       "        0.55959302, 0.55959302, 0.55959302, 0.57122093, 0.57655039,\n",
       "        0.57655039, 0.5809109 , 0.59544574, 0.60949617, 0.6056202 ,\n",
       "        0.60755814, 0.62160858, 0.61627907, 0.61434104, 0.62209307]),\n",
       " array([0.51744186, 0.52228682, 0.52034884, 0.5247093 , 0.52664729,\n",
       "        0.52422481, 0.52810078, 0.53536822, 0.56443798, 0.55232558,\n",
       "        0.56153101, 0.56492248, 0.55717054, 0.54118217, 0.54748062,\n",
       "        0.53246124, 0.55232558, 0.56686047, 0.56589147, 0.55523256,\n",
       "        0.55281008, 0.57800383, 0.57994186, 0.5755814 , 0.58284884,\n",
       "        0.57945736, 0.57848832, 0.58236429, 0.57170543, 0.5809109 ,\n",
       "        0.58575586, 0.58575586, 0.59738377, 0.60949617, 0.60901163,\n",
       "        0.6187015 , 0.61531008, 0.61967054, 0.61531008, 0.61821701,\n",
       "        0.62257747, 0.63517437, 0.60513571, 0.61482553, 0.6061046 ,\n",
       "        0.60513571, 0.60271313, 0.54021318, 0.55329457, 0.56782946,\n",
       "        0.57267442, 0.57897287, 0.57606589, 0.57073643, 0.58381783,\n",
       "        0.57218992, 0.56831395, 0.56540698, 0.5377907 , 0.53972868,\n",
       "        0.55474806, 0.54748062, 0.53391473, 0.5377907 , 0.54796512,\n",
       "        0.54651163, 0.54069767, 0.55474806, 0.52810078, 0.52567829,\n",
       "        0.53100775, 0.53197674, 0.53343023, 0.53827519, 0.55959302,\n",
       "        0.55959302, 0.55959302, 0.57122093, 0.57655039, 0.57655039,\n",
       "        0.5809109 , 0.59544574, 0.60949617, 0.6056202 , 0.60755814,\n",
       "        0.62160858, 0.61627907, 0.61434104, 0.62209307, 0.63565891]),\n",
       " array([0.52228682, 0.52034884, 0.5247093 , 0.52664729, 0.52422481,\n",
       "        0.52810078, 0.53536822, 0.56443798, 0.55232558, 0.56153101,\n",
       "        0.56492248, 0.55717054, 0.54118217, 0.54748062, 0.53246124,\n",
       "        0.55232558, 0.56686047, 0.56589147, 0.55523256, 0.55281008,\n",
       "        0.57800383, 0.57994186, 0.5755814 , 0.58284884, 0.57945736,\n",
       "        0.57848832, 0.58236429, 0.57170543, 0.5809109 , 0.58575586,\n",
       "        0.58575586, 0.59738377, 0.60949617, 0.60901163, 0.6187015 ,\n",
       "        0.61531008, 0.61967054, 0.61531008, 0.61821701, 0.62257747,\n",
       "        0.63517437, 0.60513571, 0.61482553, 0.6061046 , 0.60513571,\n",
       "        0.60271313, 0.54021318, 0.55329457, 0.56782946, 0.57267442,\n",
       "        0.57897287, 0.57606589, 0.57073643, 0.58381783, 0.57218992,\n",
       "        0.56831395, 0.56540698, 0.5377907 , 0.53972868, 0.55474806,\n",
       "        0.54748062, 0.53391473, 0.5377907 , 0.54796512, 0.54651163,\n",
       "        0.54069767, 0.55474806, 0.52810078, 0.52567829, 0.53100775,\n",
       "        0.53197674, 0.53343023, 0.53827519, 0.55959302, 0.55959302,\n",
       "        0.55959302, 0.57122093, 0.57655039, 0.57655039, 0.5809109 ,\n",
       "        0.59544574, 0.60949617, 0.6056202 , 0.60755814, 0.62160858,\n",
       "        0.61627907, 0.61434104, 0.62209307, 0.63565891, 0.6371124 ]),\n",
       " array([0.52034884, 0.5247093 , 0.52664729, 0.52422481, 0.52810078,\n",
       "        0.53536822, 0.56443798, 0.55232558, 0.56153101, 0.56492248,\n",
       "        0.55717054, 0.54118217, 0.54748062, 0.53246124, 0.55232558,\n",
       "        0.56686047, 0.56589147, 0.55523256, 0.55281008, 0.57800383,\n",
       "        0.57994186, 0.5755814 , 0.58284884, 0.57945736, 0.57848832,\n",
       "        0.58236429, 0.57170543, 0.5809109 , 0.58575586, 0.58575586,\n",
       "        0.59738377, 0.60949617, 0.60901163, 0.6187015 , 0.61531008,\n",
       "        0.61967054, 0.61531008, 0.61821701, 0.62257747, 0.63517437,\n",
       "        0.60513571, 0.61482553, 0.6061046 , 0.60513571, 0.60271313,\n",
       "        0.54021318, 0.55329457, 0.56782946, 0.57267442, 0.57897287,\n",
       "        0.57606589, 0.57073643, 0.58381783, 0.57218992, 0.56831395,\n",
       "        0.56540698, 0.5377907 , 0.53972868, 0.55474806, 0.54748062,\n",
       "        0.53391473, 0.5377907 , 0.54796512, 0.54651163, 0.54069767,\n",
       "        0.55474806, 0.52810078, 0.52567829, 0.53100775, 0.53197674,\n",
       "        0.53343023, 0.53827519, 0.55959302, 0.55959302, 0.55959302,\n",
       "        0.57122093, 0.57655039, 0.57655039, 0.5809109 , 0.59544574,\n",
       "        0.60949617, 0.6056202 , 0.60755814, 0.62160858, 0.61627907,\n",
       "        0.61434104, 0.62209307, 0.63565891, 0.6371124 , 0.66472868]),\n",
       " array([0.5247093 , 0.52664729, 0.52422481, 0.52810078, 0.53536822,\n",
       "        0.56443798, 0.55232558, 0.56153101, 0.56492248, 0.55717054,\n",
       "        0.54118217, 0.54748062, 0.53246124, 0.55232558, 0.56686047,\n",
       "        0.56589147, 0.55523256, 0.55281008, 0.57800383, 0.57994186,\n",
       "        0.5755814 , 0.58284884, 0.57945736, 0.57848832, 0.58236429,\n",
       "        0.57170543, 0.5809109 , 0.58575586, 0.58575586, 0.59738377,\n",
       "        0.60949617, 0.60901163, 0.6187015 , 0.61531008, 0.61967054,\n",
       "        0.61531008, 0.61821701, 0.62257747, 0.63517437, 0.60513571,\n",
       "        0.61482553, 0.6061046 , 0.60513571, 0.60271313, 0.54021318,\n",
       "        0.55329457, 0.56782946, 0.57267442, 0.57897287, 0.57606589,\n",
       "        0.57073643, 0.58381783, 0.57218992, 0.56831395, 0.56540698,\n",
       "        0.5377907 , 0.53972868, 0.55474806, 0.54748062, 0.53391473,\n",
       "        0.5377907 , 0.54796512, 0.54651163, 0.54069767, 0.55474806,\n",
       "        0.52810078, 0.52567829, 0.53100775, 0.53197674, 0.53343023,\n",
       "        0.53827519, 0.55959302, 0.55959302, 0.55959302, 0.57122093,\n",
       "        0.57655039, 0.57655039, 0.5809109 , 0.59544574, 0.60949617,\n",
       "        0.6056202 , 0.60755814, 0.62160858, 0.61627907, 0.61434104,\n",
       "        0.62209307, 0.63565891, 0.6371124 , 0.66472868, 0.68556202]),\n",
       " array([0.52664729, 0.52422481, 0.52810078, 0.53536822, 0.56443798,\n",
       "        0.55232558, 0.56153101, 0.56492248, 0.55717054, 0.54118217,\n",
       "        0.54748062, 0.53246124, 0.55232558, 0.56686047, 0.56589147,\n",
       "        0.55523256, 0.55281008, 0.57800383, 0.57994186, 0.5755814 ,\n",
       "        0.58284884, 0.57945736, 0.57848832, 0.58236429, 0.57170543,\n",
       "        0.5809109 , 0.58575586, 0.58575586, 0.59738377, 0.60949617,\n",
       "        0.60901163, 0.6187015 , 0.61531008, 0.61967054, 0.61531008,\n",
       "        0.61821701, 0.62257747, 0.63517437, 0.60513571, 0.61482553,\n",
       "        0.6061046 , 0.60513571, 0.60271313, 0.54021318, 0.55329457,\n",
       "        0.56782946, 0.57267442, 0.57897287, 0.57606589, 0.57073643,\n",
       "        0.58381783, 0.57218992, 0.56831395, 0.56540698, 0.5377907 ,\n",
       "        0.53972868, 0.55474806, 0.54748062, 0.53391473, 0.5377907 ,\n",
       "        0.54796512, 0.54651163, 0.54069767, 0.55474806, 0.52810078,\n",
       "        0.52567829, 0.53100775, 0.53197674, 0.53343023, 0.53827519,\n",
       "        0.55959302, 0.55959302, 0.55959302, 0.57122093, 0.57655039,\n",
       "        0.57655039, 0.5809109 , 0.59544574, 0.60949617, 0.6056202 ,\n",
       "        0.60755814, 0.62160858, 0.61627907, 0.61434104, 0.62209307,\n",
       "        0.63565891, 0.6371124 , 0.66472868, 0.68556202, 0.68362398]),\n",
       " array([0.52422481, 0.52810078, 0.53536822, 0.56443798, 0.55232558,\n",
       "        0.56153101, 0.56492248, 0.55717054, 0.54118217, 0.54748062,\n",
       "        0.53246124, 0.55232558, 0.56686047, 0.56589147, 0.55523256,\n",
       "        0.55281008, 0.57800383, 0.57994186, 0.5755814 , 0.58284884,\n",
       "        0.57945736, 0.57848832, 0.58236429, 0.57170543, 0.5809109 ,\n",
       "        0.58575586, 0.58575586, 0.59738377, 0.60949617, 0.60901163,\n",
       "        0.6187015 , 0.61531008, 0.61967054, 0.61531008, 0.61821701,\n",
       "        0.62257747, 0.63517437, 0.60513571, 0.61482553, 0.6061046 ,\n",
       "        0.60513571, 0.60271313, 0.54021318, 0.55329457, 0.56782946,\n",
       "        0.57267442, 0.57897287, 0.57606589, 0.57073643, 0.58381783,\n",
       "        0.57218992, 0.56831395, 0.56540698, 0.5377907 , 0.53972868,\n",
       "        0.55474806, 0.54748062, 0.53391473, 0.5377907 , 0.54796512,\n",
       "        0.54651163, 0.54069767, 0.55474806, 0.52810078, 0.52567829,\n",
       "        0.53100775, 0.53197674, 0.53343023, 0.53827519, 0.55959302,\n",
       "        0.55959302, 0.55959302, 0.57122093, 0.57655039, 0.57655039,\n",
       "        0.5809109 , 0.59544574, 0.60949617, 0.6056202 , 0.60755814,\n",
       "        0.62160858, 0.61627907, 0.61434104, 0.62209307, 0.63565891,\n",
       "        0.6371124 , 0.66472868, 0.68556202, 0.68362398, 0.68120155]),\n",
       " array([0.52810078, 0.53536822, 0.56443798, 0.55232558, 0.56153101,\n",
       "        0.56492248, 0.55717054, 0.54118217, 0.54748062, 0.53246124,\n",
       "        0.55232558, 0.56686047, 0.56589147, 0.55523256, 0.55281008,\n",
       "        0.57800383, 0.57994186, 0.5755814 , 0.58284884, 0.57945736,\n",
       "        0.57848832, 0.58236429, 0.57170543, 0.5809109 , 0.58575586,\n",
       "        0.58575586, 0.59738377, 0.60949617, 0.60901163, 0.6187015 ,\n",
       "        0.61531008, 0.61967054, 0.61531008, 0.61821701, 0.62257747,\n",
       "        0.63517437, 0.60513571, 0.61482553, 0.6061046 , 0.60513571,\n",
       "        0.60271313, 0.54021318, 0.55329457, 0.56782946, 0.57267442,\n",
       "        0.57897287, 0.57606589, 0.57073643, 0.58381783, 0.57218992,\n",
       "        0.56831395, 0.56540698, 0.5377907 , 0.53972868, 0.55474806,\n",
       "        0.54748062, 0.53391473, 0.5377907 , 0.54796512, 0.54651163,\n",
       "        0.54069767, 0.55474806, 0.52810078, 0.52567829, 0.53100775,\n",
       "        0.53197674, 0.53343023, 0.53827519, 0.55959302, 0.55959302,\n",
       "        0.55959302, 0.57122093, 0.57655039, 0.57655039, 0.5809109 ,\n",
       "        0.59544574, 0.60949617, 0.6056202 , 0.60755814, 0.62160858,\n",
       "        0.61627907, 0.61434104, 0.62209307, 0.63565891, 0.6371124 ,\n",
       "        0.66472868, 0.68556202, 0.68362398, 0.68120155, 0.6879845 ]),\n",
       " array([0.53536822, 0.56443798, 0.55232558, 0.56153101, 0.56492248,\n",
       "        0.55717054, 0.54118217, 0.54748062, 0.53246124, 0.55232558,\n",
       "        0.56686047, 0.56589147, 0.55523256, 0.55281008, 0.57800383,\n",
       "        0.57994186, 0.5755814 , 0.58284884, 0.57945736, 0.57848832,\n",
       "        0.58236429, 0.57170543, 0.5809109 , 0.58575586, 0.58575586,\n",
       "        0.59738377, 0.60949617, 0.60901163, 0.6187015 , 0.61531008,\n",
       "        0.61967054, 0.61531008, 0.61821701, 0.62257747, 0.63517437,\n",
       "        0.60513571, 0.61482553, 0.6061046 , 0.60513571, 0.60271313,\n",
       "        0.54021318, 0.55329457, 0.56782946, 0.57267442, 0.57897287,\n",
       "        0.57606589, 0.57073643, 0.58381783, 0.57218992, 0.56831395,\n",
       "        0.56540698, 0.5377907 , 0.53972868, 0.55474806, 0.54748062,\n",
       "        0.53391473, 0.5377907 , 0.54796512, 0.54651163, 0.54069767,\n",
       "        0.55474806, 0.52810078, 0.52567829, 0.53100775, 0.53197674,\n",
       "        0.53343023, 0.53827519, 0.55959302, 0.55959302, 0.55959302,\n",
       "        0.57122093, 0.57655039, 0.57655039, 0.5809109 , 0.59544574,\n",
       "        0.60949617, 0.6056202 , 0.60755814, 0.62160858, 0.61627907,\n",
       "        0.61434104, 0.62209307, 0.63565891, 0.6371124 , 0.66472868,\n",
       "        0.68556202, 0.68362398, 0.68120155, 0.6879845 , 0.68895349]),\n",
       " array([0.56443798, 0.55232558, 0.56153101, 0.56492248, 0.55717054,\n",
       "        0.54118217, 0.54748062, 0.53246124, 0.55232558, 0.56686047,\n",
       "        0.56589147, 0.55523256, 0.55281008, 0.57800383, 0.57994186,\n",
       "        0.5755814 , 0.58284884, 0.57945736, 0.57848832, 0.58236429,\n",
       "        0.57170543, 0.5809109 , 0.58575586, 0.58575586, 0.59738377,\n",
       "        0.60949617, 0.60901163, 0.6187015 , 0.61531008, 0.61967054,\n",
       "        0.61531008, 0.61821701, 0.62257747, 0.63517437, 0.60513571,\n",
       "        0.61482553, 0.6061046 , 0.60513571, 0.60271313, 0.54021318,\n",
       "        0.55329457, 0.56782946, 0.57267442, 0.57897287, 0.57606589,\n",
       "        0.57073643, 0.58381783, 0.57218992, 0.56831395, 0.56540698,\n",
       "        0.5377907 , 0.53972868, 0.55474806, 0.54748062, 0.53391473,\n",
       "        0.5377907 , 0.54796512, 0.54651163, 0.54069767, 0.55474806,\n",
       "        0.52810078, 0.52567829, 0.53100775, 0.53197674, 0.53343023,\n",
       "        0.53827519, 0.55959302, 0.55959302, 0.55959302, 0.57122093,\n",
       "        0.57655039, 0.57655039, 0.5809109 , 0.59544574, 0.60949617,\n",
       "        0.6056202 , 0.60755814, 0.62160858, 0.61627907, 0.61434104,\n",
       "        0.62209307, 0.63565891, 0.6371124 , 0.66472868, 0.68556202,\n",
       "        0.68362398, 0.68120155, 0.6879845 , 0.68895349, 0.73352713]),\n",
       " array([0.55232558, 0.56153101, 0.56492248, 0.55717054, 0.54118217,\n",
       "        0.54748062, 0.53246124, 0.55232558, 0.56686047, 0.56589147,\n",
       "        0.55523256, 0.55281008, 0.57800383, 0.57994186, 0.5755814 ,\n",
       "        0.58284884, 0.57945736, 0.57848832, 0.58236429, 0.57170543,\n",
       "        0.5809109 , 0.58575586, 0.58575586, 0.59738377, 0.60949617,\n",
       "        0.60901163, 0.6187015 , 0.61531008, 0.61967054, 0.61531008,\n",
       "        0.61821701, 0.62257747, 0.63517437, 0.60513571, 0.61482553,\n",
       "        0.6061046 , 0.60513571, 0.60271313, 0.54021318, 0.55329457,\n",
       "        0.56782946, 0.57267442, 0.57897287, 0.57606589, 0.57073643,\n",
       "        0.58381783, 0.57218992, 0.56831395, 0.56540698, 0.5377907 ,\n",
       "        0.53972868, 0.55474806, 0.54748062, 0.53391473, 0.5377907 ,\n",
       "        0.54796512, 0.54651163, 0.54069767, 0.55474806, 0.52810078,\n",
       "        0.52567829, 0.53100775, 0.53197674, 0.53343023, 0.53827519,\n",
       "        0.55959302, 0.55959302, 0.55959302, 0.57122093, 0.57655039,\n",
       "        0.57655039, 0.5809109 , 0.59544574, 0.60949617, 0.6056202 ,\n",
       "        0.60755814, 0.62160858, 0.61627907, 0.61434104, 0.62209307,\n",
       "        0.63565891, 0.6371124 , 0.66472868, 0.68556202, 0.68362398,\n",
       "        0.68120155, 0.6879845 , 0.68895349, 0.73352713, 0.74709307]),\n",
       " array([0.56153101, 0.56492248, 0.55717054, 0.54118217, 0.54748062,\n",
       "        0.53246124, 0.55232558, 0.56686047, 0.56589147, 0.55523256,\n",
       "        0.55281008, 0.57800383, 0.57994186, 0.5755814 , 0.58284884,\n",
       "        0.57945736, 0.57848832, 0.58236429, 0.57170543, 0.5809109 ,\n",
       "        0.58575586, 0.58575586, 0.59738377, 0.60949617, 0.60901163,\n",
       "        0.6187015 , 0.61531008, 0.61967054, 0.61531008, 0.61821701,\n",
       "        0.62257747, 0.63517437, 0.60513571, 0.61482553, 0.6061046 ,\n",
       "        0.60513571, 0.60271313, 0.54021318, 0.55329457, 0.56782946,\n",
       "        0.57267442, 0.57897287, 0.57606589, 0.57073643, 0.58381783,\n",
       "        0.57218992, 0.56831395, 0.56540698, 0.5377907 , 0.53972868,\n",
       "        0.55474806, 0.54748062, 0.53391473, 0.5377907 , 0.54796512,\n",
       "        0.54651163, 0.54069767, 0.55474806, 0.52810078, 0.52567829,\n",
       "        0.53100775, 0.53197674, 0.53343023, 0.53827519, 0.55959302,\n",
       "        0.55959302, 0.55959302, 0.57122093, 0.57655039, 0.57655039,\n",
       "        0.5809109 , 0.59544574, 0.60949617, 0.6056202 , 0.60755814,\n",
       "        0.62160858, 0.61627907, 0.61434104, 0.62209307, 0.63565891,\n",
       "        0.6371124 , 0.66472868, 0.68556202, 0.68362398, 0.68120155,\n",
       "        0.6879845 , 0.68895349, 0.73352713, 0.74709307, 0.7495155 ]),\n",
       " array([0.56492248, 0.55717054, 0.54118217, 0.54748062, 0.53246124,\n",
       "        0.55232558, 0.56686047, 0.56589147, 0.55523256, 0.55281008,\n",
       "        0.57800383, 0.57994186, 0.5755814 , 0.58284884, 0.57945736,\n",
       "        0.57848832, 0.58236429, 0.57170543, 0.5809109 , 0.58575586,\n",
       "        0.58575586, 0.59738377, 0.60949617, 0.60901163, 0.6187015 ,\n",
       "        0.61531008, 0.61967054, 0.61531008, 0.61821701, 0.62257747,\n",
       "        0.63517437, 0.60513571, 0.61482553, 0.6061046 , 0.60513571,\n",
       "        0.60271313, 0.54021318, 0.55329457, 0.56782946, 0.57267442,\n",
       "        0.57897287, 0.57606589, 0.57073643, 0.58381783, 0.57218992,\n",
       "        0.56831395, 0.56540698, 0.5377907 , 0.53972868, 0.55474806,\n",
       "        0.54748062, 0.53391473, 0.5377907 , 0.54796512, 0.54651163,\n",
       "        0.54069767, 0.55474806, 0.52810078, 0.52567829, 0.53100775,\n",
       "        0.53197674, 0.53343023, 0.53827519, 0.55959302, 0.55959302,\n",
       "        0.55959302, 0.57122093, 0.57655039, 0.57655039, 0.5809109 ,\n",
       "        0.59544574, 0.60949617, 0.6056202 , 0.60755814, 0.62160858,\n",
       "        0.61627907, 0.61434104, 0.62209307, 0.63565891, 0.6371124 ,\n",
       "        0.66472868, 0.68556202, 0.68362398, 0.68120155, 0.6879845 ,\n",
       "        0.68895349, 0.73352713, 0.74709307, 0.7495155 , 0.75436047])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dea955c4-3ca8-4a86-ad16-d33d03e5e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste = np.array(X_teste)\n",
    "X_teste = np.reshape(X_teste,(X_teste.shape[0],X_teste.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3e5ee93-13b0-4f30-acf9-a7b4132b40e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 90, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53311a39-ee7c-413c-8faf-7bf69eb29972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step\n"
     ]
    }
   ],
   "source": [
    "previsoes = regressor.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da5ae82a-cda0-475a-bcd6-b7005a326a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55358493],\n",
       "       [0.5575634 ],\n",
       "       [0.5618036 ],\n",
       "       [0.5681441 ],\n",
       "       [0.5750977 ],\n",
       "       [0.58100146],\n",
       "       [0.5866347 ],\n",
       "       [0.59108734],\n",
       "       [0.5934677 ],\n",
       "       [0.59483385],\n",
       "       [0.59755826],\n",
       "       [0.60188025],\n",
       "       [0.6101202 ],\n",
       "       [0.62343866],\n",
       "       [0.6383779 ],\n",
       "       [0.6505954 ],\n",
       "       [0.65873516],\n",
       "       [0.66294205],\n",
       "       [0.6697264 ],\n",
       "       [0.68154556],\n",
       "       [0.6958288 ],\n",
       "       [0.7091726 ]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e66d5b28-c83e-478c-a9a4-57faee0d90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = normalizador.inverse_transform(previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f241a84-95ca-4c29-bd77-e39b4dbbd1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.625993],\n",
       "       [15.708109],\n",
       "       [15.795626],\n",
       "       [15.926494],\n",
       "       [16.070015],\n",
       "       [16.19187 ],\n",
       "       [16.30814 ],\n",
       "       [16.400042],\n",
       "       [16.449173],\n",
       "       [16.47737 ],\n",
       "       [16.533602],\n",
       "       [16.622808],\n",
       "       [16.79288 ],\n",
       "       [17.067774],\n",
       "       [17.37612 ],\n",
       "       [17.628288],\n",
       "       [17.796293],\n",
       "       [17.883123],\n",
       "       [18.023151],\n",
       "       [18.2671  ],\n",
       "       [18.561907],\n",
       "       [18.837322]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a25b7b1-0f8f-428a-b8e8-ba3567b7832b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.190001],\n",
       "       [16.49    ],\n",
       "       [16.780001],\n",
       "       [16.700001],\n",
       "       [16.74    ],\n",
       "       [17.030001],\n",
       "       [16.92    ],\n",
       "       [16.879999],\n",
       "       [17.040001],\n",
       "       [17.32    ],\n",
       "       [17.35    ],\n",
       "       [17.92    ],\n",
       "       [18.35    ],\n",
       "       [18.309999],\n",
       "       [18.26    ],\n",
       "       [18.4     ],\n",
       "       [18.42    ],\n",
       "       [19.34    ],\n",
       "       [19.620001],\n",
       "       [19.67    ],\n",
       "       [19.77    ],\n",
       "       [19.74    ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10e175cd-9aef-44fb-b756-87f2849e02dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.92469"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc7bf421-d853-4c78-bcdf-6bf7e469fff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.87454563636364"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed428442-aca8-403a-8c4e-7bfb733c77b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9498548695956145"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_teste,previsores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e246ced-862f-4294-8231-319cd159b33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x71775b292270>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHFCAYAAAAHcXhbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABoYklEQVR4nO3dd3zM9x8H8NfJ3iQSSYwgQqhdW43YUZFQuyqoWaqlZqlVpVWjVaWqFaWqVs3Ye8+KUYSYQSJmIpGdz++Pz+8uToaEJN8br+fjcQ933/ve3Tu5xL3ymSohhAARERGRniqkdAFEREREb4NhhoiIiPQawwwRERHpNYYZIiIi0msMM0RERKTXGGaIiIhIrzHMEBERkV5jmCEiIiK9xjBDREREeo1hhozK0qVLoVKpNBdTU1OUKFECffr0wb179xSpqXTp0ujdu3euH7d27VoULlwYderUwdmzZzF48GBMnTo17wvMxJvWbMxu3boFlUqFpUuXKl3KG0tMTES9evVgYmIClUqFQoUKoWLFinjw4IHSpZGRM1W6ACIlBAUFwdvbG/Hx8Th48CBmzJiBAwcO4MKFC7CxsSnQWtavXw97e/tcP2727NkYPXo0EhMT0bJlSxQuXBg7d+7MhwqJJAsLCxw7dgwhISFwdXWFi4sLTExMlC6LiGGGjFPlypVRq1YtAICPjw9SU1Px9ddfY8OGDfjwww8zfcyLFy9gbW2d57XUqFHjjR537NgxzfUpU6bkVTl6Jz4+HpaWllCpVEqXYhRUKtUb/8wS5Rd2MxEBqFevHgDg9u3bAIDevXvD1tYWFy5cQKtWrWBnZ4fmzZsDAJKSkjBt2jR4e3vDwsICzs7O6NOnDx4+fKh5voCAAHh4eCAtLS3Da9WtWxc1a9bU3H61yyYtLQ3Tpk1DhQoVYGVlhcKFC6Nq1ar48ccfNeeEhYWhT58+8PLygrW1NYoXLw4/Pz9cuHAhw+vduXMHPXv2hIuLCywsLFCxYkXMnj0709pelZycjNGjR8PV1RXW1tZ47733cPLkyUzPvXjxIvz9/VGkSBFYWlqievXq+OOPP177GoD8gBw6dCgWLVqE8uXLw8LCApUqVcLff/+tdZ66m3Dnzp3o27cvnJ2dYW1tjcTERADAqlWrUL9+fdjY2MDW1hatW7fG2bNnM7zeiRMn4OfnBycnJ1haWsLT0xOff/651jmHDx9G8+bNYWdnB2trazRo0ADBwcE5+nru37+PLl26wM7ODg4ODujatSsiIyMznHf69Gl069YNpUuXhpWVFUqXLo3u3btrfg7VXrx4gZEjR6JMmTKwtLSEo6MjatWqhZUrV2Zbx8OHD/HJJ5+gUqVKsLW1hYuLC5o1a4ZDhw5lODcxMRFTp05FxYoVYWlpCScnJ/j4+ODo0aOacxISEjBu3DiUKVMG5ubmKF68OIYMGYJnz55leL6cvBc3btxAt27d4O7uDgsLCxQrVgzNmzdHSEhItl8X0avYMkMEGQ4AwNnZWXMsKSkJ7du3x8CBAzF27FikpKQgLS0N/v7+OHToEEaPHo0GDRrg9u3bmDRpEpo2bYrTp0/DysoKffv2hb+/P/bu3YsWLVponvPKlSs4efIk5s2bl2UtM2fOxOTJkzFhwgQ0btwYycnJuHLlitYHxv379+Hk5IRvv/0Wzs7OePLkCf744w/UrVsXZ8+eRYUKFQDID7MGDRogKSkJX3/9NUqXLo0tW7Zg5MiRuH79OhYsWJDt96V///5YtmwZRo4ciZYtW+LixYvo2LEjnj9/rnVeaGgoGjRoABcXF8ybNw9OTk74888/0bt3bzx48ACjR49+7XuwadMm7Nu3D1OnToWNjQ0WLFiA7t27w9TUFJ06ddI6t2/fvnj//fexfPlyxMXFwczMDNOnT8eECRPQp08fTJgwAUlJSfj+++/RqFEjnDx5EpUqVQIA7NixA35+fqhYsSLmzJmDUqVK4datW1pddAcOHEDLli1RtWpV/P7777CwsMCCBQvg5+eHlStXomvXrll+HfHx8WjRogXu37+PGTNmoHz58ggODs70Mbdu3UKFChXQrVs3ODo6IiIiAgsXLkTt2rVx6dIlFC1aFAAwYsQILF++HNOmTUONGjUQFxeHixcv4vHjx9l+T588eQIAmDRpElxdXREbG4v169ejadOm2LNnD5o2bQoASElJga+vLw4dOoTPP/8czZo1Q0pKCo4fP447d+6gQYMGEEIgICAAe/bswbhx49CoUSOcP38ekyZNwrFjx3Ds2DFYWFgAQI7fi7Zt2yI1NRUzZ85EqVKl8OjRIxw9ejTTcESULUFkRIKCggQAcfz4cZGcnCyeP38utmzZIpydnYWdnZ2IjIwUQggRGBgoAIglS5ZoPX7lypUCgFi3bp3W8VOnTgkAYsGCBUIIIZKTk0WxYsVEjx49tM4bPXq0MDc3F48ePdIc8/DwEIGBgZrb7dq1E9WrV8/V15WSkiKSkpKEl5eXGD58uOb42LFjBQBx4sQJrfMHDx4sVCqVCA0NzfI5L1++LABoPZ8QQqxYsUIA0Kq5W7duwsLCQty5c0frXF9fX2FtbS2ePXuWbf0AhJWVleb7r/6avL29Rbly5TTH1O9fr169tB5/584dYWpqKj799FOt48+fPxeurq6iS5cummOenp7C09NTxMfHZ1lPvXr1hIuLi3j+/LlWPZUrVxYlSpQQaWlpWT524cKFAoDYuHGj1vH+/fsLACIoKCjLx6akpIjY2FhhY2MjfvzxR83xypUri4CAgCwfl1MpKSkiOTlZNG/eXHTo0EFzfNmyZQKAWLx4cZaP3b59uwAgZs6cqXV81apVAoD49ddfhRA5fy8ePXokAIgffvjhrb8uInYzkVGqV68ezMzMYGdnh3bt2sHV1RXbtm1DsWLFtM774IMPtG5v2bIFhQsXhp+fH1JSUjSX6tWrw9XVFfv37wcAmJqaomfPnvjnn38QHR0NAEhNTcXy5cvh7+8PJyenLGurU6cOzp07h08++QQ7duxATExMhnNSUlIwffp0VKpUCebm5jA1NYW5uTmuXbuGy5cva87bu3cvKlWqhDp16mg9vnfv3hBCYO/evVnWsW/fPgDIMIaoS5cuMDXVbtTdu3cvmjdvjpIlS2Z4nRcvXmiN78lK8+bNtb7/JiYm6Nq1K8LCwnD37l2tc199X3bs2IGUlBT06tVL632xtLREkyZNNO/L1atXcf36dXz88cewtLTMtI64uDicOHECnTp1gq2trVY9H330Ee7evYvQ0NAsv459+/bBzs4O7du31zreo0ePDOfGxsZizJgxKFeuHExNTWFqagpbW1vExcVpvY916tTBtm3bMHbsWOzfvx/x8fFZvv6rfvnlF9SsWROWlpYwNTWFmZkZ9uzZo/X827Ztg6WlJfr27Zvl86h/Vl6dxda5c2fY2Nhgz549AHL+Xjg6OsLT0xPff/895syZg7Nnz+ao65MoMwwzZJSWLVuGU6dO4ezZs7h//z7Onz+Phg0bap1jbW2dYZbRgwcP8OzZM5ibm8PMzEzrEhkZiUePHmnO7du3LxISEjTjPnbs2IGIiAj06dMn29rGjRuHWbNm4fjx4/D19YWTkxOaN2+O06dPa84ZMWIEvvrqKwQEBGDz5s04ceIETp06hWrVqml90D1+/Bhubm4ZXsPd3V1zf1bU97m6umodNzU1zRDG3uZ11F59nZePvfr4V19LPTW4du3aGd6XVatWad4X9bimEiVKZFnH06dPIYR4q+/bq6E4q6+vR48emD9/Pvr164cdO3bg5MmTOHXqFJydnbXex3nz5mHMmDHYsGEDfHx84OjoiICAAFy7di3LOgBgzpw5GDx4MOrWrYt169bh+PHjOHXqFNq0aaP1/A8fPoS7uzsKFcr6I+Hx48cwNTXV6ooF5HgnV1dXzfckp++FSqXCnj170Lp1a8ycORM1a9aEs7Mzhg0blqEbk+h1OGaGjFLFihU1s5myktnsmKJFi8LJyQnbt2/P9DF2dnaa6+oWkaCgIAwcOBBBQUFwd3dHq1atsn1dU1NTjBgxAiNGjMCzZ8+we/dufPnll2jdujXCw8NhbW2NP//8E7169cL06dO1Hvvo0SMULlxYc9vJyQkREREZXuP+/fuarycr6sASGRmJ4sWLa46npKRk+DB/m9dRy2yArPrYq+Hp1fdG/fxr166Fh4dHlq+h/iB+taXnZUWKFEGhQoXe6vuW2SDpV7++6OhobNmyBZMmTcLYsWM1xxMTEzVjXdRsbGwwZcoUTJkyBQ8ePNC00vj5+eHKlStZ1vLnn3+iadOmWLhwodbxV8OCs7MzDh8+jLS0tCwDjZOTE1JSUvDw4UOtQCOEQGRkJGrXrg0g5+8FAHh4eOD3338HIFvNVq9ejcmTJyMpKQm//PJLto8lehlbZohyoV27dnj8+DFSU1NRq1atDBf1wFu1Pn364MSJEzh8+DA2b96MwMDAXK3LUbhwYXTq1AlDhgzBkydPcOvWLQDyw1w92FItODg4w8J/zZs3x6VLl/Dvv/9qHV+2bBlUKhV8fHyyfG314NAVK1ZoHV+9ejVSUlIyvM7evXs1H/Yvv461tbVmtlh29uzZo7X4WmpqKlatWgVPT89sW1IAoHXr1jA1NcX169czfV/UwbV8+fLw9PTEkiVLNDOgXmVjY4O6devin3/+0Wq9SEtLw59//okSJUqgfPnyWdbi4+OD58+fY9OmTVrH//rrL63bKpUKQogM7+Nvv/2G1NTULJ+/WLFi6N27N7p3747Q0FC8ePEiy3Mz+zk5f/58hm4/X19fJCQkZLugn3o2359//ql1fN26dYiLi9Pcn9P34lXly5fHhAkTUKVKlQw/r0Svw5YZolzo1q0bVqxYgbZt2+Kzzz5DnTp1YGZmhrt372Lfvn3w9/dHhw4dNOd3794dI0aMQPfu3ZGYmJijVXP9/Pw06+A4Ozvj9u3b+OGHH+Dh4QEvLy8AMlQtXboU3t7eqFq1Ks6cOYPvv/8+w4f+8OHDsWzZMrz//vuYOnUqPDw8EBwcjAULFmDw4MHZfihXrFgRPXv2xA8//AAzMzO0aNECFy9exKxZszJ0v02aNAlbtmyBj48PJk6cCEdHR6xYsQLBwcGYOXMmHBwcXvt1Fy1aFM2aNcNXX32lmc105cqVDNOzM1O6dGlMnToV48ePx40bN9CmTRsUKVIEDx48wMmTJzUtGwDw888/w8/PD/Xq1cPw4cNRqlQp3LlzBzt27NAEtxkzZqBly5bw8fHByJEjYW5ujgULFuDixYtYuXJltmva9OrVC3PnzkWvXr3wzTffwMvLC1u3bsWOHTu0zrO3t0fjxo3x/fffo2jRoihdujQOHDiA33//Xat1DZDT+du1a4eqVauiSJEiuHz5MpYvX4769etnu/ZRu3bt8PXXX2PSpElo0qQJQkNDMXXqVJQpU0YrkHbv3h1BQUEYNGgQQkND4ePjg7S0NJw4cQIVK1ZEt27d0LJlS7Ru3RpjxoxBTEwMGjZsqJnNVKNGDXz00Ue5ei/Onz+PoUOHonPnzvDy8oK5uTn27t2L8+fPa7VUEeWIsuOPiQqWejbMqVOnsj0vMDBQ2NjYZHpfcnKymDVrlqhWrZqwtLQUtra2wtvbWwwcOFBcu3Ytw/k9evQQAETDhg0zfb5XZzPNnj1bNGjQQBQtWlSYm5uLUqVKiY8//ljcunVLc87Tp0/Fxx9/LFxcXIS1tbV47733xKFDh0STJk1EkyZNtJ7/9u3bokePHsLJyUmYmZmJChUqiO+//16kpqZm+z0QQojExETxxRdfCBcXF2FpaSnq1asnjh07lqFmIYS4cOGC8PPzEw4ODsLc3FxUq1Yt25k7LwMghgwZIhYsWCA8PT2FmZmZ8Pb2FitWrNA673Xv34YNG4SPj4+wt7cXFhYWwsPDQ3Tq1Ens3r1b67xjx44JX19fYWdnJwAIT0/PDLO2Dh06JJo1ayZsbGyElZWVqFevnti8eXOOvp67d++KDz74QNja2go7OzvxwQcfiKNHj2aYzaQ+r0iRIsLOzk60adNGXLx4McP3d+zYsaJWrVqiSJEiwsLCQpQtW1YMHz5ca1ZcZhITE8XIkSNF8eLFhaWlpahZs6bYsGGDCAwMFB4eHlrnxsfHi4kTJwovLy8BQAAQzZo1E0ePHtU6Z8yYMcLDw0OYmZkJNzc3MXjwYPH06dMMr/269+LBgweid+/ewtvbW9jY2AhbW1tRtWpVMXfuXJGSkpKj7zORmkoIIZSLUkREsjtkyJAhmD9/foG/du/evdGiRQv07NmzwF9bV4WFhaFDhw74999/YWZmpnQ5RK/FMTNEZJSOHz+OQ4cOITExEWvXrlW6HJ3w/PlzbNu2DVeuXMHVq1fx33//KV0SUY5wzAwRGaWNGzdi7ty5KFKkCH766Sely9EJsbGx6Nu3L54+fYqmTZvC29tb6ZKIcoTdTERERKTX2M1EREREeo1hhoiIiPQawwwRERHpNYMfAJyWlob79+/Dzs4u24WuiIiISHcIIfD8+fPX7hsGGEGYuX//foadfImIiEg/hIeHv3ZLE4MPM+qN/8LDwzMswU5ERES6KSYmBiVLltTawDcrBh9m1F1L9vb2DDNERER6JidDRDgAmIiIiPQawwwRERHpNYYZIiIi0msGP2Ymp1JTU5GcnKx0GZSHzMzMYGJionQZRESUz4w+zAghEBkZiWfPnildCuWDwoULw9XVlWsMEREZMKMPM+og4+LiAmtra37oGQghBF68eIGoqCgAgJubm8IVERFRfjHqMJOamqoJMk5OTkqXQ3nMysoKABAVFQUXFxd2ORERGSijHgCsHiNjbW2tcCWUX9TvLcdDEREZLqMOM2rsWjJcfG+JiAwfwwwRERHpNYYZ0ktLly5F4cKFlS6DiIh0AMOMHurduzdUKhVUKhXMzMxQtmxZjBw5EnFxcUqXRkREVOCMejaTPmvTpg2CgoKQnJyMQ4cOoV+/foiLi8PChQsznJucnAwzMzMFqsxIl2ohIjIqCQnAixdAkSKAgY0nZMuMnrKwsICrqytKliyJHj164MMPP8SGDRsAAJMnT0b16tWxZMkSlC1bFhYWFhBCIDo6GgMGDICLiwvs7e3RrFkznDt3Tut5N23ahFq1asHS0hJFixZFx44dNfc9ffoUvXr1QpEiRWBtbQ1fX19cu3Yt2zpVKhV++eUX+Pv7w8bGBtOmTQMAbN68Ge+++y4sLS1RtmxZTJkyBSkpKZrHzZkzB1WqVIGNjQ1KliyJTz75BLGxsXn03SMiMhJpacCBA0Dv3kDRooCTE2BjA1SoALRoAfTpA0ycCCxeDGzfDvz3HxATo3TVucaWmVcJIZNrQbO2fqukbGVlpTX9OCwsDKtXr8a6des066u8//77cHR0xNatW+Hg4IBFixahefPmuHr1KhwdHREcHIyOHTti/PjxWL58OZKSkhAcHKx5zt69e+PatWvYtGkT7O3tMWbMGLRt2xaXLl3KtrVl0qRJmDFjBubOnQsTExPs2LEDPXv2xLx589CoUSNcv34dAwYM0JwLAIUKFcK8efNQunRp3Lx5E5988glGjx6NBQsWvPH3iIjIaNy+Dfzxh7zcuKF9X3w8cPWqvGTF3h4oWTL7y//X8tIJwsBFR0cLACI6OjrDffHx8eLSpUsiPj4+/WBsrBAy0hTsJTY2x19TYGCg8Pf319w+ceKEcHJyEl26dBFCCDFp0iRhZmYmoqKiNOfs2bNH2Nvbi4SEBK3n8vT0FIsWLRJCCFG/fn3x4YcfZvqaV69eFQDEkSNHNMcePXokrKysxOrVq7OsFYD4/PPPtY41atRITJ8+XevY8uXLhZubW5bPs3r1auHk5KS5HRQUJBwcHLI8Xy3T95iIyBDFxQmxfLkQzZsLoVKlf77Y2QnRr58QR44IER8vRFiYEPv2CbFsmRDffCPEwIFCtG0rRJUqQhQunPPPLScnIapXF8LPTz5XHsvu8/tVbJnRU1u2bIGtrS1SUlKQnJwMf39//PTTT5r7PTw84OzsrLl95swZxMbGZljpOD4+HtevXwcAhISEoH///pm+3uXLl2Fqaoq6detqjjk5OaFChQq4fPlytrXWqlVL6/aZM2dw6tQpfPPNN5pjqampSEhIwIsXL2BtbY19+/Zh+vTpuHTpEmJiYpCSkoKEhATExcXBxsbmNd8dIiIjIQRw7BgQFASsWgU8f55+X7NmshupY0fZ+q/m6SkvWYmNBcLDs7/ExQGPH8tLSAhQrVq+fYk5wTDzKmtr+UYq8bq54OPjg4ULF8LMzAzu7u4Zunle/cBPS0uDm5sb9u/fn+G51FOcrbJpMhRCZHn8dQvTZVbLlClTtMbjqFlaWuL27dto27YtBg0ahK+//hqOjo44fPgwPv74Y67kS0QEAPfuAcuWAUuXancXlSkjx8cEBgIeHm/23La2QMWK8pIZIYBnz7TDzbvvvtlr5RGGmVepVHJwlI6zsbFBuXLlcnx+zZo1ERkZCVNTU5QuXTrTc6pWrYo9e/agT58+Ge6rVKkSUlJScOLECTRo0AAA8PjxY1y9ehUVs/qBz6aW0NDQLOs/ffo0UlJSMHv2bBQqJMeor169OlevQURkcBISgI0bZYDZuVMO7gXkH8OdO8tWmEaNgEL5PLdHpZIzoooUAapWzd/XyiGGGSPRokUL1K9fHwEBAfjuu+9QoUIF3L9/H1u3bkVAQABq1aqFSZMmoXnz5vD09ES3bt2QkpKCbdu2YfTo0fDy8oK/vz/69++PRYsWwc7ODmPHjkXx4sXh7++fq1omTpyIdu3aoWTJkujcuTMKFSqE8+fP48KFC5g2bRo8PT2RkpKCn376CX5+fjhy5Ah++eWXfPrOEBHpMCGA06dlgFm5Enj6NP2+Ro1kgOnUCbCzU6xEXcCp2UZCpVJh69ataNy4Mfr27Yvy5cujW7duuHXrFooVKwYAaNq0KdasWYNNmzahUqVKqFWrFk6cOKF5jqCgILz77rto164d6tevDyEEtm7dmut1Y1q3bo0tW7Zg165dqF27NurVq4c5c+bA4/9NotWrV8ecOXPw3XffoXLlylixYgVmzJiRd98MIiJdFxkJzJoFVKkC1KkDLFggg0zJksCECcC1a8DBgzLMGHmQAQCVyGowhIGIiYmBg4MDoqOjYW9vr3VfQkICbt68iTJlysDS0lKhCnXT0aNHsXDhQixfvlzpUt4K32Mi0nkPH8pBtGfPyn9DQoDQ0PRuJEtLOYi3d285qPf/y20Yuuw+v1/FbibK4MqVK0hNTcWmTZuULoWIyHCkpQE3b2oHl7Nngfv3Mz+/Xj0ZYLp2BbgXXbYYZiiDIUOG4MiRIwgMDFS6FCIi/ZSYCFy6pN3aEhKiPXX6ZV5eQPXqQI0a8t/q1QE3t4KqVu8xzFAGe/bsUboEIiL98ewZcO6cdmvLpUvAS1u0aFhYAJUra4eWqlU57uUtMcwQERG9idhYoEsXYNu2zO8vUkS7taVGDbknEjfbzXMMM0RERLmVkAD4+wN798rbHh7arS01asiZRwa2O7WuYpghIiLKjeRk2SKzd69cLXfXLjlYlxTDdWaIiIhyKjVVbhWwebOcMr15M4OMDmCYISIiygkhgMGD5Uq8pqbA2rVA06ZKV0VgmCEiIno9IYCRI4HFi+XeRytWAO+/r3RV9H8MM5Rj+/fvh0qlwrNnz5QuhYioYH39NTBnjry+eLEcM0M6g2FGT/Xu3RsqlQoqlQpmZmYoW7YsRo4cibi4uHx7zQYNGiAiIgIODg759hpERDpn7lxg0iR5/YcfgL59FS2HMuJsJj3Wpk0bBAUFITk5GYcOHUK/fv0QFxeHhQsXap2XnJyc680gM2Nubg5XV9e3fp6sJCUlwdzcPN+en4go1377DRgxQl7/+mvgs8+UrYcyxZYZPWZhYQFXV1eULFkSPXr0wIcffogNGzZg8uTJqF69OpYsWYKyZcvCwsICQghER0djwIABcHFxgb29PZo1a4Zz584BAEJDQ6FSqXDlyhWt15gzZw5Kly4NIUSGbqbbt2/Dz88PRYoUgY2NDd555x1s3bpV89gDBw6gTp06sLCwgJubG8aOHYuUl1bEbNq0KYYOHYoRI0agaNGiaNmyJQDg0qVLaNu2LWxtbVGsWDF89NFHePTokeZxa9euRZUqVWBlZQUnJye0aNEiX1ukiMhIrVoFDBggr48aBYwfr2w9lCWGmVcIAcTFFfwlL/Yut7KyQnJyMgAgLCwMq1evxrp16xASEgIAeP/99xEZGYmtW7fizJkzqFmzJpo3b44nT56gQoUKePfdd7FixQqt5/zrr7/Qo0cPqDJZ+GnIkCFITEzEwYMHceHCBXz33XewtbUFANy7dw9t27ZF7dq1ce7cOSxcuBC///47pk2bpvUcf/zxB0xNTXHkyBEsWrQIERERaNKkCapXr47Tp09j+/btePDgAbr8v386IiIC3bt3R9++fXH58mXs378fHTt2hIFv/k5EBW3zZqBnT/mf86BBwHffcQE8XSYMXHR0tAAgoqOjM9wXHx8vLl26JOLj4zXHYmOFkD+9BXuJjc3d1xUYGCj8/f01t0+cOCGcnJxEly5dxKRJk4SZmZmIiorS3L9nzx5hb28vEhIStJ7H09NTLFq0SAghxJw5c0TZsmU194WGhgoA4r///hNCCLFv3z4BQDx9+lQIIUSVKlXE5MmTM63vyy+/FBUqVBBpaWmaYz///LOwtbUVqampQgghmjRpIqpXr671uK+++kq0atVK61h4eLgAIEJDQ8WZM2cEAHHr1q2cfJsyfY+JiLK1Z48QFhbyP+cPPxTi//9nUcHK7vP7VWyZ0WNbtmyBra0tLC0tUb9+fTRu3Bg//fQTAMDDwwPOzs6ac8+cOYPY2Fg4OTnB1tZWc7l58yauX78OAOjWrRtu376N48ePAwBWrFiB6tWro1KlSpm+/rBhwzBt2jQ0bNgQkyZNwvnz5zX3Xb58GfXr19dq0WnYsCFiY2Nx9+5dzbFatWppPeeZM2ewb98+rRq9vb0BANevX0e1atXQvHlzVKlSBZ07d8bixYvx9OnTt/k2EhGlO34caN9e7nrt7w8EBcmp2KTTOAD4FdbWcu8wJV43t3x8fLBw4UKYmZnB3d1da5CvjY2N1rlpaWlwc3PD/v37MzxP4cKFAQBubm7w8fHBX3/9hXr16mHlypUYOHBglq/fr18/tG7dGsHBwdi5cydmzJiB2bNn49NPP4UQIkPXlPh/V9DLxzOr08/PD999912G13Nzc4OJiQl27dqFo0ePYufOnfjpp58wfvx4nDhxAmXKlMmyViKi1zp3DvD1lX3/LVoAf//NTSH1BMPMK1Qq4JXPV51lY2ODcuXK5ejcmjVrIjIyEqampihdunSW53344YcYM2YMunfvjuvXr6Nbt27ZPm/JkiUxaNAgDBo0COPGjcPixYvx6aefolKlSli3bp1WqDl69Cjs7OxQvHjxbOtct24dSpcuDVPTzH88VSoVGjZsiIYNG2LixInw8PDA+vXrMUI944CIKLdCQ4FWrYBnz4AGDYANG+R2BaQX2HZmJFq0aIH69esjICAAO3bswK1bt3D06FFMmDABp0+f1pzXsWNHxMTEYPDgwfDx8ck2eHz++efYsWMHbt68iX///Rd79+5FxYoVAQCffPIJwsPD8emnn+LKlSvYuHEjJk2ahBEjRqBQNk22Q4YMwZMnT9C9e3ecPHkSN27cwM6dO9G3b1+kpqbixIkTmD59Ok6fPo07d+7gn3/+wcOHDzWvS0SUa7dvy5aYqCi543VwsP78VUsA2DJjNFQqFbZu3Yrx48ejb9++ePjwIVxdXdG4cWMUK1ZMc569vT38/PywZs0aLFmyJNvnTE1NxZAhQ3D37l3Y29ujTZs2mDt3LgCgePHi2Lp1K0aNGoVq1arB0dERH3/8MSZMmJDtc7q7u+PIkSMYM2YMWrdujcTERHh4eKBNmzYoVKgQ7O3tcfDgQfzwww+IiYmBh4cHZs+eDV9f37f/JhGR8YmIAJo3B+7eBby9gZ07gf93vZP+UAn1QAYDFRMTAwcHB0RHR8Pe3l7rvoSEBNy8eRNlypSBJZsTDRLfYyLK0uPHcqPIixeB0qWBQ4eAEiWUror+L7vP71exm4mIiIxPTIwc7HvxIuDmBuzezSCjxxhmiIjIuLx4Afj5AadOAU5OMsh4eipdFb0FhhkiIjIeSUlAp07AwYOAvT2wYweQxVpapD8YZoiIyDikpAAffghs2wZYWclZS+++q3RVlAcYZpC+mBsZHr63RAQASEsD+vcH1q4FzM3lOjLvvad0VZRHjDrMqFfMffHihcKVUH5Rv7dmXMWTyLgtXw4sXQqYmMiVfVu1UroiykNGvc6MiYkJChcujKioKACAtbV1prtDk/4RQuDFixeIiopC4cKFYWJionRJRKSkdevkv19+CXTooGwtlOeMOswAgKurKwBoAg0ZlsKFC2veYyIyUgkJwJ498nrHjsrWQvnC6MOMSqWCm5sbXFxckJycrHQ5lIfMzMzYIkNEcubSixdyPZlq1ZSuhvKB0YcZNRMTE37wEREZom3b5L9t28rdhMngGPUAYCIiMgJbt8p/uYebwWKYISIiw3X9OnD1KmBqKnfGJoPEMENERIZL3cX03nuAg4OytVC+YZghIiLDxS4mo8AwQ0REhik+Hti3T15v21bZWihfMcwQEZFh2r9frjFTsiTwzjtKV0P5iGGGiIgMk7qLiVOyDR7DDBERGR4hOF7GiDDMEBGR4bl6FbhxAzAzA5o3V7oaymcMM0REZHjUU7KbNAFsbZWthfIdwwwRERkedjEZFYYZIiIyLLGxwIED8jqnZBsFhhkiIjIs+/YBSUlAmTJAhQpKV0MFgGGGiIgMy8tdTJySbRQYZoiIyHC8PCWbXUxGg2GGiIgMx+XLwJ07gIUF4OOjdDVUQBhmiIjIcKhbZZo2BaytFS2FCg7DDBERGQ52MRklhhkiIjIMMTHA4cPyOsOMUVE0zBw8eBB+fn5wd3eHSqXChg0btO5/8OABevfuDXd3d1hbW6NNmza4du2aMsUSEZFu27MHSE4GvLyAcuWUroYKkKJhJi4uDtWqVcP8+fMz3CeEQEBAAG7cuIGNGzfi7Nmz8PDwQIsWLRAXF6dAtUREpNO46q/RMlXyxX19feGbxQ/dtWvXcPz4cVy8eBHvvPMOAGDBggVwcXHBypUr0a9fv4IslYiIdJkQ6fsxsYvJ6OjsmJnExEQAgKWlpeaYiYkJzM3NcVjdJ5rF42JiYrQuRERk4C5cAO7dA6ys5OaSZFR0Nsx4e3vDw8MD48aNw9OnT5GUlIRvv/0WkZGRiIiIyPJxM2bMgIODg+ZSsmTJAqyaiIgUoe5iatYMeOmPYDIOOhtmzMzMsG7dOly9ehWOjo6wtrbG/v374evrCxMTkywfN27cOERHR2su4eHhBVg1EREpgl1MRk3RMTOv8+677yIkJATR0dFISkqCs7Mz6tati1q1amX5GAsLC1hYWBRglUREpKhnz4AjR+R1Dv41SjrbMvMyBwcHODs749q1azh9+jT8/f2VLomIiHTFrl1Aairg7S13yiajo2jLTGxsLMLCwjS3b968iZCQEDg6OqJUqVJYs2YNnJ2dUapUKVy4cAGfffYZAgIC0KpVKwWrJiIincIuJqOnaJg5ffo0fF7aCGzEiBEAgMDAQCxduhQREREYMWIEHjx4ADc3N/Tq1QtfffWVUuUSEZGuSUtjmCGohBBC6SLyU0xMDBwcHBAdHQ17e3ulyyEiorz077/Au+8CtrbAo0dyt2wyCLn5/NaLMTNERESZUk/Jbt6cQcaIMcwQEZH+YhcTgWGGiIj01ePHwPHj8jqnZBs1hhkiItJPO3fKAcCVKwNc7d2oMcwQEZF+YhcT/R/DDBER6R9OydYJ9+4BHToAUVHK1qHT2xkQERFl6vRpORXb3h5o0EDpaoxSVBTQogVw5QqQlAQEBytXC1tmiIhI/6hbZVq2BMzMlK3FCD15Ir/1V64AJUoAP/+sbD0MM0REpH/U68uwi6nARUcDrVsD588Drq7A3r1A6dLK1sQwQ0RE+uXhQ+DUKXm9TRtlazEysbEyP54+DTg5Abt3A15eSlfFMENERPpmxw5ACKB6dcDdXelqjEZ8PODvDxw9Cjg4yM3K33lH6aokhhkiItIv7GIqcImJwAcfyC4lW1tg+3agRg2lq0rHMENERPojNVW2zAAMMwUkJQXo3l2OubaykrOW6tVTuiptDDNERKQ/Tp6UU2kKFwbq1lW6GoOXmgoEBgLr1wPm5sDGjUDjxkpXlRHDDBER6Q91F1Pr1oApl0rLT2lpwMCBwF9/yW/12rVyOrYuYpghIiL9wfEyBUIIYNgw4PffgUKFZKDx81O6qqwxzBARkX6IjAT+/Vdeb91a2VoMmBDA6NFyITyVCli6FOjcWemqsscwQ0RE+mH7dvlvrVpAsWLK1mLApkwBZs2S13/5BfjoI2XryQmGGSIi0g/sYsp3330nwwwA/PADMGCAouXkGMMMERHpvpQUYOdOed3XV9laDNRPPwFjx8rrM2YAn32mbD25wTBDRES679gxuSmQkxNQu7bS1Ric336TA34B4Kuv0kONvmCYISIi3afuYmrTBjAxUbYWA7NiRXp30hdfpHcz6ROGGSIi0n3qMMMupjy1bp1cFE8IYPBg4Pvv5QwmfcMwQ0REuu3ePeD8efkpyynZeSY4GOjWTa7y27s3MH++fgYZgGGGiIh03bZt8t+6dYGiRZWtxUDs3i03jkxJkYHmt9/k4nj6So9LJyIio8Ap2Xnq0CHA31/uhB0QACxbpv/DkBhmiIhIdyUlyWYEgONl8sDJk8D77wMvXsix1H//DZiZKV3V22OYISIi3XXkCPD8OeDiAtSsqXQ1ei0kRA45ev4c8PEB/vkHsLBQuqq8wTBDRES66+VZTPo8qENh164BrVoBz54B9esDmzYBVlZKV5V3+JNBRES6Sz34l11MbywyUrbIPHwI1Kghv6W2tkpXlbcYZoiISDfdvg38959skWnVSulq9NLz53Lc9M2bQNmyMsg4OChdVd5jmCEiIt2kbpVp0AAoUkTZWvRQUhLQsSNw9izg7Azs2GG4m40zzBARkW5iF9MbS0sD+vSRE8FsbOTQo3LllK4q/zDMEBGR7klMTJ+SzfVlcm30aOCvvwBTU7llQa1aSleUvxhmiIhI9xw8KBdDcXMDqlVTuhq9Mnu2vADAkiXGsQMEwwwREemel7uY9HXDIAX89RcwcqS8PnMm8NFHytZTUBhmiIhI93ALg1zbvVtuGAkAn32WHmqMAcMMERHplhs3gNBQOeCjRQulq9ELZ88CHToAyclAly7AnDnG1aDFMENERLpF3cX03nuGuShKHrtxQ/bGxcbKbQqWLTO+xZJNlS6AiIiMTHIy8OQJ8Pgx8OiR/Pfl65s2yfM4Jfu1oqLkAN8HD+Q46fXrDWe/pdxgmCEiojeXmCjXyX81kGR3PTo6Z8/t55e/teu52FigXTsgLAzw8DDc1X1zgmGGiIhy78ED4JtvgF9/lYEmt1Qquaqvk5O8FC2qfb1mTaBixbyv20AkJwOdOwOnTslv2Y4dcha7sWKYISKinIuOBmbNAubOBeLi5DETk8wDSXbXixSRj6NcEwLo1w/Yvh2wtgaCg4EKFZSuSlkMM0RE9Hrx8cD8+cC338rxLgBQuzYwYwbQrJlxTZ1R2JdfykG+JibA6tVA3bpKV6Q8hhkiIspacjIQFARMmQLcvy+PVawou5gCAhhiCti8eTJPAsDixcD77ytbj65gmCEielOffQb88QdQpoxs5y9fXv6rvm5vr3SFby4tTf7Z/9VXcoQpAJQqJUPNRx+xi0gBq1cDn38ur3/zjdxIkiSGGSKiN7F7t/wzGQBCQuTlVa6umYecMmUAM7OCrDbnhJCDMb78Mv1rcnYGxo8HBg0yznm/OmDfPpkhhQCGDAHGjVO6It3CMENElFsJCcAnn8jrH38M+PvLFWtDQ4GrV+W/Dx4AkZHycuCA9uNNTQFPz4whp0IFwMVFua6bI0fkp+ShQ/K2nR0wapRsDrCzU6YmwrlzskcvKQn44APgxx/Zu/cqlRBCKF1EfoqJiYGDgwOio6Nhr89NvkSkO6ZMASZPlnNhL1/OfHGPZ8+Aa9cyhpyrV+Vg2qw4OMhgU6UKUKMGUL06ULVq/nZZnT8vW162bJG3LSyAoUOBsWPl7CNSzK1bQIMGQEQE0LixnIJtaal0VQUjN5/fDDNERLlx7RpQubL8M/nvv4GuXXP3+LQ04N69jCEnNBS4fVv2I2SmXDkZbNSXGjVkmHqbP9Fv3AAmTpRbLQshx8H06SOPlSz55s9LeeLRI7mjQ2io/JE7dAgoXFjpqgoOw8xLGGaIKM8IIdeO37ULaNVKji3Jy/b+hAQ52PbKFdm3oB6Lc/du5uc7O6cHG3XIKV/+9YNzIyKAadPkgncpKfJYly7A11/Lx5Pi4uKA5s2BEydkrjx2DCheXOmqChbDzEsYZogoz/z9N9C9u+yGuXhRtpYUhIcP08PN2bPy3ytXZCvPq6ysZLfUyyGnShW5utrTp8DMmXLQhbqrq3VrYPp0ueIu6YSUFDlGJjhYri145IhxLobMMPMShhkiyhPR0YC3txzQO2WK7IpRUnw8cOFCeuvN2bNy7MuLFxnPLVRIDi6OiJBjeQCgfn254F2TJgVYNL1OYiLw4YfAunVybMyePXLMjDHKzec3ZzMREeXEhAkyyJQvD4wZo3Q1sgWmTh15UUtNld1U6tYbdciJipIDlQE5+OKbb+QmjpwSo1OePwc6dJABxtxcritjrEEmt9gyQ0T0OqdPy9AghFxfpnlzpSvKOSFkCDt7VrbQtGzJBe900KNHgK+v/FGztQU2bNCvH7P8wJYZIqK8kpoqF4sTAujRQ/8+YVQqOevJmLdU1nF37sjx5KGhcg/ObdvktleUcwwzRETZWbgQOHNGrv8ye7bS1ZCBuXxZBpm7d4ESJeREOW9vpavSP4WULoCISGfdvy+X9QfkYFlXV2XrIYNy6hTQqJEMMt7ewNGjDDJvimGGiCgrI0bIUZm1awMDBihdDRmQ3bsBHx/g8WP543XoENcpfBsMM0REmdm5E1i1Sg6a/eUXDpqlPLN2LfD+++kL4+3Zw10j3hbDDBHRq+Lj0zeSHDqUC8pRnvn1V7nYsnrTyOBg7uGZFxhmiIhe9e23wPXrcgbQ118rXQ0ZACHksKuBA+X1AQNkw5+FhdKVGQaGGSKil129KsMMIJf95/pU9JbS0oAvvkgfS/7ll+y5zGucmk1EpCaE7F5KSpJ7FnXqpHRFpOeSk4F+/YBly+Tt2bPluHLKWwwzRERqK1fK0ZgWFsDPP3O5f3or8fFA167A5s2yFWbJEqBXL6WrMkwMM0REgNyAUf0n84QJgKenouWQfouOlttfHTokN4xcvVrepvzBMENEBADjxwMPHsjdpUeNUroa0mMPHsheynPn5JCrzZuBxo2VrsqwMcwQEZ08KbctAIAFCzjFhN7YzZtye4KwMMDFBdixA6heXemqDB/DDBEZt5SU9I0ke/YEmjVTuiLSUxcvyiATEQGULi33WSpXTumqjAOnZhORcVuwADh7FihcGJg1S+lqSE8dPSr3WYqIACpXBo4cYZApSIqGmYMHD8LPzw/u7u5QqVTYsGGD1v2xsbEYOnQoSpQoASsrK1SsWBEL1U3BRERv6/59OdgXkCuaFSumbD2kl7ZtA1q0kGPI69cHDh4E3N2Vrsq4KBpm4uLiUK1aNcyfPz/T+4cPH47t27fjzz//xOXLlzF8+HB8+umn2LhxYwFXSkQGafhwuZFk3brcSJJyTQg53bp9ezkNu00b2bVUpIjSlRkfRcfM+Pr6wtfXN8v7jx07hsDAQDRt2hQAMGDAACxatAinT5+Gv79/AVVJRAZp+3Y5X7ZQITn4txB73Snndu8Gxo0DTp+Wt7t3B5YuBczNFS3LaOn0b+97772HTZs24d69exBCYN++fbh69Spat26d5WMSExMRExOjdSEi0hIfDwwZIq8PGwbUqKFsPaQ3Tp6UO123bCmDjI2N3L7rzz8ZZJSk02Fm3rx5qFSpEkqUKAFzc3O0adMGCxYswHvvvZflY2bMmAEHBwfNpWTJkgVYMRHphRkzgBs3gOLFgalTla6G9MClS0DHjrJHcu9eGVyGDZM/RhMmsGFPaTr97Z83bx6OHz+OTZs24cyZM5g9ezY++eQT7N69O8vHjBs3DtHR0ZpLeHh4AVZMRDrvypX0jSR/+AGws1O0HNJtt28DffoAVaoA69fL0NK7t9yP9Mcf5VoypDydXWcmPj4eX375JdavX4/3338fAFC1alWEhIRg1qxZaNGiRaaPs7CwgAUXvCKizKg3kkxOBnx9gQ8+ULoi0lFRUcA338jdrZOS5LEOHYBp04BKlZStjTLS2TCTnJyM5ORkFHql7c7ExARpaWkKVUVEeu2vv4B9++RmOfPncyNJyiA6Wu5sPWcOEBcnjzVrBkyfLruYSDcpGmZiY2MRFhamuX3z5k2EhITA0dERpUqVQpMmTTBq1ChYWVnBw8MDBw4cwLJlyzBnzhwFqyYivfT0qfZGkmXLKlsP6ZT4eLlR+owZwJMn8litWvJ2Fh0BpENUQgih1Ivv378fPj4+GY4HBgZi6dKliIyMxLhx47Bz5048efIEHh4eGDBgAIYPHw5VDv+iiomJgYODA6Kjo2Fvb5/XXwIR6YvBg2Wfgbc3EBLC/ZcIgNzNIigImDIFuHdPHvP2lt1JHTuy8U5Jufn8VjTMFASGGSJCSAhQs6YcM7NvH/D/tavIeKWlAWvXAl99JQfzAkDJkjLUfPQRYKqzgzCMR24+v/l2EZHh+/ZbGWS6dGGQMXJCADt3ygXvzp6Vx4oWBcaPl/uNWloqWx+9GYYZIjJs168Da9bI619+qWwtpKhjx2SIOXBA3razA774Qg6l4gx9/ZarMCOEwJ07d+Di4gIrK6v8qomIKO/Mni37FNq0AapVU7oaKkBCAP/9J7uT1q6V1wE5XGrIEBlsihZVtkbKG7kOM15eXvjvv//g5eWVXzUREeWNqCg5uhMAxoxRthYqEEIA586lB5jQ0PT7zMyAXr2ASZPk+BgyHLkKM4UKFYKXlxceP37MMENEum/ePCAhAahTB2jSROlqKJ8IIfdJWrsWWLdO9iyqmZvLRrlOnQA/P6BwYcXKpHyU6zEzM2fOxKhRo7Bw4UJUrlw5P2oiInp7z5/LhUMAYPRozrE1MGlpwIkT6QHm9u30+ywtgbZtZYB5/32AE1kNX67DTM+ePfHixQtUq1YN5ubmGcbOPFGvNkREpKTffgOePQO8vICAAKWroTyQmgocPZoeYNTrwgCAtTXQrp0MML6+gK2tcnVSwct1mPnhhx/yoQwiojyUlCTXoweAUaMAExNl66E3lpICHDokA8w//wCRken32dnJrqNOnYDWrWWgIeOU6zATGBiYH3UQEeWdlSuBu3cBV1e5AhrpleRkubbh2rXAhg3Aw4fp9zk4AP7+MsC0bMl1YUh6o3VmUlNTsWHDBly+fBkqlQqVKlVC+/btYcK/fohIaWlpwMyZ8vrnn/PTTs/s3QsMHAi8tG0fHB1lT2GnTkDz5nJQL9HLch1mwsLC0LZtW9y7dw8VKlSAEAJXr15FyZIlERwcDE9Pz/yok4goZ4KDgUuX5KjPQYOUroZy6PFj2SOonknv5CTDS6dOciKamZmy9ZFuK5TbBwwbNgyenp4IDw/Hv//+i7Nnz+LOnTsoU6YMhg0blh81EhHl3HffyX8HDZJ9EqTThAD++guoWFEGGZVKLmh344bcF7RFCwYZer1cbzRpY2OD48ePo0qVKlrHz507h4YNGyI2NjZPC3xb3GiSyIgcOQK8957sh7h1C3BzU7oiysatW3Iz8+3b5e133gF+/RVo0EDRskhH5ObzO9ctMxYWFnj+/HmG47GxsTBnRyYRKUndKtOrF4OMDktJkbtMvPOODDLm5sDXXwP//ssgQ28m12GmXbt2GDBgAE6cOAEhBIQQOH78OAYNGoT27dvnR41ERK/333/A5s2yn2LUKKWroSz8+y9Qty4wciTw4oUcD3P+PDBhAgf20pvLdZiZN28ePD09Ub9+fVhaWsLS0hINGzZEuXLl8OOPP+ZHjUREr/f99/LfDh2A8uWVrYUyiIuTGbNOHRloihQBfv9dTsGuUEHp6kjf5XrMjNq1a9dw5coVCCFQqVIllCtXLq9ryxMcM0NkBMLDgbJlZf/FiRPyE5N0xo4dcjz2rVvydteuwI8/AsWKKVoW6bjcfH6/0TozAODl5cXNJolIN8ydK4NM06YMMjokKgoYMQJYsULeLlUKWLBA7pdElJdyFGZGjBiR4yeco15CnIioIDx5IqfAAMCYMcrWQgDkdOtly2SQefIEKFQIGDZMDvLlnkmUH3IUZs6ePZujJ1NxV1oiKmgLFsgBGVWryg16SFFhYXIF37175e1q1YDFi4HatZWtiwxbjsLMvn378rsOIqLci48H5s2T10ePljOZSBHJyXK69ZQpQEKC3EViyhRg+HAuekf5743HzBARKS4oSO5C6OEhR5WSIk6eBPr3l1OsAblq7y+/ANzdhgrKG4WZU6dOYc2aNbhz5w6SkpK07vvnn3/ypDAiomylpACzZsnrX3wBmPJvs4KWkCCHKf30kxwn4+Qkx2L37MlGMipYuV5n5u+//0bDhg1x6dIlrF+/HsnJybh06RL27t0LB+6DQkQFZe1a4OZN+Qnat6/S1Rid2FigbVvZyycE8NFHwOXL8l8GGSpouQ4z06dPx9y5c7FlyxaYm5vjxx9/xOXLl9GlSxeUKlUqP2okItImRPrWBZ9+CtjYKFuPkXn2DGjVSi54Z2sLbN0qZy85OytdGRmrXIeZ69ev4/3/LxJgYWGBuLg4qFQqDB8+HL+qp0cSEeWn3buBkBDA2hoYOlTpaozKw4eAjw9w7JhcxXfPHsDXV+mqyNjlOsw4OjpqNposXrw4Ll68CAB49uwZXrx4kbfVERFlRt0q06+f7GaiAnH/vtxLKSQEcHEB9u/nGoWkG3IcZkJCQgAAjRo1wq5duwAAXbp0wWeffYb+/fuje/fuaN68eb4USUSkceaMbA4wMZGrslGBuHULaNRIjospUQI4eFAu7UOkC3I8/L9mzZqoUaMGAgIC0L17dwDAuHHjYGZmhsOHD6Njx4746quv8q1QIiIA6a0y3bvLKdmU70JD5XTru3flFlh79gClSytdFVG6HG80eezYMSxZsgSrV69GcnIyOnbsiI8//hg+Pj75XeNb4UaTRAYkLExusZyWJhc1qVJF6YoM3vnzQMuWcp+lihXlcCV3d6WrImOQm8/vHHcz1a9fH4sXL0ZkZCQWLlyIu3fvokWLFvD09MQ333yDu3fvvnXhRETZmjVLBpm2bRlkCsDJk3LvzqgooEYN4MABBhnSTTlumcnM9evXERQUhGXLliEiIgItW7bE1q1b87K+t8aWGSIDERkp+zYSE+WnauPGSldk0A4elLtbx8YC9evL6deFCytdFRmTfGmZyYynpyfGjh2L8ePHw97eHjt27HibpyMiytq8eTLI1KsnR6JSvtmxA2jTRgYZHx9g504GGdJtb7z+94EDB7BkyRKsW7cOJiYm6NKlCz7++OO8rI2ISIqJkbtjA3L9fC4xm282bJDbXCUlyZaZNWsAKyulqyLKXq7CTHh4OJYuXYqlS5fi5s2baNCgAX766Sd06dIFNlyBk4jyy6+/AtHRcvBv+/ZKV2OwVqwAAgOB1FSgc2fgzz8Bc3OlqyJ6vRyHmZYtW2Lfvn1wdnZGr1690LdvX1SoUCE/ayMikl1Lc+fK66NGAYXeqnecsvDrr8CgQXKniMBA4LffuHcn6Y8c/6haWVlh3bp1aNeuHUxMTPKzJiKidCtWyKVn3d3ldsyU5+bOTV9/cMgQOTyJmZH0SY7DzKZNm/KzDiKijNLSgJkz5fXPPwcsLBQtx9AIAUybBkycKG+PGQPMmMEhSaR/2IhIRLpr0ya5/KyDAzBwoNLVGBQhZHj5/nt5e9o04MsvGWRIPzHMEJFuEiJ964LBgwGuE5Vn0tKATz9NnyA2d65s+CLSVwwzRKSbDh0Cjh+XXUuffaZ0NQYjJUVuNv7HH7IVZtEioH9/pasiejsMM0Skm9StMoGBgKursrUYiKQk4MMPgbVr5abjy5YBPXooXRXR22OYISLdc+GCXD9fpQJGjlS6GoMQHw906iS/rebmwKpVQECA0lUR5Q2GGSLSPeoZTB98AHh5KVuLAUhOlsFl5065mu+GDUCrVkpXRZR3GGaISLfcvg2sXCmvjxmjbC0GQAg5fnrnTsDGBti2jVtbkeFhmCGighcfD9y9C4SHZ7xcuiTX02/WDKhVS+lK9d7MmcDvv8tF8FatYpAhw8QwQ0R5KzkZuHcv86Civjx69Prn+eqr/K/VwK1ZA4wdK6/Pmyc3jiQyRAwzRPRmhAD+/hs4eVI7qERGyvtex8YGKFky80uFCoCHR/5/DQbs2DHgo4/k9c8/l9sUEBkqhhkiyj0h5CyjOXMyv9/cHChRIj2clCqVMbAULszlZvPJjRuAv7/co7N9e2DWLKUrIspfDDNElHtTp6YHmUGDgIoVtYOKszN3KlTI06eyO+nhQ6BmTblPJ/cGJkPHMENEuTNnDjB5srz+44/AsGGKlkPpkpLkbPYrV2TD2ObNgK2t0lUR5T/+6UREObd4MfDFF/L6tGkMMjpECLkX5759MsAEBwPu7kpXRVQwGGaIKGf+/jt95+rRo+UWy6QzZswAli6VXUpr1gBVqypdEVHBYZghotfbvFlOjRFCjpH59lsO3tUhf/8NjB8vr//0E9CmjbL1EBU0hhkiyt6ePUDnznK75Z49gZ9/ZpDRIUeOAL17y+tffCFX+yUyNgwzRJS1Y8fS5/gGBABBQZylpEPCwrTfHvVG40TGhv8rEVHmQkKAtm2BuDigZUvZl2HKCZC64skTOQX78WO568Off3IKNhkvhhkiyig0VG6r/OwZ0KABsH49YGGhdFX0f4mJQIcOwNWrcj3CzZvlgspExophhoi03boFtGghV12rUUPO8eUnpc4QAujfHzh4ELC3l2+Pq6vSVREpi2GGiNJFRMggc/euXNV3xw657QDpjGnTgOXL06dgV66sdEVEymOYISLp8WM5Nub6daBMGWDXLrktAemMFSuAiRPl9YULZU8gETHMEBEAxMTIxUn++08uG7t7N1C8uNJV0UsOHQL69pXXR4+WXU1EJDHMEBm7Fy+Adu2A06eBokVli0zZskpXRS+5dk1OvVbvvTRjhtIVEekWhhkiY5aYCHTsKP/st7eXY2QqVVK6KnrJ48dyhvyTJ0CdOsCyZVzqh+hV/JUgMlYpKcCHH8oAY20NbN0K1KypdFX0EvVieGFhgIcHsGmTfKuISBvDDJExSksD+vUD1q0DzM2BDRuAhg2VropeIoQcI3P4MODgILNmsWJKV0WkmxhmiIyNEMBnnwF//CHn965aJWcxkU6ZMgX46y+56PLatez9I8oOwwyRsZkwAZg/X24WuXSp7McgnbJsmQwzAPDLL3LpHyLKGsMMkTH59ltg+nR5fcECuQs26ZRdu2QPIACMGwd8/LGy9RDpA4YZImPx88/y0xEAZs4EBg1Sth7K4MABuQt2cjLQpYtc7ZeIXk/RMHPw4EH4+fnB3d0dKpUKGzZs0LpfpVJlevn++++VKZhIH6WkAN9/DwwdKm9PmACMGqVsTZTB8eNyuZ/4eLkb9vLlnIJNlFOK/qrExcWhWrVqmD9/fqb3R0REaF2WLFkClUqFDz74oIArJb324AFQrx5QuzaweDEQF6d0RQXn8GE53Xr0aHl72DBg6lRla6IM/v1XLsAcGyvHx6xdKyeZEVHOqIQQQukiANkKs379egRkMxgxICAAz58/x549e3L8vDExMXBwcEB0dDTs7e3zoFLSK9HRQNOmQEhI+jEHB6B3b2DwYKBCBYUKy2dRUTLA/PGHvO3oKMfL9OsnB/6Szrh4Uf6IPn4MNGoEbNvGTcqJgNx9futNI+aDBw8QHByMjzkajnIqIUHO1AkJAVxcgK+/Bjw9ZcD58UfA21v+GfzPP7IrxhCkpsqBvRUqpAeZfv2A0FC5mQ+DjE4JDZU/go8fy9V9t2xhkCF6E3oTZv744w/Y2dmhY8eO2Z6XmJiImJgYrQsZodRUubrt/v2AnR2wfbscK3L1qvzT189PfrDv2SM3uyldWoadiAilK39zJ07IT8QhQ4Bnz4AaNYBjx2TXWtGiSldHr7hxA2jeXPaCVq8uf0TZeEz0ZvQmzCxZsgQffvghLC0tsz1vxowZcHBw0FxKlixZQBWSzhAC+OQT2eJibg5s3Cg/2AE5orJNG7ku/I0bcnaPszNw7x4wcSJQqhTQrRtw8KB8Hn3w+LFsdalXTw6+cHCQ68icOiWPkc4JD5dB5t49uRjezp1AkSJKV0Wkv/QizBw6dAihoaHop158IRvjxo1DdHS05hIeHl4AFZJOmTgR+PVXGVxWrgR8fDI/r3RpueZKeDjw559A/fqyu2nVKqBJE6BqVWDhQuD58wItP8fS0mSrS/nywG+/yWOBgbL1acgQubov6ZyICBlkbt0CvLyA3btlniaiN6cXYeb333/Hu+++i2rVqr32XAsLC9jb22tdyIjMm5e+OMfChXJH6NexsJBdUkePypaN/v3lbn4XL8oWHnd3GQ7++y9/a8+NM2dk+BowQG6nXKWK3Pl66VI5Poh00sOHcozMtWsyS+/ZA7i5KV0Vkf5TNMzExsYiJCQEIf+faXLz5k2EhITgzp07mnNiYmKwZs2aHLXKkJFbuVLuOQTI8S8DBuT+OWrUkK069+4BP/wgWz1iY+Wg2sqV5bSTNWvkqmZKePpUBqvatYGTJ+V4oLlzZQh77z1laqIcefoUaNUKuHQJKF4c2LsXYC84UR4RCtq3b58AkOESGBioOWfRokXCyspKPHv27I1eIzo6WgAQ0dHReVQ16aTt24UwNRUCEOLTT4VIS8ub501LE2L3biE6dBCiUCH5/IAQbm5CTJwoxN27efM6r5OaKkRQkBDOzuk19OghxL17BfP69Faio4WoU0e+bcWKCREaqnRFRLovN5/fOrPOTH7hOjNG4MQJOQghLg7o3l2Of8mPpVPDw+UYlV9/lVNQ1EqUkC04FSrIi/q6h0fejFs5f152dx05Im9XrCi3JshqLBDplLg4Oeb88GHAyUlOsKtcWemqiHRfbj6/GWZIv12+LFcae/xYtuFv3pz/S6cmJQHr18uup4MHsz7P3BwoVy5jyKlQQX6qvU5MDDBpEvDTT3KquY2NvP3ZZ1weVk8kJMgtCvbskZPM9u6VCzIT0esxzLyEYcaAhYcDDRvKf+vUkZ8YtrYFW8OTJ3L2UGiovKivX7sGJCZm/ThHx8xDjqenHJC8ciXwxRdAZKQ8v1MnYM4cDrLQI0lJcvx5cLD8sdy1izPliXKDYeYlDDMGSr32++XLMgQcPqxbC8OlpgJ37mQedLJbLqBQIfl1REXJ215ecs2YVq0Kpm7KEykpQNeucqkjKyu5IF7jxkpXRaRfcvP5bVpANRHlnbg42XZ/+bKcFrJzp24FGUCOlSlTRl5at9a+Ly4OCAtLDzkvB52YGBlkrKzkisVffCFbakhvpKbK5X5eXrORQYYofzHMkH5JTpZdLsePyyVTd+6Uq/bqExsboFo1eXmZEHJg8fXrcqxNsWLK1EdvLC1Nrgjw11+Aqanc/bplS6WrIjJ8DDOkP9LSgD59ZJu9lZUcjFCpktJV5R2VCnB1lRfSO0IAw4YBS5akLz7t56d0VUTGQS9WACaCEMCIEcCKFfJP3nXr5Aq4RDpACGD0aDljXqWSG5Z36qR0VUTGg2GG9MO33wI//iivBwUBvr7K1kP0kkmTgFmz5PVffwV69lS2HiJjwzBDuu+334Avv5TX587lJwXplBkz5O4ZgFwSiDuvEBU8hhnSbRs2AAMHyutjxwKff65kNUQaKSnAlCnpOXvmTGDoUGVrIjJWDDPG4NIloHdv2apx/brS1eTcgQNAt25y4G/fvsD06UpXRAQAOHtWrtM4ebK8PXkyMGqUkhURGTfOZjJ0N27IfYvUK8mOGCH39vHzA9q3l0uS5sX+QXktJETWl5gI+PsDixbJkZVECoqPl8Fl9my5nkyRInJh5sBApSsjMm5cAdiQPXggl/u/fh3w9gbc3OReQqmp6ecULQq0bSuDQ6tWgJ2dcvWq3bgBNGgg62/cOH0qNpGC9u2Ta8iEhcnbXbrIMemcSU+UP3Lz+c1uJkMVEyNn/Fy/DpQuLfct2rsXePRILoDRvTtQuLC8vWyZnEdatKhcrfbnn+VS/AUpMVF2h61fL0PVgwdA1apy+VQGGVLQ06dA//5As2YyyLi7yx/LVasYZIh0BVtmDFFCgmxt2bcPcHYGjhyRe/y8KjlZ3rd5M7BpU/qfnGrVqsnuKD8/oFYtuRLY2xACuH8/4xL+oaHArVtybIxamTKyNje3t3tNorewbp0c1KvupR08WM5ecnBQti4iY8CNJl9idGEmNVW2f//zj+wy2r8fqFnz9Y8TQoYKdbA5elQ7XLi6yv2Q/PyAFi0Aa+usn+v58/Sg8upGi3FxWT/O1lZuGlm1KjBxomxRIlLA/fsyxKxfL29XqAAsXiz3NiWigsEw8xKjCjNCAIMGyVW7zM2Bbdtk2/ibePRIPn7zZjlm5fnz9PssLWWg8fOTGz2+Glju38/6edUbMFaoIC/ly6dfd3XlIF9SVFoa8PvvcmZSdLRcbHrMGLnnp6Wl0tURGReGmZcYVZiZOFGu3qVSAatX59166klJcpq0utXm9u3XP8bFJWNYKV8eKFtWBi0iHXPtmhwbc+CAvF27tlyvsWpVZesiMlYMMy8xmjDz009ylzsAWLhQttDkByGAixdlsAkOBmJjMw8thQvnz+sT5bHkZDnVevJkOQ7d2hqYNk3+OuniqgVExoJh5iVGEWZWrgR69JDXp04FvvpK2XqI9MSZM3L7gZAQebtlS7mkUZkyipZFRODUbOOyc2f6il1Dh8rOfSLK1osXclxMnToyyDg6yp2ud+xgkCHSR1wBWJ+dPAl07Cjbybt1kyt4cQAtUbb27JGL3924IW+rf3VcXJSti4jeHFtm9NWVK3Itmbg42Tb+xx9vvw4MkQF78kRu8dWihQwyJUrIoV8rVzLIEOk7tszoo7t35Sq5jx/LKRfr1nGGEFEmUlPl2ourVwN//y1/ZQBgyBC5b6mhDqMjMjYMM/rmyRO55UB4uJw5FBysG/spEemItDTg2DEZYNasASIi0u/z9pbTrRs2VK4+Isp7DDP6JC5OrsJ76ZJcrG7HDrldAZGREwI4fjw9wNy7l36fgwPQoYNcGLtFC8DMTLk6iSh/MMzoi+RkoHNn+SdnkSIyyHh4KF0VkWKEAE6dSg8wL++NamcHBATIANOyJWBhoViZRFQAGGb0QVqaHLm4bZvcQTo4GHjnHaWrIipwQgD//isDzOrVcn9SNVtboH17oGtXOaSM2w8QGQ+GGV0nBPDFF8Cff8rlSNeuBerXV7oqogIjBHDuHLBqlQww6inVAGBjI7cI69IFaNNGZn0iMj4MM7ruu++AH36Q14OC5HRsIgMnBHDhQnoLzLVr6fdZWcmhY126yF+H7DZwJyLjwDCjy37/HRg3Tl6fMwf46CNl6yHKJ0IAYWFyHcgTJ4Bdu+RSSmqWljK4dOkCvP++7FIiIlJjmNFVGzbIZUoBYOxYYPhwRcshyksPH6YHl5Mn5eXpU+1zzM0BX18ZYPz8uAIBEWWNYUYXHTwo11hXD/ydPl3pioje2IsXwNmz2sHl5s2M51lYADVqAHXrAvXqySDj4FDw9RKR/mGY0TXnzsk/QxMT5dSMRYu43xLpjdRU2T2kDi4nTsixL6mpGc+tWFFu9FinjgwwVapwIWsiejMMM7rk1i05JSMmBmjUSK6/bsq3iHRTUpJcnO7s2fTgcvo0EBub8VxXVxlY1MGlVi22uhBR3uEnpa548kS2q0dGyj9RN23iPFNShBBAdLQMKi9f7t7Vvh0VlfnjbWxkWFGHlzp15KaObGAkovzCMKMLEhIAf3/ZPl+iBLB1K1C4sNJVkQFKTZV5+XVBJS4uZ89nYSH3O3q51aViRbkkEhFRQWGYUVpampxyffiwbHfftk0GGqK3kJwMhIYCISFyGFZIiMzKERGZj1/JTJEicguw4sXlj2Rm152c2OJCRMpjmFHayJFyVV8zM2D9eqByZaUrIj3z7JkMLOrQcu4ccPGiHNOSmUKFADe37ENK8eJcjI6I9AfDjJLmzpUXAFi6FPDxUbQc0m1CyDHiL7e2hIQAt29nfr6tLVCtmrxUry5zcqlSQLFiHFdORIaF/6UpZe1auecSILcs6NFD2XpIp8THA//9p93acu6cnOiWmVKlZGBRB5dq1YAyZWQrDBGRoWOYUcLhw0DPnvJP7SFDgFGjlK6IdMCtW3I2/po1MrhkNrbF3FxumP5yaKlaFXB0LOhqiYh0B8NMQbtyRS6Gl5goZzD9+CNHUBqxyEgZXlauBI4d077PyUkGlpdbXLy95fAqIiJKxzBTkCIj5aJ4T5/K9dr/+otzWI3Q06fAP//IALNvn5zQBshM27Qp0L27XHKoeHHmXCKinGCYKSjPn8vtfm/fBry8gM2bOV3EiMTFybd85Uo5+z45Of2+unVlgOncGXB3V65GIiJ9xTBTEJKT5da///4LODvLT7OiRZWuivJZUhKwfbscB7Nxo9xwUa1yZRlgunUDypZVrkYiIkPAMJPfhAAGDZKfatbWQHAw4OmpdFWUT1JTgf37ZQvMunVyDRi1smXTAwyXEyIiyjsMM/lt6lRgyRI5R3bVKqB2baUrojwmhNxkceVKYPVqOTRKzc0N6NpVhpjatTkGhogoPzDM5KclS4DJk+X1BQuAdu0ULYfyVliYfIv//hu4eTP9uKMj0KmTDDCNGnGMNxFRfmOYyS/btwMDBsjr48cDAwcqWw/lCSGAAwfkws2bN8vbgNwpOiBABpiWLeV6MEREVDAYZvLDv//KP81TU4FevYCvv1a6InpLiYmyG+mHH+SCdmq+vkCfPnKiGienEREpg2Emr926BbRtK+fitmgBLF7MgRJ67MED4JdfZC9hVJQ8Zm0N9O4NDBsGVKigaHlERASGmbz15IlcFO/BA7nG/Lp17G/QU+fOycWZV6xI3326RAng00+Bfv24fQARkS5hmMkrCQlym4LQUKBkSWDrVsDeXumqKBfS0uTM+blz5cq8anXrAsOHAx07cisBIiJdxDCTF9LS5MaRR44ADg5yUbzixZWuinIoNhZYulS2xISFyWMmJnLY0+efy50niIhIdzHM5IUvvkjvUtqwQW5rTDrv9m3gp5+A334DoqPlscKF5SS0IUOAUqUULY+IiHKIYeZtzZ0rp7gAwB9/yJ0CSWcJARw9Kt+yf/5J3+TRy0u2wvTqBdjaKlkhERHlFsPM21i9GhgxQl7//nu5Tj3ppORkYM0aGWJOnUo/3ry5HA/j6ysXaSYiIv3DMPOmDh4EPvpIXh86VHY1kc6JiQF+/VWGmHv35DELCznE6bPPgCpVFC2PiIjyAMPMm1qzRs7ZDQiQn5RcS0anRETIAb0LF8pAAwDFismxMAMHAi4uytZHRER5h2HmTc2bJwf6BgZy8x0dcuUKMGsWsHx5+vow3t7AyJGyNcbCQtn6iIgo7zHMvCmVChg0SOkq6P+OHAFmzgQ2bUo/1rAhMHq03N+T42GIiAwXwwzprbQ0udnjzJlyhpJaQAAwahTQoIFipRERUQFimCG9k5gou5FmzZILLgNyiZ9eveQ4bG9vZesjIqKCxTBDeuPZM7np448/ApGR8piDA/DJJ3LPJDc3RcsjIiKFMMyQzrt7V04YW7RIbj0AyE0fhw8H+vcH7OwULY+IiBTGMEM66+JFuRbhX38BKSnyWOXKclBv167ckJyIiCSGGdIpQsj1CGfOlBuPqzVtKkNMmzZc0oeIiLQxzJDOOHVKBpb9++XtQoWADz6QM5Nq11a0NCIi0mEMM6S4sDDgyy/losqAXNiub1+57VW5csrWRkREuk/RpcQOHjwIPz8/uLu7Q6VSYcOGDRnOuXz5Mtq3bw8HBwfY2dmhXr16uHPnTsEXS3nuwQO5rVXFijLIqFRA797A1avAggUMMkRElDOKhpm4uDhUq1YN8+fPz/T+69ev47333oO3tzf279+Pc+fO4auvvoKlpWUBV0p5KTYWmDJFhpWff5aDe9u2Bc6dA4KCgFKllK6QiIj0iUoIIZQuAgBUKhXWr1+PgIAAzbFu3brBzMwMy5cvf+PnjYmJgYODA6Kjo2Fvb58HldKbSk4GFi+WQSYqSh6rXVsO9m3aVNHSiIhIx+Tm81tnd6xJS0tDcHAwypcvj9atW8PFxQV169bNtCuKdJsQwNq1cl/OIUNkkPH0BFatAk6cYJAhIqK3o7NhJioqCrGxsfj222/Rpk0b7Ny5Ex06dEDHjh1x4MCBLB+XmJiImJgYrQsp5+BBoH59oHNn4No1wNkZmD8fuHQJ6NKF06yJiOjt6exsprS0NACAv78/hg8fDgCoXr06jh49il9++QVNmjTJ9HEzZszAlClTCqxOytzFi8DYsUBwsLxtYwOMHCn3TuKKvURElJd0tmWmaNGiMDU1RaVKlbSOV6xYMdvZTOPGjUN0dLTmEh4ent+l0kvCw+W06mrVZJAxMQEGD5bTrydPZpAhIqK8p7MtM+bm5qhduzZC1dsi/9/Vq1fh4eGR5eMsLCxgYWGR3+XRK54+Bb79Fpg3D0hIkMc++ACYPh0oX17Z2oiIyLApGmZiY2MRFhamuX3z5k2EhITA0dERpUqVwqhRo9C1a1c0btwYPj4+2L59OzZv3oz96iViSXEJCXIMzPTpMtAAQKNGcoZSvXrK1kZERMZB0anZ+/fvh4+PT4bjgYGBWLp0KQBgyZIlmDFjBu7evYsKFSpgypQp8Pf3z/FrcGp2/khJAVasACZOBNS9fu+8I1tn3n+fA3uJiOjt5ObzW2fWmckvDDN5KzkZ+PNP4JtvgOvX5bHixYGpU4HAQDlGhoiI6G3l5vNbZ8fMkG5JSgKWLZPdSTdvymNFi8oZSsOGAVZWytZHRETGi2GGspWYCCxdCsyYAdy+LY+5uMidrAcNAmxtFS2PiIiIYYYyl5AALFkix8CoZ7e7ugKjRwMDBwLW1srWR0REpMYwQ1oSEuT+Sd99B9y7J4+5uckF8Pr3Z3cSERHpHoYZAgDExwO//ipDTESEPFaihAwxH38McKNyIiLSVQwzRi4uDli0SK4L8+CBPFaqFDBuHNCnD8D1B4mISNcxzBip2Fhg4ULg+++Bhw/lsdKlgS+/lFOszc0VLY+IiCjHGGaMzPPnwM8/A7NnA48eyWNlywLjxwMffQSYmSlbHxERUW4xzBiJ6Gi57cCcOcCTJ/JYuXLAhAlAjx4MMUREpL8YZgxYSgqwfz+wdi2wahXw7Jk8XqGCDDHdugGm/AkgIiI9x48yA5OcDOzbB6xZA6xfDzx+nH5fxYrAV18BXbpw2wEiIjIcDDMGICkJ2LtXBpgNG9K7kQC55UDHjkCnTkCzZgwxRERkeBhm9FRSErB7twwwGzcCT5+m3+fikh5gmjRhVxIRERk2fszpkcREYOdOOQZm40Y5qFetWDHggw9kgGncmC0wRERkPBhmdFxCArBjhwwwmzYBMTHp97m5yQDTuTPQsCEDDBERGSeGGR0UHw9s3y67kDZvlgvcqbm7y9aXzp2BBg2AQoWUq5OIiEgXMMzoiGfPgK1bZfdRcLDcZkCtRIn0AFOvHgMMERHRyxhmFBQeLsPLxo1yPZiUlPT7SpVKDzB16jDAEBERZYVhpgAJAVy4IMPLhg3Av/9q31+xIhAQIC+1awMqlQJFEhER6RmGmXyWkgIcPpweYG7dSr9PpZLjXgICAH9/wMtLoSKJiIj0GMNMPoiLkzOQNm4EtmzRXsTO0hJo2VIGmHbt5JowRERE9OYYZvLIgwdy5tHGjcCuXXJNGDUnJxlcAgJkkLGxUaxMIiIig8Mw8xZCQ9MH8B47JsfEqJUtK7uO/P3lGjBchZeIiCh/8CP2DY0YAcydq32sVq30AFO5MgfwEhERFQSGmTdUt65sbfHxkd1H7dvL9WCIiIioYDHMvKH27YGHD4HChZWuhIiIyLgxzLwhKyt5ISIiImVxXVkiIiLSawwzREREpNcYZoiIiEivMcwQERGRXmOYISIiIr3GMENERER6jWGGiIiI9BrDDBEREek1hhkiIiLSawwzREREpNcYZoiIiEivMcwQERGRXmOYISIiIr1m8LtmCyEAADExMQpXQkRERDml/txWf45nx+DDzPPnzwEAJUuWVLgSIiIiyq3nz5/DwcEh23NUIieRR4+lpaXh/v37sLOzg0qlytPnjomJQcmSJREeHg57e/s8fW7KW3yv9AffK/3C90t/6Nt7JYTA8+fP4e7ujkKFsh8VY/AtM4UKFUKJEiXy9TXs7e314geD+F7pE75X+oXvl/7Qp/fqdS0yahwATERERHqNYYaIiIj0GsPMW7CwsMCkSZNgYWGhdCn0Gnyv9AffK/3C90t/GPJ7ZfADgImIiMiwsWWGiIiI9BrDDBEREek1hhkiIiLSawwzREREpNcYZt7QggULUKZMGVhaWuLdd9/FoUOHlC6JMjF58mSoVCqti6urq9JlEYCDBw/Cz88P7u7uUKlU2LBhg9b9QghMnjwZ7u7usLKyQtOmTfHff/8pU6yRe9171bt37wy/Z/Xq1VOmWCM3Y8YM1K5dG3Z2dnBxcUFAQABCQ0O1zjHE3y2GmTewatUqfP755xg/fjzOnj2LRo0awdfXF3fu3FG6NMrEO++8g4iICM3lwoULSpdEAOLi4lCtWjXMnz8/0/tnzpyJOXPmYP78+Th16hRcXV3RsmVLzX5rVHBe914BQJs2bbR+z7Zu3VqAFZLagQMHMGTIEBw/fhy7du1CSkoKWrVqhbi4OM05Bvm7JSjX6tSpIwYNGqR1zNvbW4wdO1ahiigrkyZNEtWqVVO6DHoNAGL9+vWa22lpacLV1VV8++23mmMJCQnCwcFB/PLLLwpUSGqvvldCCBEYGCj8/f0VqYeyFxUVJQCIAwcOCCEM93eLLTO5lJSUhDNnzqBVq1Zax1u1aoWjR48qVBVl59q1a3B3d0eZMmXQrVs33LhxQ+mS6DVu3ryJyMhIrd8zCwsLNGnShL9nOmr//v1wcXFB+fLl0b9/f0RFRSldEgGIjo4GADg6OgIw3N8thplcevToEVJTU1GsWDGt48WKFUNkZKRCVVFW6tati2XLlmHHjh1YvHgxIiMj0aBBAzx+/Fjp0igb6t8l/p7pB19fX6xYsQJ79+7F7NmzcerUKTRr1gyJiYlKl2bUhBAYMWIE3nvvPVSuXBmA4f5uGfyu2flFpVJp3RZCZDhGyvP19dVcr1KlCurXrw9PT0/88ccfGDFihIKVUU7w90w/dO3aVXO9cuXKqFWrFjw8PBAcHIyOHTsqWJlxGzp0KM6fP4/Dhw9nuM/QfrfYMpNLRYsWhYmJSYYEGxUVlSHpku6xsbFBlSpVcO3aNaVLoWyoZ5zx90w/ubm5wcPDg79nCvr000+xadMm7Nu3DyVKlNAcN9TfLYaZXDI3N8e7776LXbt2aR3ftWsXGjRooFBVlFOJiYm4fPky3NzclC6FslGmTBm4urpq/Z4lJSXhwIED/D3TA48fP0Z4eDh/zxQghMDQoUPxzz//YO/evShTpozW/Yb6u8VupjcwYsQIfPTRR6hVqxbq16+PX3/9FXfu3MGgQYOULo1eMXLkSPj5+aFUqVKIiorCtGnTEBMTg8DAQKVLM3qxsbEICwvT3L558yZCQkLg6OiIUqVK4fPPP8f06dPh5eUFLy8vTJ8+HdbW1ujRo4eCVRun7N4rR0dHTJ48GR988AHc3Nxw69YtfPnllyhatCg6dOigYNXGaciQIfjrr7+wceNG2NnZaVpgHBwcYGVlBZVKZZi/W4rOpdJjP//8s/Dw8BDm5uaiZs2ammlvpFu6du0q3NzchJmZmXB3dxcdO3YU//33n9JlkRBi3759AkCGS2BgoBBCTiGdNGmScHV1FRYWFqJx48biwoULyhZtpLJ7r168eCFatWolnJ2dhZmZmShVqpQIDAwUd+7cUbpso5TZ+wRABAUFac4xxN8tlRBCFHyEIiIiIsobHDNDREREeo1hhoiIiPQawwwRERHpNYYZIiIi0msMM0RERKTXGGaIiIhIrzHMEBERkV5jmCEiIiK9xjBDRPlOpVJle+ndu7fSJRKRHuPeTESU7yIiIjTXV61ahYkTJyI0NFRzzMrKSomyiMhAsGWGiPKdq6ur5uLg4ACVSqV17ODBg3j33XdhaWmJsmXLYsqUKUhJSdE8XqVSYdGiRWjXrh2sra1RsWJFHDt2DGFhYWjatClsbGxQv359XL9+XfOYyZMno3r16li0aBFKliwJa2trdO7cGc+ePdOck5aWhqlTp6JEiRKwsLBA9erVsX379oL81hBRHmCYISJF7dixAz179sSwYcNw6dIlLFq0CEuXLsU333yjdd7XX3+NXr16ISQkBN7e3ujRowcGDhyIcePG4fTp0wCAoUOHaj0mLCwMq1evxubNm7F9+3aEhIRgyJAhmvt//PFHzJ49G7NmzcL58+fRunVrtG/fHteuXcv/L5yI8o7SO10SkXEJCgoSDg4OmtuNGjUS06dP1zpn+fLlws3NTXMbgJgwYYLm9rFjxwQA8fvvv2uOrVy5UlhaWmpuT5o0SZiYmIjw8HDNsW3btolChQqJiIgIIYQQ7u7u4ptvvtF67dq1a4tPPvnk7b5IIipQHDNDRIo6c+YMTp06pdUSk5qaioSEBLx48QLW1tYAgKpVq2ruL1asGACgSpUqWscSEhIQExMDe3t7AECpUqVQokQJzTn169dHWloaQkNDYW1tjfv376Nhw4Za9TRs2BDnzp3L+y+UiPINwwwRKSotLQ1TpkxBx44dM9xnaWmpuW5mZqa5rlKpsjyWlpaW5Wupz1H/++p1ABBCZDhGRLqNYYaIFFWzZk2EhoaiXLlyef7cd+7cwf379+Hu7g4AOHbsGAoVKoTy5cvD3t4e7u7uOHz4MBo3bqx5zNGjR1GnTp08r4WI8g/DDBEpauLEiWjXrh1KliyJzp07o1ChQjh//jwuXLiAadOmvdVzW1paIjAwELNmzUJMTAyGDRuGLl26wNXVFQAwatQoTJo0CZ6enqhevTqCgoIQEhKCFStW5MWXRkQFhGGGiBTVunVrbNmyBVOnTsXMmTNhZmYGb29v9OvX762fu1y5cujYsSPatm2LJ0+eoG3btliwYIHm/mHDhiEmJgZffPEFoqKiUKlSJWzatAleXl5v/dpEVHBUQgihdBFERHlt8uTJ2LBhA0JCQpQuhYjyGdeZISIiIr3GMENERER6jd1MREREpNfYMkNERER6jWGGiIiI9BrDDBEREek1hhkiIiLSawwzREREpNcYZoiIiEivMcwQERGRXmOYISIiIr3GMENERER67X/UW/mGsIClpAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_teste,color=\"red\",label=\"Preço real\")\n",
    "plt.plot(previsores,color=\"blue\",label=\"Previsores\")\n",
    "plt.title(\"Previsão do preço das ações\")\n",
    "plt.xlabel(\"Tempo\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
