{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb6e90a-ae5d-4b14-99d0-3c668cd779da",
   "metadata": {},
   "source": [
    "# Previsão temporal - preços da bolsa de valores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad8eeeb-bbbb-4fb2-8d17-95cdb23165bd",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e184b0e-32a4-4805-a47f-4e7e499ca278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacao desta lib para desativar erro no TensorFlow\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5674851-e883-4e2b-8a46-191012c19f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 16:26:00.592779: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-11 16:26:00.839208: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-11 16:26:01.643426: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-11 16:26:03.784107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f5ef04c-bb08-4940-abf8-180a2b76d996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.26.4', '2.2.2', '2.16.1', '3.8.4', '1.4.2')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__, pd.__version__, tf.__version__, matplotlib.__version__, sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8814e86d-2c49-444a-ad93-ed0144a2f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5613a-a694-4474-a8b8-53dae35bfe6d",
   "metadata": {},
   "source": [
    "## Carregamento base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aae312f5-ada8-4af3-80ac-2b4c83586e27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>20.209999</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>18.086271</td>\n",
       "      <td>30182600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>19.809999</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>18.738441</td>\n",
       "      <td>30552600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>20.330000</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>20.170000</td>\n",
       "      <td>20.430000</td>\n",
       "      <td>18.766001</td>\n",
       "      <td>36141000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>20.480000</td>\n",
       "      <td>20.670000</td>\n",
       "      <td>19.950001</td>\n",
       "      <td>20.080000</td>\n",
       "      <td>18.444506</td>\n",
       "      <td>28069600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.230000</td>\n",
       "      <td>19.459999</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>17.911745</td>\n",
       "      <td>29091300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>2017-12-25</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.718563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>15.990000</td>\n",
       "      <td>15.690000</td>\n",
       "      <td>15.970000</td>\n",
       "      <td>15.938125</td>\n",
       "      <td>22173100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>15.990000</td>\n",
       "      <td>16.139999</td>\n",
       "      <td>15.980000</td>\n",
       "      <td>16.049999</td>\n",
       "      <td>16.017963</td>\n",
       "      <td>23552200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.129999</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.067865</td>\n",
       "      <td>19011500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>16.067865</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1245 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Open       High        Low      Close  Adj Close  \\\n",
       "0     2013-01-02  19.990000  20.209999  19.690001  19.690001  18.086271   \n",
       "1     2013-01-03  19.809999  20.400000  19.700001  20.400000  18.738441   \n",
       "2     2013-01-04  20.330000  20.620001  20.170000  20.430000  18.766001   \n",
       "3     2013-01-07  20.480000  20.670000  19.950001  20.080000  18.444506   \n",
       "4     2013-01-08  20.110001  20.230000  19.459999  19.500000  17.911745   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "1240  2017-12-25  15.750000  15.750000  15.750000  15.750000  15.718563   \n",
       "1241  2017-12-26  15.750000  15.990000  15.690000  15.970000  15.938125   \n",
       "1242  2017-12-27  15.990000  16.139999  15.980000  16.049999  16.017963   \n",
       "1243  2017-12-28  16.100000  16.129999  16.000000  16.100000  16.067865   \n",
       "1244  2017-12-29  16.100000  16.100000  16.100000  16.100000  16.067865   \n",
       "\n",
       "          Volume  \n",
       "0     30182600.0  \n",
       "1     30552600.0  \n",
       "2     36141000.0  \n",
       "3     28069600.0  \n",
       "4     29091300.0  \n",
       "...          ...  \n",
       "1240         0.0  \n",
       "1241  22173100.0  \n",
       "1242  23552200.0  \n",
       "1243  19011500.0  \n",
       "1244         0.0  \n",
       "\n",
       "[1245 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = pd.read_csv('petr4-treinamento.csv')\n",
    "base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15301b20-af73-404b-8707-c857c46b2495",
   "metadata": {},
   "source": [
    "## Verificar se há dados faltantes na base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e97a554e-a1e9-45c4-b279-f86753f9237b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         3\n",
       "High         3\n",
       "Low          3\n",
       "Close        3\n",
       "Adj Close    3\n",
       "Volume       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b27fcaaa-881b-4ced-a111-66d50b7055cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = base.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b0dbf1-6b31-4f97-8263-a01560afc82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21367f52-0024-4a89-89e8-89bcbb8889ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7cb5730-f533-482c-9d61-f71849ee81f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_treinamento = base.iloc[:,1:7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3728f64-fabd-4a2b-a179-ab9680c98282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9990000e+01, 2.0209999e+01, 1.9690001e+01, 1.9690001e+01,\n",
       "        1.8086271e+01, 3.0182600e+07],\n",
       "       [1.9809999e+01, 2.0400000e+01, 1.9700001e+01, 2.0400000e+01,\n",
       "        1.8738441e+01, 3.0552600e+07],\n",
       "       [2.0330000e+01, 2.0620001e+01, 2.0170000e+01, 2.0430000e+01,\n",
       "        1.8766001e+01, 3.6141000e+07],\n",
       "       ...,\n",
       "       [1.5990000e+01, 1.6139999e+01, 1.5980000e+01, 1.6049999e+01,\n",
       "        1.6017963e+01, 2.3552200e+07],\n",
       "       [1.6100000e+01, 1.6129999e+01, 1.6000000e+01, 1.6100000e+01,\n",
       "        1.6067865e+01, 1.9011500e+07],\n",
       "       [1.6100000e+01, 1.6100000e+01, 1.6100000e+01, 1.6100000e+01,\n",
       "        1.6067865e+01, 0.0000000e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d10896a-fdf6-47a6-86e3-d690ea29614b",
   "metadata": {},
   "source": [
    "## Normalização dos dados - escalonamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98e237a4-5905-4d6f-bec6-4ed4c2a13e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76501938, 0.77266112, 0.79682707, 0.76080559, 0.6838135 ,\n",
       "        0.04318274],\n",
       "       [0.7562984 , 0.78187106, 0.79733884, 0.79567784, 0.71590949,\n",
       "        0.0437121 ],\n",
       "       [0.78149225, 0.79253519, 0.82139202, 0.79715132, 0.71726583,\n",
       "        0.05170752],\n",
       "       ...,\n",
       "       [0.57122093, 0.57537562, 0.60696008, 0.58202356, 0.58202349,\n",
       "        0.03369652],\n",
       "       [0.57655039, 0.57489089, 0.60798362, 0.5844794 , 0.58447937,\n",
       "        0.02720006],\n",
       "       [0.57655039, 0.57343674, 0.61310133, 0.5844794 , 0.58447937,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizador = MinMaxScaler(feature_range=(0,1))\n",
    "base_treinamento_normalizada = normalizador.fit_transform(base_treinamento)\n",
    "base_treinamento_normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7db5642-2f44-4ac4-99b2-b710808fa570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76501938],\n",
       "       [0.7562984 ],\n",
       "       [0.78149225],\n",
       "       ...,\n",
       "       [0.57122093],\n",
       "       [0.57655039],\n",
       "       [0.57655039]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Este normalizador servirá apenas para a base de teste de previsores\n",
    "normalizador_previsao = MinMaxScaler(feature_range=(0,1))\n",
    "normalizador_previsao.fit_transform(base_treinamento[:,0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cee5a9-740a-413c-974d-11c6b39fcf9d",
   "metadata": {},
   "source": [
    "## Separacao base de previsores e alvo com base nos ultimos 90 registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d64bbcb0-4259-453e-834c-227e474663cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_treinamento_normalizada.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b505e6cf-4e37-4410-8c78-5dbde3a612c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # previsores\n",
    "y = [] # alvo - preco real\n",
    "\n",
    "for i in range(90,1242): # 90 precos anteriores\n",
    "    X.append(base_treinamento_normalizada[i-90:i,0:6])\n",
    "    y.append(base_treinamento_normalizada[i,0])\n",
    "    #print(i,i-90)\n",
    "\n",
    "X,y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "544c59d4-f5b1-4969-ad9a-4a03f3eb38ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.76501938, 0.77266112, 0.79682707, 0.76080559, 0.6838135 ,\n",
       "         0.04318274],\n",
       "        [0.7562984 , 0.78187106, 0.79733884, 0.79567784, 0.71590949,\n",
       "         0.0437121 ],\n",
       "        [0.78149225, 0.79253519, 0.82139202, 0.79715132, 0.71726583,\n",
       "         0.05170752],\n",
       "        [0.78875969, 0.7949588 , 0.81013311, 0.77996075, 0.70144373,\n",
       "         0.04015963],\n",
       "        [0.77083338, 0.77363063, 0.78505624, 0.75147351, 0.67522435,\n",
       "         0.0416214 ],\n",
       "        [0.74806197, 0.75618037, 0.78505624, 0.76031438, 0.68336137,\n",
       "         0.03485382],\n",
       "        [0.75436047, 0.76490543, 0.78915051, 0.76768177, 0.69014234,\n",
       "         0.02507502],\n",
       "        [0.75823643, 0.76442079, 0.79733884, 0.77013751, 0.6924025 ,\n",
       "         0.0260728 ],\n",
       "        [0.76598837, 0.77411537, 0.79682707, 0.76227897, 0.68516964,\n",
       "         0.0404927 ],\n",
       "        [0.76598837, 0.77411537, 0.79682707, 0.76719061, 0.68969016,\n",
       "         0.0423977 ],\n",
       "        [0.76017437, 0.75714973, 0.79222108, 0.76817293, 0.69059437,\n",
       "         0.02401858],\n",
       "        [0.75872098, 0.75908871, 0.79222108, 0.76178781, 0.68471746,\n",
       "         0.02821315],\n",
       "        [0.75581391, 0.75714973, 0.78915051, 0.75540279, 0.6788408 ,\n",
       "         0.02706042],\n",
       "        [0.74467054, 0.74309258, 0.77533265, 0.74607071, 0.67025175,\n",
       "         0.02587622],\n",
       "        [0.7374031 , 0.74357736, 0.77328557, 0.75540279, 0.6788408 ,\n",
       "         0.03367205],\n",
       "        [0.7374031 , 0.74454673, 0.77328557, 0.75392926, 0.67748471,\n",
       "         0.02460946],\n",
       "        [0.73498067, 0.75036355, 0.78045041, 0.75687631, 0.68019705,\n",
       "         0.02806007],\n",
       "        [0.75242248, 0.75327189, 0.77533265, 0.74508849, 0.66934774,\n",
       "         0.02878973],\n",
       "        [0.73401163, 0.73194382, 0.75332651, 0.73231836, 0.65759427,\n",
       "         0.03876941],\n",
       "        [0.71656977, 0.71352399, 0.71903787, 0.68762287, 0.6164569 ,\n",
       "         0.09583767],\n",
       "        [0.68120155, 0.68153175, 0.70522006, 0.68172891, 0.61103237,\n",
       "         0.04756616],\n",
       "        [0.67538755, 0.69704314, 0.71647907, 0.70039291, 0.62821037,\n",
       "         0.04129104],\n",
       "        [0.67635659, 0.68250121, 0.70470824, 0.67779964, 0.60741587,\n",
       "         0.04620398],\n",
       "        [0.63372098, 0.67959287, 0.67246673, 0.68172891, 0.61103237,\n",
       "         0.11064144],\n",
       "        [0.66521318, 0.66553563, 0.6862846 , 0.65815327, 0.58933361,\n",
       "         0.04418925],\n",
       "        [0.65649225, 0.66456617, 0.67553736, 0.65324168, 0.584813  ,\n",
       "         0.0530315 ],\n",
       "        [0.64680228, 0.65487159, 0.67860793, 0.6650295 , 0.5956623 ,\n",
       "         0.04444964],\n",
       "        [0.66618222, 0.66553563, 0.69651996, 0.66797641, 0.59837464,\n",
       "         0.03194532],\n",
       "        [0.65843028, 0.66068832, 0.6888434 , 0.66159139, 0.59249793,\n",
       "         0.0370597 ],\n",
       "        [0.64970935, 0.65535633, 0.6862846 , 0.6596267 , 0.59068976,\n",
       "         0.0357702 ],\n",
       "        [0.65116274, 0.66311202, 0.68577277, 0.67288805, 0.60289526,\n",
       "         0.02903152],\n",
       "        [0.66424419, 0.67426079, 0.70470824, 0.68271123, 0.61193639,\n",
       "         0.0412361 ],\n",
       "        [0.67344961, 0.67038294, 0.68730803, 0.65913564, 0.59023768,\n",
       "         0.03711206],\n",
       "        [0.64292631, 0.6446922 , 0.66939616, 0.64440082, 0.57667593,\n",
       "         0.04346845],\n",
       "        [0.64486434, 0.64178381, 0.65967247, 0.63605111, 0.56899095,\n",
       "         0.04421171],\n",
       "        [0.62257747, 0.62190984, 0.65148414, 0.62622798, 0.55994986,\n",
       "         0.04364257],\n",
       "        [0.60949617, 0.61027635, 0.63510752, 0.61591359, 0.55045665,\n",
       "         0.04779322],\n",
       "        [0.60998067, 0.61609307, 0.6407369 , 0.61935165, 0.55362107,\n",
       "         0.04092922],\n",
       "        [0.60852713, 0.60979157, 0.63613096, 0.60952857, 0.54457989,\n",
       "         0.03981569],\n",
       "        [0.59593023, 0.61803199, 0.62845445, 0.62377213, 0.55768961,\n",
       "         0.04509603],\n",
       "        [0.61143411, 0.62190984, 0.63254862, 0.60412577, 0.5396073 ,\n",
       "         0.05085238],\n",
       "        [0.60222863, 0.60542899, 0.6320368 , 0.60707267, 0.54231954,\n",
       "         0.04531064],\n",
       "        [0.64922481, 0.67862336, 0.6704196 , 0.68025539, 0.60967603,\n",
       "         0.10572707],\n",
       "        [0.68362398, 0.74212312, 0.72620261, 0.72445981, 0.65036132,\n",
       "         0.08930445],\n",
       "        [0.70687989, 0.72952012, 0.7185261 , 0.69597258, 0.62414194,\n",
       "         0.04376518],\n",
       "        [0.68265509, 0.71255448, 0.7062436 , 0.72347744, 0.64945705,\n",
       "         0.03589495],\n",
       "        [0.70978682, 0.72079491, 0.74257927, 0.71414542, 0.64086801,\n",
       "         0.03739277],\n",
       "        [0.70784879, 0.72370339, 0.74769703, 0.71463658, 0.64132019,\n",
       "         0.04530406],\n",
       "        [0.71608527, 0.73242845, 0.74104401, 0.74115922, 0.66573124,\n",
       "         0.03887614],\n",
       "        [0.73643411, 0.74066888, 0.76202661, 0.73133599, 0.65669001,\n",
       "         0.06269313],\n",
       "        [0.7122093 , 0.73097431, 0.75332651, 0.73673879, 0.6616627 ,\n",
       "         0.05787405],\n",
       "        [0.7122093 , 0.73097431, 0.75281474, 0.73182715, 0.65714209,\n",
       "         0.04839097],\n",
       "        [0.7194767 , 0.72176442, 0.74513818, 0.71954817, 0.6458407 ,\n",
       "         0.03954013],\n",
       "        [0.70348832, 0.70722254, 0.73541453, 0.70383112, 0.63137489,\n",
       "         0.03144514],\n",
       "        [0.69525189, 0.69995148, 0.73387917, 0.70874262, 0.63589531,\n",
       "         0.02308847],\n",
       "        [0.70397287, 0.70528357, 0.73183214, 0.70677803, 0.63408723,\n",
       "         0.03482392],\n",
       "        [0.70397287, 0.7081919 , 0.73490276, 0.70677803, 0.63408723,\n",
       "         0.02257928],\n",
       "        [0.69767442, 0.69510427, 0.72824974, 0.69842833, 0.6264022 ,\n",
       "         0.01903582],\n",
       "        [0.68168605, 0.68395536, 0.71136131, 0.67927317, 0.60877212,\n",
       "         0.02224034],\n",
       "        [0.68168605, 0.68395536, 0.69344933, 0.66306491, 0.59385423,\n",
       "         0.02942397],\n",
       "        [0.65310078, 0.66650509, 0.69396111, 0.67779964, 0.60741587,\n",
       "         0.02244093],\n",
       "        [0.66618222, 0.67571493, 0.6949847 , 0.66355598, 0.59430621,\n",
       "         0.02782257],\n",
       "        [0.64825581, 0.66117305, 0.68730803, 0.66797641, 0.59837464,\n",
       "         0.02440802],\n",
       "        [0.66182175, 0.66117305, 0.6765609 , 0.64685666, 0.57893629,\n",
       "         0.03144357],\n",
       "        [0.64341085, 0.6776539 , 0.68372569, 0.68516703, 0.61419665,\n",
       "         0.04400526],\n",
       "        [0.67877902, 0.69704314, 0.71903787, 0.69842833, 0.6264022 ,\n",
       "         0.04546845],\n",
       "        [0.69137592, 0.69122642, 0.7036848 , 0.67730848, 0.60696374,\n",
       "         0.03177292],\n",
       "        [0.66569772, 0.66941348, 0.6862846 , 0.67583495, 0.6056075 ,\n",
       "         0.03919891],\n",
       "        [0.65406982, 0.6572952 , 0.665302  , 0.63998039, 0.57260735,\n",
       "         0.05120333],\n",
       "        [0.64292631, 0.65341735, 0.68116684, 0.66306491, 0.59385423,\n",
       "         0.03397579],\n",
       "        [0.64147292, 0.64614639, 0.65813715, 0.63703343, 0.56989516,\n",
       "         0.05635362],\n",
       "        [0.63565891, 0.66262729, 0.665302  , 0.66895878, 0.5992789 ,\n",
       "         0.04077971],\n",
       "        [0.67587209, 0.68880271, 0.70777897, 0.6969548 , 0.625046  ,\n",
       "         0.0548714 ],\n",
       "        [0.68653106, 0.70382942, 0.71903787, 0.71660126, 0.64312846,\n",
       "         0.03461346],\n",
       "        [0.70300383, 0.73921474, 0.74411464, 0.73280952, 0.6580463 ,\n",
       "         0.04969664],\n",
       "        [0.71996119, 0.74600097, 0.76202661, 0.74852661, 0.67251211,\n",
       "         0.04766145],\n",
       "        [0.73982553, 0.74745521, 0.76867958, 0.73526526, 0.66030651,\n",
       "         0.05031056],\n",
       "        [0.76550388, 0.79059622, 0.80962134, 0.79666016, 0.71681365,\n",
       "         0.10120858],\n",
       "        [0.74854651, 0.76732913, 0.7840328 , 0.7804519 , 0.71911682,\n",
       "         0.06567045],\n",
       "        [0.75823643, 0.79301983, 0.80501535, 0.78831045, 0.72648688,\n",
       "         0.04828195],\n",
       "        [0.78924419, 0.79447407, 0.80706238, 0.77455795, 0.71358928,\n",
       "         0.06152981],\n",
       "        [0.76598837, 0.78041692, 0.80348004, 0.79223972, 0.73017189,\n",
       "         0.04455508],\n",
       "        [0.78488372, 0.79835191, 0.82702155, 0.80648339, 0.74353023,\n",
       "         0.03775975],\n",
       "        [0.80184109, 0.80222976, 0.82395082, 0.79027514, 0.72832946,\n",
       "         0.03492235],\n",
       "        [0.77761628, 0.78768783, 0.81729785, 0.7907662 , 0.72879006,\n",
       "         0.03271233],\n",
       "        [0.77325581, 0.78138628, 0.79785051, 0.77406679, 0.71312854,\n",
       "         0.0315204 ],\n",
       "        [0.7562984 , 0.75521086, 0.78096208, 0.75098236, 0.69147899,\n",
       "         0.03087142],\n",
       "        [0.74273261, 0.74697043, 0.77430911, 0.75392926, 0.69424286,\n",
       "         0.04384244],\n",
       "        [0.74127907, 0.74503146, 0.77840328, 0.75491163, 0.6951641 ,\n",
       "         0.03128876],\n",
       "        [0.74224806, 0.76635967, 0.78505624, 0.76375249, 0.7034554 ,\n",
       "         0.03586405]]),\n",
       " (1152, 90, 6))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938b32d0-584b-4fb9-a765-e2e0ab0b95c2",
   "metadata": {},
   "source": [
    "## Estrutura da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "009c8b00-17f3-4723-9f24-19af598d5b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m42,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m30,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">113,451</span> (443.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m113,451\u001b[0m (443.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">113,451</span> (443.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m113,451\u001b[0m (443.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 100, return_sequences=True, input_shape=(X.shape[1],6)))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences=True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences=True))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.3))\n",
    "\n",
    "regressor.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "951a8935-bfce-4b61-8259-b66c45964319",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer='adam',loss='mean_squared_error',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61a2e216-44dc-4c8d-8d0d-10d5c3029aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='loss',min_delta=1e-10,patience=10,verbose=True)\n",
    "rlr = ReduceLROnPlateau(monitor='loss',factor=0.2,patience=5,verbose=1)\n",
    "mcp = ModelCheckpoint(filepath='pesos.keras',monitor='loss',save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bcf9f73-650b-4c7f-a444-e2e340503f56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0594 - mean_absolute_error: 0.1863\n",
      "Epoch 1: loss improved from inf to 0.03054, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 133ms/step - loss: 0.0586 - mean_absolute_error: 0.1848 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0093 - mean_absolute_error: 0.0754\n",
      "Epoch 2: loss improved from 0.03054 to 0.00870, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - loss: 0.0093 - mean_absolute_error: 0.0753 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0085 - mean_absolute_error: 0.0722\n",
      "Epoch 3: loss improved from 0.00870 to 0.00789, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - loss: 0.0084 - mean_absolute_error: 0.0721 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0070 - mean_absolute_error: 0.0651\n",
      "Epoch 4: loss improved from 0.00789 to 0.00718, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - loss: 0.0070 - mean_absolute_error: 0.0651 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0057 - mean_absolute_error: 0.0580\n",
      "Epoch 5: loss improved from 0.00718 to 0.00651, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - loss: 0.0057 - mean_absolute_error: 0.0581 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0054 - mean_absolute_error: 0.0572\n",
      "Epoch 6: loss improved from 0.00651 to 0.00575, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - loss: 0.0054 - mean_absolute_error: 0.0572 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0065 - mean_absolute_error: 0.0606\n",
      "Epoch 7: loss did not improve from 0.00575\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - loss: 0.0065 - mean_absolute_error: 0.0606 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0060 - mean_absolute_error: 0.0595\n",
      "Epoch 8: loss did not improve from 0.00575\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.0060 - mean_absolute_error: 0.0595 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0056 - mean_absolute_error: 0.0576\n",
      "Epoch 9: loss improved from 0.00575 to 0.00551, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.0056 - mean_absolute_error: 0.0576 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0048 - mean_absolute_error: 0.0540\n",
      "Epoch 10: loss improved from 0.00551 to 0.00489, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - loss: 0.0048 - mean_absolute_error: 0.0540 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0056 - mean_absolute_error: 0.0570\n",
      "Epoch 11: loss did not improve from 0.00489\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - loss: 0.0056 - mean_absolute_error: 0.0570 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0051 - mean_absolute_error: 0.0540\n",
      "Epoch 12: loss did not improve from 0.00489\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0051 - mean_absolute_error: 0.0540 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0049 - mean_absolute_error: 0.0535\n",
      "Epoch 13: loss improved from 0.00489 to 0.00449, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 0.0049 - mean_absolute_error: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0053 - mean_absolute_error: 0.0552\n",
      "Epoch 14: loss did not improve from 0.00449\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0053 - mean_absolute_error: 0.0552 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0044 - mean_absolute_error: 0.0504\n",
      "Epoch 15: loss did not improve from 0.00449\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - loss: 0.0044 - mean_absolute_error: 0.0504 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0046 - mean_absolute_error: 0.0517\n",
      "Epoch 16: loss did not improve from 0.00449\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 0.0046 - mean_absolute_error: 0.0518 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0045 - mean_absolute_error: 0.0509\n",
      "Epoch 17: loss improved from 0.00449 to 0.00447, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 0.0045 - mean_absolute_error: 0.0509 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0040 - mean_absolute_error: 0.0479\n",
      "Epoch 18: loss improved from 0.00447 to 0.00422, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 0.0040 - mean_absolute_error: 0.0479 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0040 - mean_absolute_error: 0.0480\n",
      "Epoch 19: loss did not improve from 0.00422\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0040 - mean_absolute_error: 0.0480 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0038 - mean_absolute_error: 0.0471\n",
      "Epoch 20: loss improved from 0.00422 to 0.00374, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0038 - mean_absolute_error: 0.0471 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0037 - mean_absolute_error: 0.0458\n",
      "Epoch 21: loss improved from 0.00374 to 0.00359, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - loss: 0.0037 - mean_absolute_error: 0.0458 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0038 - mean_absolute_error: 0.0456\n",
      "Epoch 22: loss did not improve from 0.00359\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0038 - mean_absolute_error: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0039 - mean_absolute_error: 0.0478\n",
      "Epoch 23: loss did not improve from 0.00359\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0039 - mean_absolute_error: 0.0478 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0037 - mean_absolute_error: 0.0455\n",
      "Epoch 24: loss improved from 0.00359 to 0.00352, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0037 - mean_absolute_error: 0.0455 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0038 - mean_absolute_error: 0.0458\n",
      "Epoch 25: loss improved from 0.00352 to 0.00347, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0038 - mean_absolute_error: 0.0458 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0032 - mean_absolute_error: 0.0420\n",
      "Epoch 26: loss improved from 0.00347 to 0.00317, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0032 - mean_absolute_error: 0.0420 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0032 - mean_absolute_error: 0.0422\n",
      "Epoch 27: loss improved from 0.00317 to 0.00308, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0032 - mean_absolute_error: 0.0422 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0030 - mean_absolute_error: 0.0416\n",
      "Epoch 28: loss did not improve from 0.00308\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0030 - mean_absolute_error: 0.0417 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0035 - mean_absolute_error: 0.0454\n",
      "Epoch 29: loss did not improve from 0.00308\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0035 - mean_absolute_error: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0035 - mean_absolute_error: 0.0436\n",
      "Epoch 30: loss did not improve from 0.00308\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0034 - mean_absolute_error: 0.0436 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0030 - mean_absolute_error: 0.0412\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00308\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0030 - mean_absolute_error: 0.0412 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0029 - mean_absolute_error: 0.0395\n",
      "Epoch 32: loss improved from 0.00308 to 0.00287, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0029 - mean_absolute_error: 0.0395 - learning_rate: 2.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0027 - mean_absolute_error: 0.0388\n",
      "Epoch 33: loss improved from 0.00287 to 0.00248, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0026 - mean_absolute_error: 0.0387 - learning_rate: 2.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0027 - mean_absolute_error: 0.0400\n",
      "Epoch 34: loss did not improve from 0.00248\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0027 - mean_absolute_error: 0.0400 - learning_rate: 2.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0025 - mean_absolute_error: 0.0375\n",
      "Epoch 35: loss did not improve from 0.00248\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0025 - mean_absolute_error: 0.0375 - learning_rate: 2.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0025 - mean_absolute_error: 0.0383\n",
      "Epoch 36: loss improved from 0.00248 to 0.00245, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0025 - mean_absolute_error: 0.0383 - learning_rate: 2.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0030 - mean_absolute_error: 0.0421\n",
      "Epoch 37: loss did not improve from 0.00245\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0030 - mean_absolute_error: 0.0421 - learning_rate: 2.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0027 - mean_absolute_error: 0.0399\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00245\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0027 - mean_absolute_error: 0.0399 - learning_rate: 2.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0028 - mean_absolute_error: 0.0404\n",
      "Epoch 39: loss did not improve from 0.00245\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0028 - mean_absolute_error: 0.0404 - learning_rate: 4.0000e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0025 - mean_absolute_error: 0.0380\n",
      "Epoch 40: loss did not improve from 0.00245\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0025 - mean_absolute_error: 0.0380 - learning_rate: 4.0000e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0025 - mean_absolute_error: 0.0385\n",
      "Epoch 41: loss improved from 0.00245 to 0.00243, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0025 - mean_absolute_error: 0.0385 - learning_rate: 4.0000e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0025 - mean_absolute_error: 0.0382\n",
      "Epoch 42: loss did not improve from 0.00243\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0025 - mean_absolute_error: 0.0382 - learning_rate: 4.0000e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0025 - mean_absolute_error: 0.0380\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00243\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0025 - mean_absolute_error: 0.0380 - learning_rate: 4.0000e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0024 - mean_absolute_error: 0.0379\n",
      "Epoch 44: loss did not improve from 0.00243\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - loss: 0.0024 - mean_absolute_error: 0.0379 - learning_rate: 8.0000e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0025 - mean_absolute_error: 0.0382\n",
      "Epoch 45: loss did not improve from 0.00243\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0025 - mean_absolute_error: 0.0382 - learning_rate: 8.0000e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0030 - mean_absolute_error: 0.0406\n",
      "Epoch 46: loss did not improve from 0.00243\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0030 - mean_absolute_error: 0.0406 - learning_rate: 8.0000e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0026 - mean_absolute_error: 0.0382\n",
      "Epoch 47: loss improved from 0.00243 to 0.00238, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0026 - mean_absolute_error: 0.0382 - learning_rate: 8.0000e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0026 - mean_absolute_error: 0.0382\n",
      "Epoch 48: loss did not improve from 0.00238\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - loss: 0.0026 - mean_absolute_error: 0.0382 - learning_rate: 8.0000e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0025 - mean_absolute_error: 0.0377\n",
      "Epoch 49: loss did not improve from 0.00238\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0025 - mean_absolute_error: 0.0377 - learning_rate: 8.0000e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0025 - mean_absolute_error: 0.0378\n",
      "Epoch 50: loss did not improve from 0.00238\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0025 - mean_absolute_error: 0.0378 - learning_rate: 8.0000e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0023 - mean_absolute_error: 0.0359\n",
      "Epoch 51: loss improved from 0.00238 to 0.00237, saving model to pesos.keras\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0023 - mean_absolute_error: 0.0360 - learning_rate: 8.0000e-06\n",
      "Epoch 52/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0025 - mean_absolute_error: 0.0374\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00237\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 0.0025 - mean_absolute_error: 0.0374 - learning_rate: 8.0000e-06\n",
      "Epoch 53/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0024 - mean_absolute_error: 0.0375\n",
      "Epoch 53: loss did not improve from 0.00237\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0024 - mean_absolute_error: 0.0375 - learning_rate: 1.6000e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0026 - mean_absolute_error: 0.0383\n",
      "Epoch 54: loss did not improve from 0.00237\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0026 - mean_absolute_error: 0.0383 - learning_rate: 1.6000e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0027 - mean_absolute_error: 0.0389\n",
      "Epoch 55: loss did not improve from 0.00237\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0027 - mean_absolute_error: 0.0390 - learning_rate: 1.6000e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0024 - mean_absolute_error: 0.0378\n",
      "Epoch 56: loss did not improve from 0.00237\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0024 - mean_absolute_error: 0.0378 - learning_rate: 1.6000e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0027 - mean_absolute_error: 0.0394\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "\n",
      "Epoch 57: loss did not improve from 0.00237\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0027 - mean_absolute_error: 0.0394 - learning_rate: 1.6000e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0026 - mean_absolute_error: 0.0388\n",
      "Epoch 58: loss did not improve from 0.00237\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0026 - mean_absolute_error: 0.0388 - learning_rate: 3.2000e-07\n",
      "Epoch 59/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0028 - mean_absolute_error: 0.0403\n",
      "Epoch 59: loss did not improve from 0.00237\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0028 - mean_absolute_error: 0.0402 - learning_rate: 3.2000e-07\n",
      "Epoch 60/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0026 - mean_absolute_error: 0.0386\n",
      "Epoch 60: loss did not improve from 0.00237\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0026 - mean_absolute_error: 0.0386 - learning_rate: 3.2000e-07\n",
      "Epoch 61/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0023 - mean_absolute_error: 0.0364\n",
      "Epoch 61: loss did not improve from 0.00237\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0023 - mean_absolute_error: 0.0364 - learning_rate: 3.2000e-07\n",
      "Epoch 61: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f551cb66c60>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X,y,epochs=100,batch_size=32,callbacks=[es,rlr,mcp])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49612d6f-5dfd-48a5-b4a3-17e1b4ac2354",
   "metadata": {},
   "source": [
    "## Previsoes com Base de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac280fde-b4ec-43fd-a270-0de812ef76b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.190001</td>\n",
       "      <td>16.549999</td>\n",
       "      <td>16.516966</td>\n",
       "      <td>33461800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>16.490000</td>\n",
       "      <td>16.719999</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.666668</td>\n",
       "      <td>55940900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>16.780001</td>\n",
       "      <td>16.959999</td>\n",
       "      <td>16.620001</td>\n",
       "      <td>16.730000</td>\n",
       "      <td>16.696608</td>\n",
       "      <td>37064900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>16.700001</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>16.570000</td>\n",
       "      <td>16.830000</td>\n",
       "      <td>16.796408</td>\n",
       "      <td>26958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>16.740000</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.709999</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.996010</td>\n",
       "      <td>28400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>17.160000</td>\n",
       "      <td>16.959999</td>\n",
       "      <td>17.030001</td>\n",
       "      <td>16.996010</td>\n",
       "      <td>35070900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>16.920000</td>\n",
       "      <td>17.049999</td>\n",
       "      <td>16.770000</td>\n",
       "      <td>16.799999</td>\n",
       "      <td>16.766466</td>\n",
       "      <td>28547700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>16.879999</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>16.840000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>17.215569</td>\n",
       "      <td>37921500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>17.040001</td>\n",
       "      <td>17.410000</td>\n",
       "      <td>17.020000</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>17.265469</td>\n",
       "      <td>45912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>17.320000</td>\n",
       "      <td>17.440001</td>\n",
       "      <td>17.150000</td>\n",
       "      <td>17.350000</td>\n",
       "      <td>17.315371</td>\n",
       "      <td>28945400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>17.350000</td>\n",
       "      <td>17.840000</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>17.650000</td>\n",
       "      <td>17.614771</td>\n",
       "      <td>58618300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-17</td>\n",
       "      <td>17.920000</td>\n",
       "      <td>18.360001</td>\n",
       "      <td>17.809999</td>\n",
       "      <td>18.360001</td>\n",
       "      <td>18.323355</td>\n",
       "      <td>58488900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>18.530001</td>\n",
       "      <td>17.930000</td>\n",
       "      <td>18.219999</td>\n",
       "      <td>18.183632</td>\n",
       "      <td>48575800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>18.309999</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>18.030001</td>\n",
       "      <td>18.260000</td>\n",
       "      <td>18.223553</td>\n",
       "      <td>33470200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>18.260000</td>\n",
       "      <td>18.469999</td>\n",
       "      <td>18.090000</td>\n",
       "      <td>18.469999</td>\n",
       "      <td>18.433134</td>\n",
       "      <td>33920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>18.459999</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.240000</td>\n",
       "      <td>18.203592</td>\n",
       "      <td>35567700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>19.629999</td>\n",
       "      <td>18.420000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.301397</td>\n",
       "      <td>89768200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.301397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>19.620001</td>\n",
       "      <td>19.980000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>19.890221</td>\n",
       "      <td>81989500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>19.670000</td>\n",
       "      <td>20.049999</td>\n",
       "      <td>19.570000</td>\n",
       "      <td>19.850000</td>\n",
       "      <td>19.810381</td>\n",
       "      <td>55726200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>19.360001</td>\n",
       "      <td>19.490000</td>\n",
       "      <td>19.451097</td>\n",
       "      <td>46203000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>19.740000</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>19.680000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>19.660681</td>\n",
       "      <td>41576600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date       Open       High        Low      Close  Adj Close  \\\n",
       "0   2018-01-02  16.190001  16.549999  16.190001  16.549999  16.516966   \n",
       "1   2018-01-03  16.490000  16.719999  16.370001  16.700001  16.666668   \n",
       "2   2018-01-04  16.780001  16.959999  16.620001  16.730000  16.696608   \n",
       "3   2018-01-05  16.700001  16.860001  16.570000  16.830000  16.796408   \n",
       "4   2018-01-08  16.740000  17.030001  16.709999  17.030001  16.996010   \n",
       "5   2018-01-09  17.030001  17.160000  16.959999  17.030001  16.996010   \n",
       "6   2018-01-10  16.920000  17.049999  16.770000  16.799999  16.766466   \n",
       "7   2018-01-11  16.879999  17.299999  16.840000  17.250000  17.215569   \n",
       "8   2018-01-12  17.040001  17.410000  17.020000  17.299999  17.265469   \n",
       "9   2018-01-15  17.320000  17.440001  17.150000  17.350000  17.315371   \n",
       "10  2018-01-16  17.350000  17.840000  17.299999  17.650000  17.614771   \n",
       "11  2018-01-17  17.920000  18.360001  17.809999  18.360001  18.323355   \n",
       "12  2018-01-18  18.350000  18.530001  17.930000  18.219999  18.183632   \n",
       "13  2018-01-19  18.309999  18.420000  18.030001  18.260000  18.223553   \n",
       "14  2018-01-22  18.260000  18.469999  18.090000  18.469999  18.433134   \n",
       "15  2018-01-23  18.400000  18.459999  18.000000  18.240000  18.203592   \n",
       "16  2018-01-24  18.420000  19.629999  18.420000  19.340000  19.301397   \n",
       "17  2018-01-25  19.340000  19.340000  19.340000  19.340000  19.301397   \n",
       "18  2018-01-26  19.620001  19.980000  19.100000  19.930000  19.890221   \n",
       "19  2018-01-29  19.670000  20.049999  19.570000  19.850000  19.810381   \n",
       "20  2018-01-30  19.770000  19.770000  19.360001  19.490000  19.451097   \n",
       "21  2018-01-31  19.740000  19.930000  19.680000  19.700001  19.660681   \n",
       "\n",
       "      Volume  \n",
       "0   33461800  \n",
       "1   55940900  \n",
       "2   37064900  \n",
       "3   26958200  \n",
       "4   28400000  \n",
       "5   35070900  \n",
       "6   28547700  \n",
       "7   37921500  \n",
       "8   45912100  \n",
       "9   28945400  \n",
       "10  58618300  \n",
       "11  58488900  \n",
       "12  48575800  \n",
       "13  33470200  \n",
       "14  33920000  \n",
       "15  35567700  \n",
       "16  89768200  \n",
       "17         0  \n",
       "18  81989500  \n",
       "19  55726200  \n",
       "20  46203000  \n",
       "21  41576600  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_teste = pd.read_csv('petr4-teste.csv')\n",
    "base_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87f36855-a8f0-4ed0-88c5-af9bcaaaf644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eda77bd3-e810-4103-83c5-5a0bbd9df998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.190001],\n",
       "       [16.49    ],\n",
       "       [16.780001],\n",
       "       [16.700001],\n",
       "       [16.74    ],\n",
       "       [17.030001],\n",
       "       [16.92    ],\n",
       "       [16.879999],\n",
       "       [17.040001],\n",
       "       [17.32    ],\n",
       "       [17.35    ],\n",
       "       [17.92    ],\n",
       "       [18.35    ],\n",
       "       [18.309999],\n",
       "       [18.26    ],\n",
       "       [18.4     ],\n",
       "       [18.42    ],\n",
       "       [19.34    ],\n",
       "       [19.620001],\n",
       "       [19.67    ],\n",
       "       [19.77    ],\n",
       "       [19.74    ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste = base_teste.iloc[:,1:2].values\n",
    "y_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f332133-34b0-4773-a414-5a0f1290012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [base,base_teste]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc4ca502-79e7-4279-9d2b-f8d36078c456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            Date       Open       High        Low      Close  Adj Close  \\\n",
       " 0     2013-01-02  19.990000  20.209999  19.690001  19.690001  18.086271   \n",
       " 1     2013-01-03  19.809999  20.400000  19.700001  20.400000  18.738441   \n",
       " 2     2013-01-04  20.330000  20.620001  20.170000  20.430000  18.766001   \n",
       " 3     2013-01-07  20.480000  20.670000  19.950001  20.080000  18.444506   \n",
       " 4     2013-01-08  20.110001  20.230000  19.459999  19.500000  17.911745   \n",
       " ...          ...        ...        ...        ...        ...        ...   \n",
       " 1240  2017-12-25  15.750000  15.750000  15.750000  15.750000  15.718563   \n",
       " 1241  2017-12-26  15.750000  15.990000  15.690000  15.970000  15.938125   \n",
       " 1242  2017-12-27  15.990000  16.139999  15.980000  16.049999  16.017963   \n",
       " 1243  2017-12-28  16.100000  16.129999  16.000000  16.100000  16.067865   \n",
       " 1244  2017-12-29  16.100000  16.100000  16.100000  16.100000  16.067865   \n",
       " \n",
       "           Volume  \n",
       " 0     30182600.0  \n",
       " 1     30552600.0  \n",
       " 2     36141000.0  \n",
       " 3     28069600.0  \n",
       " 4     29091300.0  \n",
       " ...          ...  \n",
       " 1240         0.0  \n",
       " 1241  22173100.0  \n",
       " 1242  23552200.0  \n",
       " 1243  19011500.0  \n",
       " 1244         0.0  \n",
       " \n",
       " [1242 rows x 7 columns],\n",
       "           Date       Open       High        Low      Close  Adj Close  \\\n",
       " 0   2018-01-02  16.190001  16.549999  16.190001  16.549999  16.516966   \n",
       " 1   2018-01-03  16.490000  16.719999  16.370001  16.700001  16.666668   \n",
       " 2   2018-01-04  16.780001  16.959999  16.620001  16.730000  16.696608   \n",
       " 3   2018-01-05  16.700001  16.860001  16.570000  16.830000  16.796408   \n",
       " 4   2018-01-08  16.740000  17.030001  16.709999  17.030001  16.996010   \n",
       " 5   2018-01-09  17.030001  17.160000  16.959999  17.030001  16.996010   \n",
       " 6   2018-01-10  16.920000  17.049999  16.770000  16.799999  16.766466   \n",
       " 7   2018-01-11  16.879999  17.299999  16.840000  17.250000  17.215569   \n",
       " 8   2018-01-12  17.040001  17.410000  17.020000  17.299999  17.265469   \n",
       " 9   2018-01-15  17.320000  17.440001  17.150000  17.350000  17.315371   \n",
       " 10  2018-01-16  17.350000  17.840000  17.299999  17.650000  17.614771   \n",
       " 11  2018-01-17  17.920000  18.360001  17.809999  18.360001  18.323355   \n",
       " 12  2018-01-18  18.350000  18.530001  17.930000  18.219999  18.183632   \n",
       " 13  2018-01-19  18.309999  18.420000  18.030001  18.260000  18.223553   \n",
       " 14  2018-01-22  18.260000  18.469999  18.090000  18.469999  18.433134   \n",
       " 15  2018-01-23  18.400000  18.459999  18.000000  18.240000  18.203592   \n",
       " 16  2018-01-24  18.420000  19.629999  18.420000  19.340000  19.301397   \n",
       " 17  2018-01-25  19.340000  19.340000  19.340000  19.340000  19.301397   \n",
       " 18  2018-01-26  19.620001  19.980000  19.100000  19.930000  19.890221   \n",
       " 19  2018-01-29  19.670000  20.049999  19.570000  19.850000  19.810381   \n",
       " 20  2018-01-30  19.770000  19.770000  19.360001  19.490000  19.451097   \n",
       " 21  2018-01-31  19.740000  19.930000  19.680000  19.700001  19.660681   \n",
       " \n",
       "       Volume  \n",
       " 0   33461800  \n",
       " 1   55940900  \n",
       " 2   37064900  \n",
       " 3   26958200  \n",
       " 4   28400000  \n",
       " 5   35070900  \n",
       " 6   28547700  \n",
       " 7   37921500  \n",
       " 8   45912100  \n",
       " 9   28945400  \n",
       " 10  58618300  \n",
       " 11  58488900  \n",
       " 12  48575800  \n",
       " 13  33470200  \n",
       " 14  33920000  \n",
       " 15  35567700  \n",
       " 16  89768200  \n",
       " 17         0  \n",
       " 18  81989500  \n",
       " 19  55726200  \n",
       " 20  46203000  \n",
       " 21  41576600  ]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f429bdf-609f-492e-9007-0fd75afabe0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>19.990000</td>\n",
       "      <td>20.209999</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>18.086271</td>\n",
       "      <td>30182600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>19.809999</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>18.738441</td>\n",
       "      <td>30552600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>20.330000</td>\n",
       "      <td>20.620001</td>\n",
       "      <td>20.170000</td>\n",
       "      <td>20.430000</td>\n",
       "      <td>18.766001</td>\n",
       "      <td>36141000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>20.480000</td>\n",
       "      <td>20.670000</td>\n",
       "      <td>19.950001</td>\n",
       "      <td>20.080000</td>\n",
       "      <td>18.444506</td>\n",
       "      <td>28069600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>20.110001</td>\n",
       "      <td>20.230000</td>\n",
       "      <td>19.459999</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>17.911745</td>\n",
       "      <td>29091300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.301397</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>19.620001</td>\n",
       "      <td>19.980000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>19.890221</td>\n",
       "      <td>81989500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>19.670000</td>\n",
       "      <td>20.049999</td>\n",
       "      <td>19.570000</td>\n",
       "      <td>19.850000</td>\n",
       "      <td>19.810381</td>\n",
       "      <td>55726200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>19.770000</td>\n",
       "      <td>19.360001</td>\n",
       "      <td>19.490000</td>\n",
       "      <td>19.451097</td>\n",
       "      <td>46203000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>19.740000</td>\n",
       "      <td>19.930000</td>\n",
       "      <td>19.680000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>19.660681</td>\n",
       "      <td>41576600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1264 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date       Open       High        Low      Close  Adj Close  \\\n",
       "0   2013-01-02  19.990000  20.209999  19.690001  19.690001  18.086271   \n",
       "1   2013-01-03  19.809999  20.400000  19.700001  20.400000  18.738441   \n",
       "2   2013-01-04  20.330000  20.620001  20.170000  20.430000  18.766001   \n",
       "3   2013-01-07  20.480000  20.670000  19.950001  20.080000  18.444506   \n",
       "4   2013-01-08  20.110001  20.230000  19.459999  19.500000  17.911745   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "17  2018-01-25  19.340000  19.340000  19.340000  19.340000  19.301397   \n",
       "18  2018-01-26  19.620001  19.980000  19.100000  19.930000  19.890221   \n",
       "19  2018-01-29  19.670000  20.049999  19.570000  19.850000  19.810381   \n",
       "20  2018-01-30  19.770000  19.770000  19.360001  19.490000  19.451097   \n",
       "21  2018-01-31  19.740000  19.930000  19.680000  19.700001  19.660681   \n",
       "\n",
       "        Volume  \n",
       "0   30182600.0  \n",
       "1   30552600.0  \n",
       "2   36141000.0  \n",
       "3   28069600.0  \n",
       "4   29091300.0  \n",
       "..         ...  \n",
       "17         0.0  \n",
       "18  81989500.0  \n",
       "19  55726200.0  \n",
       "20  46203000.0  \n",
       "21  41576600.0  \n",
       "\n",
       "[1264 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_completa = pd.concat(frames)\n",
    "base_completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b18ab858-2879-4eb5-9b9e-18aa258f29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_completa = base_completa.drop('Date',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19511e9a-f3ba-4c04-a1c3-ccfd7642c98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1264, 22)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_completa), len(base_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a645fa1b-ede3-4edc-9d48-18bdd136924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = base_completa[len(base_completa) - len(base_teste) - 90:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a56eec26-bfe2-4ba6-930d-fe981ae68a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3930000e+01, 1.4030000e+01, 1.3760000e+01, 1.3870000e+01,\n",
       "        1.3842316e+01, 2.7208100e+07],\n",
       "       [1.3760000e+01, 1.3850000e+01, 1.3680000e+01, 1.3850000e+01,\n",
       "        1.3822356e+01, 2.7306400e+07],\n",
       "       [1.3790000e+01, 1.3900000e+01, 1.3440000e+01, 1.3450000e+01,\n",
       "        1.3423154e+01, 5.8871700e+07],\n",
       "       [1.3530000e+01, 1.3770000e+01, 1.3470000e+01, 1.3650000e+01,\n",
       "        1.3622754e+01, 8.2909400e+07],\n",
       "       [1.3850000e+01, 1.4190000e+01, 1.3820000e+01, 1.4020000e+01,\n",
       "        1.3992017e+01, 6.0260300e+07],\n",
       "       [1.3960000e+01, 1.4180000e+01, 1.3940000e+01, 1.4170000e+01,\n",
       "        1.4141717e+01, 1.8139300e+07],\n",
       "       [1.4570000e+01, 1.4650000e+01, 1.4230000e+01, 1.4410000e+01,\n",
       "        1.4381238e+01, 5.6476800e+07],\n",
       "       [1.4650000e+01, 1.5020000e+01, 1.4510000e+01, 1.5020000e+01,\n",
       "        1.4990021e+01, 6.8418200e+07],\n",
       "       [1.5020000e+01, 1.5020000e+01, 1.5020000e+01, 1.5020000e+01,\n",
       "        1.4990021e+01, 0.0000000e+00],\n",
       "       [1.5100000e+01, 1.5150000e+01, 1.4690000e+01, 1.4710000e+01,\n",
       "        1.4680639e+01, 3.6337400e+07],\n",
       "       [1.4880000e+01, 1.5050000e+01, 1.4810000e+01, 1.4990000e+01,\n",
       "        1.4960080e+01, 3.4915900e+07],\n",
       "       [1.4980000e+01, 1.5160000e+01, 1.4860000e+01, 1.4870000e+01,\n",
       "        1.4840320e+01, 4.9702800e+07],\n",
       "       [1.4940000e+01, 1.5100000e+01, 1.4810000e+01, 1.5030000e+01,\n",
       "        1.5000000e+01, 3.7010200e+07],\n",
       "       [1.5030000e+01, 1.5260000e+01, 1.5020000e+01, 1.5040000e+01,\n",
       "        1.5009980e+01, 3.4413800e+07],\n",
       "       [1.5070000e+01, 1.5170000e+01, 1.4990000e+01, 1.5040000e+01,\n",
       "        1.5009980e+01, 4.7784700e+07],\n",
       "       [1.5020000e+01, 1.5190000e+01, 1.4980000e+01, 1.5040000e+01,\n",
       "        1.5009980e+01, 4.7601200e+07],\n",
       "       [1.5100000e+01, 1.5170000e+01, 1.4920000e+01, 1.5140000e+01,\n",
       "        1.5109781e+01, 3.5822100e+07],\n",
       "       [1.5250000e+01, 1.5880000e+01, 1.5070000e+01, 1.5870000e+01,\n",
       "        1.5838324e+01, 8.0267000e+07],\n",
       "       [1.5850000e+01, 1.5960000e+01, 1.5580000e+01, 1.5670000e+01,\n",
       "        1.5638723e+01, 4.6258800e+07],\n",
       "       [1.5600000e+01, 1.5800000e+01, 1.5430000e+01, 1.5690000e+01,\n",
       "        1.5658683e+01, 4.0928300e+07],\n",
       "       [1.5790000e+01, 1.5960000e+01, 1.5700000e+01, 1.5840000e+01,\n",
       "        1.5808384e+01, 3.6733200e+07],\n",
       "       [1.5860000e+01, 1.5900000e+01, 1.5560000e+01, 1.5560000e+01,\n",
       "        1.5528943e+01, 3.7874200e+07],\n",
       "       [1.5700000e+01, 1.5720000e+01, 1.5110000e+01, 1.5310000e+01,\n",
       "        1.5279442e+01, 4.1819300e+07],\n",
       "       [1.5370000e+01, 1.5500000e+01, 1.5220000e+01, 1.5340000e+01,\n",
       "        1.5309381e+01, 3.3829000e+07],\n",
       "       [1.5500000e+01, 1.5520000e+01, 1.5300000e+01, 1.5300000e+01,\n",
       "        1.5269462e+01, 2.8638300e+07],\n",
       "       [1.5190000e+01, 1.5400000e+01, 1.5060000e+01, 1.5400000e+01,\n",
       "        1.5369262e+01, 2.9826200e+07],\n",
       "       [1.5600000e+01, 1.5980000e+01, 1.5520000e+01, 1.5980000e+01,\n",
       "        1.5948104e+01, 5.0636700e+07],\n",
       "       [1.5900000e+01, 1.5940000e+01, 1.5650000e+01, 1.5660000e+01,\n",
       "        1.5628743e+01, 4.7798600e+07],\n",
       "       [1.5880000e+01, 1.6110001e+01, 1.5850000e+01, 1.5900000e+01,\n",
       "        1.5868263e+01, 5.5361300e+07],\n",
       "       [1.5660000e+01, 1.5770000e+01, 1.5540000e+01, 1.5690000e+01,\n",
       "        1.5658683e+01, 4.1741300e+07],\n",
       "       [1.5610000e+01, 1.5890000e+01, 1.5590000e+01, 1.5890000e+01,\n",
       "        1.5858284e+01, 2.7904700e+07],\n",
       "       [1.6129999e+01, 1.6190001e+01, 1.6010000e+01, 1.6190001e+01,\n",
       "        1.6157686e+01, 4.7066600e+07],\n",
       "       [1.6170000e+01, 1.6250000e+01, 1.6010000e+01, 1.6080000e+01,\n",
       "        1.6047905e+01, 4.0422100e+07],\n",
       "       [1.6080000e+01, 1.6080000e+01, 1.6080000e+01, 1.6080000e+01,\n",
       "        1.6047905e+01, 0.0000000e+00],\n",
       "       [1.6230000e+01, 1.6290001e+01, 1.6059999e+01, 1.6080000e+01,\n",
       "        1.6047905e+01, 2.4210000e+07],\n",
       "       [1.6160000e+01, 1.6260000e+01, 1.6000000e+01, 1.6120001e+01,\n",
       "        1.6087826e+01, 4.4699700e+07],\n",
       "       [1.6139999e+01, 1.6219999e+01, 1.6070000e+01, 1.6129999e+01,\n",
       "        1.6097803e+01, 2.5524800e+07],\n",
       "       [1.6219999e+01, 1.6280001e+01, 1.6129999e+01, 1.6160000e+01,\n",
       "        1.6127745e+01, 2.5706200e+07],\n",
       "       [1.6000000e+01, 1.6160000e+01, 1.5900000e+01, 1.6150000e+01,\n",
       "        1.6117765e+01, 2.4672800e+07],\n",
       "       [1.6190001e+01, 1.6389999e+01, 1.6170000e+01, 1.6219999e+01,\n",
       "        1.6187624e+01, 3.2417500e+07],\n",
       "       [1.6290001e+01, 1.6290001e+01, 1.6120001e+01, 1.6200001e+01,\n",
       "        1.6167665e+01, 2.9389900e+07],\n",
       "       [1.6290001e+01, 1.6510000e+01, 1.6120001e+01, 1.6510000e+01,\n",
       "        1.6477047e+01, 4.6249500e+07],\n",
       "       [1.6530001e+01, 1.6730000e+01, 1.6450001e+01, 1.6719999e+01,\n",
       "        1.6686626e+01, 3.7608200e+07],\n",
       "       [1.6780001e+01, 1.6889999e+01, 1.6660000e+01, 1.6730000e+01,\n",
       "        1.6696608e+01, 3.7848300e+07],\n",
       "       [1.6770000e+01, 1.7090000e+01, 1.6650000e+01, 1.7030001e+01,\n",
       "        1.6996010e+01, 4.5640100e+07],\n",
       "       [1.6969999e+01, 1.7170000e+01, 1.6740000e+01, 1.6780001e+01,\n",
       "        1.6746508e+01, 5.5355600e+07],\n",
       "       [1.6900000e+01, 1.6950001e+01, 1.6719999e+01, 1.6770000e+01,\n",
       "        1.6736528e+01, 3.2249000e+07],\n",
       "       [1.6990000e+01, 1.7100000e+01, 1.6879999e+01, 1.6900000e+01,\n",
       "        1.6866268e+01, 3.8876600e+07],\n",
       "       [1.6900000e+01, 1.6900000e+01, 1.6900000e+01, 1.6900000e+01,\n",
       "        1.6866268e+01, 0.0000000e+00],\n",
       "       [1.6959999e+01, 1.7010000e+01, 1.6680000e+01, 1.6940001e+01,\n",
       "        1.6906189e+01, 3.2605400e+07],\n",
       "       [1.7049999e+01, 1.7440001e+01, 1.6980000e+01, 1.7430000e+01,\n",
       "        1.7395210e+01, 4.6056100e+07],\n",
       "       [1.7309999e+01, 1.7350000e+01, 1.6500000e+01, 1.6500000e+01,\n",
       "        1.6467066e+01, 6.1098400e+07],\n",
       "       [1.6690001e+01, 1.6950001e+01, 1.6510000e+01, 1.6950001e+01,\n",
       "        1.6916168e+01, 4.1179600e+07],\n",
       "       [1.6889999e+01, 1.6940001e+01, 1.6719999e+01, 1.6719999e+01,\n",
       "        1.6686626e+01, 2.9399400e+07],\n",
       "       [1.6709999e+01, 1.6809999e+01, 1.6510000e+01, 1.6719999e+01,\n",
       "        1.6686626e+01, 3.5959400e+07],\n",
       "       [1.6690001e+01, 1.6770000e+01, 1.6389999e+01, 1.6639999e+01,\n",
       "        1.6606787e+01, 2.8697700e+07],\n",
       "       [1.6639999e+01, 1.6639999e+01, 1.5280000e+01, 1.5350000e+01,\n",
       "        1.5319362e+01, 8.8765600e+07],\n",
       "       [1.5350000e+01, 1.5350000e+01, 1.5350000e+01, 1.5350000e+01,\n",
       "        1.5319362e+01, 0.0000000e+00],\n",
       "       [1.5620000e+01, 1.6040001e+01, 1.5480000e+01, 1.5810000e+01,\n",
       "        1.5778444e+01, 4.2703800e+07],\n",
       "       [1.5920000e+01, 1.6120001e+01, 1.5810000e+01, 1.6020000e+01,\n",
       "        1.5988025e+01, 3.8376900e+07],\n",
       "       [1.6020000e+01, 1.6020000e+01, 1.6020000e+01, 1.6020000e+01,\n",
       "        1.5988025e+01, 0.0000000e+00],\n",
       "       [1.6150000e+01, 1.6309999e+01, 1.5850000e+01, 1.5900000e+01,\n",
       "        1.5868263e+01, 4.5817800e+07],\n",
       "       [1.6090000e+01, 1.6240000e+01, 1.5930000e+01, 1.6110001e+01,\n",
       "        1.6077845e+01, 3.7444900e+07],\n",
       "       [1.5980000e+01, 1.6260000e+01, 1.5940000e+01, 1.6190001e+01,\n",
       "        1.6157686e+01, 1.5403600e+07],\n",
       "       [1.6250000e+01, 1.6370001e+01, 1.6040001e+01, 1.6100000e+01,\n",
       "        1.6067865e+01, 1.8790700e+07],\n",
       "       [1.6010000e+01, 1.6020000e+01, 1.5780000e+01, 1.5870000e+01,\n",
       "        1.5838324e+01, 2.8445800e+07],\n",
       "       [1.5930000e+01, 1.6040001e+01, 1.5810000e+01, 1.5840000e+01,\n",
       "        1.5808384e+01, 3.0429600e+07],\n",
       "       [1.5870000e+01, 1.5920000e+01, 1.5320000e+01, 1.5330000e+01,\n",
       "        1.5299401e+01, 4.5973000e+07],\n",
       "       [1.5300000e+01, 1.5470000e+01, 1.4990000e+01, 1.5380000e+01,\n",
       "        1.5349302e+01, 5.2811400e+07],\n",
       "       [1.5340000e+01, 1.5770000e+01, 1.5260000e+01, 1.5610000e+01,\n",
       "        1.5578842e+01, 4.2703800e+07],\n",
       "       [1.5650000e+01, 1.5800000e+01, 1.5460000e+01, 1.5480000e+01,\n",
       "        1.5449101e+01, 4.3821500e+07],\n",
       "       [1.5500000e+01, 1.5830000e+01, 1.5210000e+01, 1.5310000e+01,\n",
       "        1.5279442e+01, 3.0228000e+07],\n",
       "       [1.5220000e+01, 1.5700000e+01, 1.5140000e+01, 1.5520000e+01,\n",
       "        1.5489023e+01, 3.9238500e+07],\n",
       "       [1.5300000e+01, 1.5490000e+01, 1.5070000e+01, 1.5260000e+01,\n",
       "        1.5229542e+01, 3.7281400e+07],\n",
       "       [1.5510000e+01, 1.5680000e+01, 1.5350000e+01, 1.5350000e+01,\n",
       "        1.5319362e+01, 3.9584500e+07],\n",
       "       [1.5480000e+01, 1.5570000e+01, 1.5370000e+01, 1.5380000e+01,\n",
       "        1.5349302e+01, 2.1281600e+07],\n",
       "       [1.5360000e+01, 1.5490000e+01, 1.5180000e+01, 1.5490000e+01,\n",
       "        1.5459082e+01, 3.6201200e+07],\n",
       "       [1.5650000e+01, 1.5680000e+01, 1.5110000e+01, 1.5180000e+01,\n",
       "        1.5149701e+01, 4.6828900e+07],\n",
       "       [1.5100000e+01, 1.5310000e+01, 1.5000000e+01, 1.5010000e+01,\n",
       "        1.4980041e+01, 3.7177300e+07],\n",
       "       [1.5050000e+01, 1.5240000e+01, 1.4950000e+01, 1.4950000e+01,\n",
       "        1.4920160e+01, 5.5668300e+07],\n",
       "       [1.5160000e+01, 1.5330000e+01, 1.5130000e+01, 1.5220000e+01,\n",
       "        1.5189621e+01, 4.2760400e+07],\n",
       "       [1.5180000e+01, 1.5250000e+01, 1.5060000e+01, 1.5140000e+01,\n",
       "        1.5109781e+01, 2.2639700e+07],\n",
       "       [1.5210000e+01, 1.5300000e+01, 1.5170000e+01, 1.5240000e+01,\n",
       "        1.5209581e+01, 2.0149700e+07],\n",
       "       [1.5310000e+01, 1.5870000e+01, 1.5300000e+01, 1.5860000e+01,\n",
       "        1.5828343e+01, 4.7219400e+07],\n",
       "       [1.5750000e+01, 1.5890000e+01, 1.5690000e+01, 1.5750000e+01,\n",
       "        1.5718563e+01, 1.8708500e+07],\n",
       "       [1.5750000e+01, 1.5750000e+01, 1.5750000e+01, 1.5750000e+01,\n",
       "        1.5718563e+01, 0.0000000e+00],\n",
       "       [1.5750000e+01, 1.5990000e+01, 1.5690000e+01, 1.5970000e+01,\n",
       "        1.5938125e+01, 2.2173100e+07],\n",
       "       [1.5990000e+01, 1.6139999e+01, 1.5980000e+01, 1.6049999e+01,\n",
       "        1.6017963e+01, 2.3552200e+07],\n",
       "       [1.6100000e+01, 1.6129999e+01, 1.6000000e+01, 1.6100000e+01,\n",
       "        1.6067865e+01, 1.9011500e+07],\n",
       "       [1.6100000e+01, 1.6100000e+01, 1.6100000e+01, 1.6100000e+01,\n",
       "        1.6067865e+01, 0.0000000e+00],\n",
       "       [1.6190001e+01, 1.6549999e+01, 1.6190001e+01, 1.6549999e+01,\n",
       "        1.6516966e+01, 3.3461800e+07],\n",
       "       [1.6490000e+01, 1.6719999e+01, 1.6370001e+01, 1.6700001e+01,\n",
       "        1.6666668e+01, 5.5940900e+07],\n",
       "       [1.6780001e+01, 1.6959999e+01, 1.6620001e+01, 1.6730000e+01,\n",
       "        1.6696608e+01, 3.7064900e+07],\n",
       "       [1.6700001e+01, 1.6860001e+01, 1.6570000e+01, 1.6830000e+01,\n",
       "        1.6796408e+01, 2.6958200e+07],\n",
       "       [1.6740000e+01, 1.7030001e+01, 1.6709999e+01, 1.7030001e+01,\n",
       "        1.6996010e+01, 2.8400000e+07],\n",
       "       [1.7030001e+01, 1.7160000e+01, 1.6959999e+01, 1.7030001e+01,\n",
       "        1.6996010e+01, 3.5070900e+07],\n",
       "       [1.6920000e+01, 1.7049999e+01, 1.6770000e+01, 1.6799999e+01,\n",
       "        1.6766466e+01, 2.8547700e+07],\n",
       "       [1.6879999e+01, 1.7299999e+01, 1.6840000e+01, 1.7250000e+01,\n",
       "        1.7215569e+01, 3.7921500e+07],\n",
       "       [1.7040001e+01, 1.7410000e+01, 1.7020000e+01, 1.7299999e+01,\n",
       "        1.7265469e+01, 4.5912100e+07],\n",
       "       [1.7320000e+01, 1.7440001e+01, 1.7150000e+01, 1.7350000e+01,\n",
       "        1.7315371e+01, 2.8945400e+07],\n",
       "       [1.7350000e+01, 1.7840000e+01, 1.7299999e+01, 1.7650000e+01,\n",
       "        1.7614771e+01, 5.8618300e+07],\n",
       "       [1.7920000e+01, 1.8360001e+01, 1.7809999e+01, 1.8360001e+01,\n",
       "        1.8323355e+01, 5.8488900e+07],\n",
       "       [1.8350000e+01, 1.8530001e+01, 1.7930000e+01, 1.8219999e+01,\n",
       "        1.8183632e+01, 4.8575800e+07],\n",
       "       [1.8309999e+01, 1.8420000e+01, 1.8030001e+01, 1.8260000e+01,\n",
       "        1.8223553e+01, 3.3470200e+07],\n",
       "       [1.8260000e+01, 1.8469999e+01, 1.8090000e+01, 1.8469999e+01,\n",
       "        1.8433134e+01, 3.3920000e+07],\n",
       "       [1.8400000e+01, 1.8459999e+01, 1.8000000e+01, 1.8240000e+01,\n",
       "        1.8203592e+01, 3.5567700e+07],\n",
       "       [1.8420000e+01, 1.9629999e+01, 1.8420000e+01, 1.9340000e+01,\n",
       "        1.9301397e+01, 8.9768200e+07],\n",
       "       [1.9340000e+01, 1.9340000e+01, 1.9340000e+01, 1.9340000e+01,\n",
       "        1.9301397e+01, 0.0000000e+00],\n",
       "       [1.9620001e+01, 1.9980000e+01, 1.9100000e+01, 1.9930000e+01,\n",
       "        1.9890221e+01, 8.1989500e+07],\n",
       "       [1.9670000e+01, 2.0049999e+01, 1.9570000e+01, 1.9850000e+01,\n",
       "        1.9810381e+01, 5.5726200e+07],\n",
       "       [1.9770000e+01, 1.9770000e+01, 1.9360001e+01, 1.9490000e+01,\n",
       "        1.9451097e+01, 4.6203000e+07],\n",
       "       [1.9740000e+01, 1.9930000e+01, 1.9680000e+01, 1.9700001e+01,\n",
       "        1.9660681e+01, 4.1576600e+07]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9202499-328a-4604-926c-575464eaebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = normalizador.transform(entradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5690904-5b0a-4f29-bfd5-72115381adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste = []\n",
    "for i in range(90,112):\n",
    "    X_teste.append(entradas[i-90:i,0:6])\n",
    "X_teste = np.array(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d91cdad1-6f6d-4f75-a018-c4e14076d418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 90, 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53311a39-ee7c-413c-8faf-7bf69eb29972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642ms/step\n"
     ]
    }
   ],
   "source": [
    "previsoes = regressor.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da5ae82a-cda0-475a-bcd6-b7005a326a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5756638 ],\n",
       "       [0.58236384],\n",
       "       [0.58853734],\n",
       "       [0.5945736 ],\n",
       "       [0.6003492 ],\n",
       "       [0.6058445 ],\n",
       "       [0.61105716],\n",
       "       [0.6152485 ],\n",
       "       [0.6185866 ],\n",
       "       [0.6215254 ],\n",
       "       [0.6244856 ],\n",
       "       [0.6282218 ],\n",
       "       [0.6343935 ],\n",
       "       [0.6432635 ],\n",
       "       [0.6536276 ],\n",
       "       [0.6639383 ],\n",
       "       [0.6723505 ],\n",
       "       [0.68007845],\n",
       "       [0.6883071 ],\n",
       "       [0.698423  ],\n",
       "       [0.7100905 ],\n",
       "       [0.72094315]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e66d5b28-c83e-478c-a9a4-57faee0d90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = normalizador_previsao.inverse_transform(previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f241a84-95ca-4c29-bd77-e39b4dbbd1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.081701],\n",
       "       [16.21999 ],\n",
       "       [16.34741 ],\n",
       "       [16.471998],\n",
       "       [16.591208],\n",
       "       [16.70463 ],\n",
       "       [16.81222 ],\n",
       "       [16.89873 ],\n",
       "       [16.967627],\n",
       "       [17.028284],\n",
       "       [17.089382],\n",
       "       [17.166498],\n",
       "       [17.293882],\n",
       "       [17.47696 ],\n",
       "       [17.690872],\n",
       "       [17.903687],\n",
       "       [18.077314],\n",
       "       [18.236818],\n",
       "       [18.406658],\n",
       "       [18.61545 ],\n",
       "       [18.856268],\n",
       "       [19.080267]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a25b7b1-0f8f-428a-b8e8-ba3567b7832b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.190001],\n",
       "       [16.49    ],\n",
       "       [16.780001],\n",
       "       [16.700001],\n",
       "       [16.74    ],\n",
       "       [17.030001],\n",
       "       [16.92    ],\n",
       "       [16.879999],\n",
       "       [17.040001],\n",
       "       [17.32    ],\n",
       "       [17.35    ],\n",
       "       [17.92    ],\n",
       "       [18.35    ],\n",
       "       [18.309999],\n",
       "       [18.26    ],\n",
       "       [18.4     ],\n",
       "       [18.42    ],\n",
       "       [19.34    ],\n",
       "       [19.620001],\n",
       "       [19.67    ],\n",
       "       [19.77    ],\n",
       "       [19.74    ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "10e175cd-9aef-44fb-b756-87f2849e02dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.364447"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc7bf421-d853-4c78-bcdf-6bf7e469fff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.87454563636364"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed428442-aca8-403a-8c4e-7bfb733c77b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5118005393399325"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_teste,previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e246ced-862f-4294-8231-319cd159b33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f551572a660>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_teste,color=\"red\",label=\"Preço real\")\n",
    "plt.plot(previsoes,color=\"blue\",label=\"Previsores\")\n",
    "plt.title(\"Previsão do preço das ações\")\n",
    "plt.xlabel(\"Tempo\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
