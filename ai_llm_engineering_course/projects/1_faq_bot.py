# import libraries for frontend
import streamlit as st

# import libraries for backend
import chromadb
from chromadb.utils import embedding_functions
from openai import OpenAI

# Embedding Class
class EmbeddingModel:
    def __init__(self):
        self.embedding_fn = embedding_functions.DefaultEmbeddingFunction()

class LLMModel:
    def __init__(self):
        self.client = OpenAI(base_url="http://localhost:11434/v1",api_key="ollama")
        self.model_name = "llama3.2:1b"

    def generate_completion(self,messages):
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=0.0
            )
            return response.choices[0].message.content 
        except Exception as e:
            return f"Error generating response: {str(e)}" 

def load_questions():
    return [
        {"id": 1, "question": "Como fa√ßo para redefinir minha senha?", "answer": "Voc√™ pode redefinir sua senha clicando em 'Esqueci minha senha' na tela de login."},
        {"id": 2, "question": "Onde posso alterar meu e-mail cadastrado?", "answer": "Acesse seu perfil, v√° em configura√ß√µes de conta e atualize o campo de e-mail."},
        {"id": 3, "question": "Quais s√£o os planos dispon√≠veis no sistema?", "answer": "Oferecemos planos B√°sico, Profissional e Empresarial. Confira os detalhes na p√°gina de pre√ßos."},
        {"id": 4, "question": "Como posso cancelar minha conta?", "answer": "Entre em 'Configura√ß√µes da Conta' e clique em 'Cancelar Conta'. Voc√™ tamb√©m pode entrar em contato com o suporte."},
        {"id": 5, "question": "O sistema possui aplicativo para celular?", "answer": "Sim, nosso app est√° dispon√≠vel para Android e iOS nas lojas oficiais."},
        {"id": 6, "question": "Como gero um relat√≥rio de atividades?", "answer": "Acesse o menu 'Relat√≥rios' e selecione o tipo de atividade que deseja visualizar."},
        {"id": 7, "question": "Consigo exportar os dados para Excel ou PDF?", "answer": "Sim, em v√°rias telas do sistema h√° a op√ß√£o de exporta√ß√£o nos formatos Excel e PDF."},
        {"id": 8, "question": "√â poss√≠vel integrar com outros sistemas?", "answer": "Sim, temos uma API dispon√≠vel e integra√ß√µes prontas com diversos sistemas."},
        {"id": 9, "question": "Onde encontro o hist√≥rico das minhas a√ß√µes?", "answer": "O hist√≥rico fica dispon√≠vel no seu perfil, na aba 'Atividades recentes'."},
        {"id": 10, "question": "Como funciona a pol√≠tica de privacidade?", "answer": "Nossa pol√≠tica de privacidade est√° dispon√≠vel no rodap√© do site e explica como usamos seus dados."},
        {"id": 11, "question": "Posso cadastrar mais de um usu√°rio na conta?", "answer": "Sim, em planos superiores voc√™ pode adicionar m√∫ltiplos usu√°rios com diferentes n√≠veis de acesso."},
        {"id": 12, "question": "O sistema envia notifica√ß√µes por e-mail?", "answer": "Sim, voc√™ pode configurar quais notifica√ß√µes deseja receber no seu perfil."},
        {"id": 13, "question": "Qual √© o hor√°rio de atendimento do suporte?", "answer": "Nosso suporte est√° dispon√≠vel de segunda a sexta, das 9h √†s 18h."},
        {"id": 14, "question": "Como fa√ßo o backup dos meus dados?", "answer": "Voc√™ pode solicitar um backup completo acessando as configura√ß√µes de conta ou via suporte."},
        {"id": 15, "question": "O sistema armazena os dados em nuvem?", "answer": "Sim, todos os dados s√£o armazenados com seguran√ßa em servidores em nuvem."},
        {"id": 16, "question": "Existe um modo escuro (dark mode)?", "answer": "Sim, voc√™ pode ativar o modo escuro nas prefer√™ncias de visualiza√ß√£o."},
        {"id": 17, "question": "√â poss√≠vel recuperar registros exclu√≠dos?", "answer": "Sim, registros exclu√≠dos ficam dispon√≠veis na lixeira por at√© 30 dias."},
        {"id": 18, "question": "Qual a diferen√ßa entre os perfis de acesso?", "answer": "Os perfis definem permiss√µes diferentes, como administrador, editor e visualizador."},
        {"id": 19, "question": "Consigo acompanhar as atualiza√ß√µes do sistema?", "answer": "Sim, todas as atualiza√ß√µes s√£o divulgadas na aba 'Novidades' dentro do sistema."},
        {"id": 20, "question": "Onde posso alterar as configura√ß√µes da minha conta?", "answer": "Basta acessar seu perfil e clicar em 'Configura√ß√µes da Conta'."},
    ]

def setup_chromadb(documents, embedding_model):
    client = chromadb.Client()

    try:
        client.delete_collection("faqs")
    except:
        pass

    collection = client.create_collection(
        name="faqs", embedding_function=embedding_model.embedding_fn
    )

    collection.add(documents=documents, ids=[str(i) for i in range(len(documents))])
    return collection

def find_related_chunks(query, collection, top_k=2):
    results = collection.query(query_texts=[query], n_results=top_k)

    return list(
        zip(
            results["documents"][0],
            (
                results["metadatas"][0]
                if results["metadatas"][0]
                else [{}] * len(results["documents"][0])
            ),
        )
    )

def augment_prompt(query, related_chunks, example_q=None, example_a=None):
    context = "\n".join([chunk[0] for chunk in related_chunks])
    example_text = ""
    if example_q and example_a:
        example_text = f"Example:\nQuestion: {example_q}\nAnswer: {example_a}\n\n"          
    augmented_prompt = f"Context:\n{context}\n\nQuestion: {query}\nAnswer:"

    return augmented_prompt

def rag_pipeline(query, collection, llm_model, top_k=2, example_q=None, example_a=None):
    print(f"\nProcessing query: {query}")

    related_chunks = find_related_chunks(query, collection, top_k)
    augmented_prompt = augment_prompt(query, related_chunks, example_q, example_a)

    response = llm_model.generate_completion(
        [
            {
                "role": "system",
                "content": "You are a helpful assistant who can answer questions about our system through the FAQ in the sources/documents given.",
            },
            {"role": "user", "content": augmented_prompt},
        ]
    )

    references = [chunk[0] for chunk in related_chunks]
    return response, references

def main():
    # Initialize models
    llm_model = LLMModel()
    embedding_model = EmbeddingModel()

    # Generate and load data
    questions = load_questions()
    documents = [f"{q['question']} {q['answer']}" for q in questions]

    # Setup ChromaDB
    collection = setup_chromadb(documents, embedding_model)

    st.set_page_config(page_title="Faq Bot", layout="wide")
    col1, col2, col3 = st.columns([1, 2, 1]) 
    with col2:
        st.title("üí¨ Chat")
        st.write("Ask your question about the FAQ below:")

        if "history" not in st.session_state:
            st.session_state.history = []

        # Caixa de texto que envia ao pressionar Enter
        user_input = st.text_input('')

        # Se houver entrada, adiciona ao hist√≥rico e gera resposta
        if user_input:

            st.session_state.history.append(user_input)

            # Exemplo de pergunta e resposta ideal para ajudar o modelo
            example_question = "Como fa√ßo para redefinir minha senha?"
            example_answer = "Voc√™ pode redefinir sua senha clicando em 'Esqueci minha senha' na tela de login."

            with st.spinner("Processing..."):
                # Chama a fun√ß√£o RAG
                response, references = rag_pipeline(user_input, collection, llm_model, example_q=example_question, example_a=example_answer)

            st.markdown(f"**Bot:** {response}")
 
if __name__ == "__main__":
    main()